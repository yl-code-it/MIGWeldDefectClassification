{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Machine_Learning_Term_Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yl-code-it/MIGWeldDefectClassification/blob/main/Machine_Learning_Term_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Machine Learning 3253 - Term Project \n",
        "# **Classifying Good/Bad Weld Images using Transfer Learning in Keras**\n",
        "# Yu Lin, Soumitra Dinda, Senda Chinganzi, and Qi (Quincy) Zhang\n",
        "\n",
        "1- Upload local weld images into Colab by choosing the zipped folder. This dataset has 2 classes (Good, and Bad). Images for each class are stored in its own folder.\n",
        "\n",
        "2- The images have dimensions of 576x300, 8-bit depth, .BMP format. Resize all of them to 150x150.\n",
        "\n",
        "3- Split images to 75-25% for training and test. Make sure you have the same distribution of Good/Bad weld  types between train and test datasets.\n",
        "\n",
        "4- Use a VGG16 model (pre-trained on ImageNet)\n",
        "\n",
        "5- Remove the top layers (fully connected layers)\n",
        "\n",
        "6- Add your own fully connected layers (one with 256 nodes using ‘relu’ activation and output layer with 2 nodes (2 classes - Good/Bad welds) and ‘softmax’ activation)\n",
        "\n",
        "7- First, freeze all layers of VGG16, train (fine-tune) and evaluate the model. You need to pick the right hyper-parameters for your training (try with different ones)\n",
        "\n",
        "8- Second, unfreeze the last block of VGG16 (block5), re-train and evaluate the model\n",
        "\n",
        "9- Unfreeze all the layers and try again.\n",
        "\n",
        "10- Compare the accuracy you got in both cases . Which one is better and why?"
      ],
      "metadata": {
        "id": "ASm4TnbDxKEy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tarfile\n",
        "import os\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import PIL.Image\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from keras.models import load_model\n",
        "from keras.models import Model\n",
        "from tensorflow.keras import applications\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from xgboost import XGBClassifier\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import StratifiedShuffleSplit"
      ],
      "metadata": {
        "id": "PCHWVS1ZRp8D"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "BJ3VAKLP4uM9",
        "outputId": "6519f8a3-4a13-4fd2-fc79-671372033de6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-60622b91-5949-44de-ab34-7e0a3d6f72cf\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-60622b91-5949-44de-ab34-7e0a3d6f72cf\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving ML3253.zip to ML3253.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import io\n",
        "data = zipfile.ZipFile(io.BytesIO(uploaded['ML3253.zip']), 'r')\n",
        "data.extractall()"
      ],
      "metadata": {
        "id": "f7z5oJY37EgG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "SyshsAjuB4WF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.printdir()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0JVp14T7Hii",
        "outputId": "4d1c3526-a3ba-4127-eee5-26e9337f35cd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File Name                                             Modified             Size\n",
            "BAD/                                           2022-03-12 17:20:20            0\n",
            "BAD/Img_SRRH_13_1_17_22.37.04_MIG16.BMP        2022-01-13 05:32:24       173878\n",
            "BAD/Img_SRRH_17_1_80_07.34.35_MIG16.BMP        2022-01-17 12:30:06       173878\n",
            "BAD/Img_SRRH_17_3_29_22.56.18_MIG16.BMP        2022-01-17 03:51:48       173878\n",
            "BAD/Img_SRRH_17_3_6_20.22.05_MIG16.BMP         2022-01-17 01:17:34       173878\n",
            "BAD/Img_SRRH_18_1_74_06.42.42_MIG16.BMP        2022-01-18 11:38:16       173878\n",
            "BAD/Img_SRRH_18_1_75_06.47.13_MIG16.BMP        2022-01-18 11:42:46       173878\n",
            "BAD/Img_SRRH_18_1_76_06.53.03_MIG16.BMP        2022-01-18 11:48:36       173878\n",
            "BAD/Img_SRRH_18_1_77_06.57.01_MIG16.BMP        2022-01-18 11:52:34       173878\n",
            "BAD/Img_SRRH_18_2_7_11.17.43_MIG16.BMP         2022-01-18 16:13:16       173878\n",
            "BAD/Img_SRRH_18_3_22_21.25.03_MIG16.BMP        2022-01-18 02:20:36       173878\n",
            "BAD/Img_SRRH_18_3_30_21.57.46_MIG16.BMP        2022-01-18 02:53:18       173878\n",
            "BAD/Img_SRRH_18_3_35_23.29.27_MIG16.BMP        2022-01-18 04:25:00       173878\n",
            "BAD/Img_SRRH_21_3_16_21.57.34_MIG16.BMP        2022-01-21 01:32:38       173878\n",
            "BAD/Img_SRRH_21_3_17_22.01.13_MIG16.BMP        2022-01-21 01:36:18       173878\n",
            "BAD/Img_SRRH_21_3_18_22.04.17_MIG16.BMP        2022-01-21 01:39:22       173878\n",
            "BAD/Img_SRRH_24_1_2_23.53.57_MIG16.BMP         2022-01-24 04:51:56       173878\n",
            "BAD/Img_SRRH_24_1_30_20.04.15_MIG16.BMP        2022-01-24 07:37:28       173878\n",
            "BAD/Img_SRRH_24_3_2_19.50.23_MIG16.BMP         2022-01-24 00:48:22       173878\n",
            "BAD/Img_SRRH_33_1_27_08.14.04_MIG16.BMP        2022-02-02 07:56:22       173878\n",
            "BAD/Img_SRRH_33_1_37_08.49.37_MIG16.BMP        2022-02-02 08:31:54       173878\n",
            "BAD/Img_SRRH_33_1_45_09.21.13_MIG16.BMP        2022-02-02 09:03:30       173878\n",
            "BAD/Img_SRRH_33_1_51_09.43.24_MIG16.BMP        2022-02-02 09:25:42       173878\n",
            "BAD/Img_SRRH_33_1_52_09.47.18_MIG16.BMP        2022-02-02 09:29:36       173878\n",
            "BAD/Img_SRRH_347_1_148_22.44.00_MIG16.BMP      2021-12-13 14:03:20       173878\n",
            "BAD/Img_SRRH_348_1_60_00.15.49_MIG16.BMP       2021-12-14 07:57:56       173878\n",
            "BAD/Img_SRRH_349_1_18_20.09.50_MIG16.BMP       2021-12-15 08:09:00       173878\n",
            "BAD/Img_SRRH_349_1_77_23.28.09_MIG16.BMP       2021-12-15 11:27:20       173878\n",
            "BAD/Img_SRRH_34_1_11_08.44.35_MIG16.BMP        2022-02-03 08:26:56       173878\n",
            "BAD/Img_SRRH_352_1_56_19.57.31_MIG16.BMP       2021-12-18 10:31:58       173878\n",
            "BAD/Img_SRRH_355_1_105_01.34.49_MIG16.BMP      2021-12-21 11:36:52       173878\n",
            "BAD/Img_SRRH_355_1_106_01.38.15_MIG16.BMP      2021-12-21 11:40:18       173878\n",
            "BAD/Img_SRRH_355_1_77_23.38.38_MIG16.BMP       2021-12-21 09:40:40       173878\n",
            "BAD/Img_SRRH_355_2_61_12.01.11_MIG16.BMP       2021-12-21 22:03:14       173878\n",
            "BAD/Img_SRRH_355_2_62_12.07.45_MIG16.BMP       2021-12-21 22:09:48       173878\n",
            "BAD/Img_SRRH_356_1_30_20.14.26_MIG16.BMP       2021-12-22 06:16:30       173878\n",
            "BAD/Img_SRRH_356_1_91_01.36.22_MIG16.BMP       2021-12-22 11:38:26       173878\n",
            "BAD/Img_SRRH_36_1_14_22.30.09_MIG16.BMP        2022-02-05 05:31:38       173878\n",
            "BAD/Img_SRRH_36_1_44_00.49.09_MIG16.BMP        2022-02-05 07:50:38       173878\n",
            "BAD/Img_SRRH_36_1_81_02.56.21_MIG16.BMP        2022-02-05 09:57:50       173878\n",
            "BAD/Img_SRRH_37_2_75_19.06.01_MIG16.BMP        2022-02-06 00:46:12       173878\n",
            "BAD/Img_SRRH_37_2_86_05.58.48_MIG16.BMP        2022-02-06 22:00:40       173878\n",
            "BAD/Img_SRRH_37_3_0_19.09.59_MIG16.BMP         2022-02-06 00:50:10       173878\n",
            "BAD/Img_SRRH_37_3_1_19.14.12_MIG16.BMP         2022-02-06 00:54:24       173878\n",
            "BAD/Img_SRRH_38_1_20_13.50.19_MIG16.BMP        2022-02-07 05:52:12       173878\n",
            "BAD/Img_SRRH_38_1_21_13.53.45_MIG16.BMP        2022-02-07 05:55:38       173878\n",
            "BAD/Img_SRRH_38_2_116_08.37.41_MIG16.BMP       2022-02-07 00:39:34       173878\n",
            "BAD/Img_SRRH_38_2_39_03.59.49_MIG16.BMP        2022-02-07 20:01:44       173878\n",
            "BAD/Img_SRRH_39_1_117_05.37.52_MIG16.BMP       2022-02-08 13:56:22       173878\n",
            "BAD/Img_SRRH_39_1_118_05.42.39_MIG16.BMP       2022-02-08 14:01:08       173878\n",
            "BAD/Img_SRRH_39_1_119_05.47.11_MIG16.BMP       2022-02-08 14:05:42       173878\n",
            "BAD/Img_SRRH_39_1_120_05.54.03_MIG16.BMP       2022-02-08 14:12:32       173878\n",
            "BAD/Img_SRRH_39_1_31_22.21.23_MIG16.BMP        2022-02-08 06:39:52       173878\n",
            "BAD/Img_SRRH_41_1_136_04.19.13_MIG16.BMP       2022-02-10 14:40:36       173878\n",
            "BAD/Img_SRRH_41_1_5_17.44.27_MIG16.BMP         2022-02-10 05:01:44       173878\n",
            "BAD/Img_SRRH_41_1_61_22.29.42_MIG16.BMP        2022-02-10 08:51:04       173878\n",
            "BAD/Img_SRRH_41_1_62_22.33.32_MIG16.BMP        2022-02-10 08:54:54       173878\n",
            "BAD/Img_SRRH_41_2_1_05.12.29_MIG16.BMP         2022-02-10 15:33:52       173878\n",
            "BAD/Img_SRRH_41_3_72_17.18.14_MIG16.BMP        2022-02-10 04:35:32       173878\n",
            "BAD/Img_SRRH_42_2_15_05.43.55_MIG16.BMP        2022-02-11 17:01:08       173878\n",
            "BAD/Img_SRRH_43_1_22_19.05.57_MIG16.BMP        2022-02-12 06:23:12       173878\n",
            "BAD/Img_SRRH_43_1_23_19.08.56_MIG16.BMP        2022-02-12 06:26:10       173878\n",
            "BAD/Img_SRRH_43_2_45_12.45.02_MIG16.BMP        2022-02-12 00:02:16       173878\n",
            "BAD/Img_SRRH_43_2_46_12.47.36_MIG16.BMP        2022-02-12 00:04:50       173878\n",
            "BAD/Img_SRRH_52_2_16_20.13.16_MIG16.BMP        2022-02-21 17:05:20       173878\n",
            "BAD/Img_SRRH_52_2_17_20.18.12_MIG16.BMP        2022-02-21 17:10:16       173878\n",
            "BAD/Img_SRRH_52_2_18_20.22.20_MIG16.BMP        2022-02-21 17:14:24       173878\n",
            "BAD/Img_SRRH_52_2_19_20.27.58_MIG16.BMP        2022-02-21 17:20:02       173878\n",
            "BAD/Img_SRRH_52_2_1_18.28.23_MIG16.BMP         2022-02-21 15:20:26       173878\n",
            "BAD/Img_SRRH_52_2_27_21.12.29_MIG16.BMP        2022-02-21 18:04:34       173878\n",
            "BAD/Img_SRRH_52_3_6_19.20.03_MIG16.BMP         2022-02-21 16:12:06       173878\n",
            "BAD/Img_SRRH_53_1_14_08.38.35_MIG16.BMP        2022-02-22 05:30:40       173878\n",
            "BAD/Img_SRRH_53_2_29_08.49.11_MIG16.BMP        2022-02-22 19:48:26       173878\n",
            "BAD/Img_SRRH_53_2_44_10.09.05_MIG16.BMP        2022-02-22 21:08:20       173878\n",
            "BAD/Img_SRRH_54_3_45_16.42.14_MIG16.BMP        2022-02-23 03:41:30       173878\n",
            "BAD/Img_SRRH_55_1_50_03.30.40_MIG16.BMP        2022-02-24 08:49:24       173878\n",
            "BAD/Img_SRRH_55_1_59_04.35.38_MIG16.BMP        2022-02-24 09:54:22       173878\n",
            "BAD/Img_SRRH_55_1_73_05.24.18_MIG16.BMP        2022-02-24 10:43:02       173878\n",
            "BAD/Img_SRRH_55_1_74_05.29.04_MIG16.BMP        2022-02-24 10:47:48       173878\n",
            "BAD/Img_SRRH_55_2_25_22.19.35_MIG16.BMP        2022-02-24 17:45:08       173878\n",
            "BAD/Img_SRRH_55_2_83_02.16.02_MIG16.BMP        2022-02-23 23:57:04       173878\n",
            "BAD/Img_SRRH_55_2_8_20.33.51_MIG16.BMP         2022-02-24 15:59:24       173878\n",
            "BAD/Img_SRRH_55_3_31_21.03.39_MIG16.BMP        2022-02-24 02:22:24       173878\n",
            "BAD/Img_SRRH_55_3_51_22.41.03_MIG16.BMP        2022-02-24 03:59:48       173878\n",
            "BAD/Img_SRRH_55_3_52_22.43.51_MIG16.BMP        2022-02-24 04:02:36       173878\n",
            "BAD/Img_SRRH_57_1_24_08.57.53_MIG16.BMP        2022-02-26 08:56:38       173878\n",
            "BAD/Img_SRRH_57_1_25_09.09.19_MIG16.BMP        2022-02-26 09:08:02       173878\n",
            "BAD/Img_SRRH_57_1_26_09.21.01_MIG16.BMP        2022-02-26 09:19:44       173878\n",
            "BAD/Img_SRRH_57_3_16_02.09.31_MIG16.BMP        2022-02-26 02:08:14       173878\n",
            "BAD/Img_SRRH_57_3_9_01.38.48_MIG16.BMP         2022-02-26 01:37:30       173878\n",
            "BAD/Img_SRRH_62_1_120_02.15.53_MIG16.BMP       2022-03-03 13:53:38       173878\n",
            "BAD/Img_SRRH_67_1_110_03.45.30_MIG16.BMP       2022-03-08 11:21:50       173878\n",
            "BAD/Img_SRRH_67_1_131_05.09.57_MIG16.BMP       2022-03-08 12:46:18       173878\n",
            "BAD/Img_SRRH_67_2_34_11.12.44_MIG16.BMP        2022-03-08 18:49:06       173878\n",
            "BAD/Img_SRRH_68_1_124_03.39.11_MIG16.BMP       2022-03-09 11:15:34       173878\n",
            "BAD/Img_SRRH_68_1_126_03.46.25_MIG16.BMP       2022-03-09 11:22:50       173878\n",
            "BAD/Img_SRRH_68_1_127_03.49.18_MIG16.BMP       2022-03-09 11:25:42       173878\n",
            "BAD/Img_SRRH_68_1_146_05.25.17_MIG16.BMP       2022-03-09 13:01:36       173878\n",
            "BAD/Img_SRRH_68_1_151_05.28.11_MIG16.BMP       2022-03-09 13:04:30       173878\n",
            "BAD/Img_SRRH_68_1_53_00.08.51_MIG16.BMP        2022-03-09 07:45:16       173878\n",
            "BAD/Img_SRRH_68_1_61_00.38.09_MIG16.BMP        2022-03-09 08:14:34       173878\n",
            "BAD/Img_SRRH_68_1_90_02.01.58_MIG16.BMP        2022-03-09 09:38:22       173878\n",
            "BAD/Img_SRRH_68_1_96_02.18.47_MIG16.BMP        2022-03-09 09:55:12       173878\n",
            "BAD/Img_SRRH_69_1_34_22.48.07_MIG16.BMP        2022-03-10 07:24:28       173878\n",
            "BAD/Img_SRRH_69_2_83_22.38.42_MIG16.BMP        2022-03-10 23:30:46       173878\n",
            "BAD/Img_SRRH_70_1_48_03.22.20_MIG16.BMP        2022-03-11 08:15:06       173878\n",
            "BAD/Img_SRRH_70_1_56_03.46.06_MIG16.BMP        2022-03-11 08:38:52       173878\n",
            "BAD/Img_SRRH_70_1_59_03.54.20_MIG16.BMP        2022-03-11 08:47:06       173878\n",
            "BAD/Img_SRRH_70_1_73_19.04.57_MIG16.BMP        2022-03-11 10:02:18       173878\n",
            "GOOD/                                          2022-03-12 22:30:30            0\n",
            "GOOD/Img_SRRH_17_1_0_23.52.33_MIG16.BMP        2022-01-17 04:48:04       173878\n",
            "GOOD/Img_SRRH_17_1_11_01.00.03_MIG16.BMP       2022-01-17 05:55:32       173878\n",
            "GOOD/Img_SRRH_17_1_12_01.03.53_MIG16.BMP       2022-01-17 05:59:24       173878\n",
            "GOOD/Img_SRRH_17_1_14_01.13.05_MIG16.BMP       2022-01-17 06:08:34       173878\n",
            "GOOD/Img_SRRH_17_1_15_01.18.44_MIG16.BMP       2022-01-17 06:14:14       173878\n",
            "GOOD/Img_SRRH_17_1_16_01.24.35_MIG16.BMP       2022-01-17 06:20:04       173878\n",
            "GOOD/Img_SRRH_17_1_17_01.28.12_MIG16.BMP       2022-01-17 06:23:42       173878\n",
            "GOOD/Img_SRRH_17_1_18_01.32.39_MIG16.BMP       2022-01-17 06:28:08       173878\n",
            "GOOD/Img_SRRH_17_1_19_01.37.40_MIG16.BMP       2022-01-17 06:33:10       173878\n",
            "GOOD/Img_SRRH_17_1_1_00.06.58_MIG16.BMP        2022-01-17 05:02:28       173878\n",
            "GOOD/Img_SRRH_17_1_21_02.33.46_MIG16.BMP       2022-01-17 07:29:16       173878\n",
            "GOOD/Img_SRRH_17_1_22_02.42.48_MIG16.BMP       2022-01-17 07:38:18       173878\n",
            "GOOD/Img_SRRH_17_1_23_02.47.13_MIG16.BMP       2022-01-17 07:42:44       173878\n",
            "GOOD/Img_SRRH_17_1_24_02.51.35_MIG16.BMP       2022-01-17 07:47:06       173878\n",
            "GOOD/Img_SRRH_17_1_25_02.54.51_MIG16.BMP       2022-01-17 07:50:22       173878\n",
            "GOOD/Img_SRRH_17_1_26_02.58.05_MIG16.BMP       2022-01-17 07:53:36       173878\n",
            "GOOD/Img_SRRH_17_1_27_03.01.00_MIG16.BMP       2022-01-17 07:56:30       173878\n",
            "GOOD/Img_SRRH_17_1_28_03.04.25_MIG16.BMP       2022-01-17 07:59:56       173878\n",
            "GOOD/Img_SRRH_17_1_29_03.20.44_MIG16.BMP       2022-01-17 08:16:14       173878\n",
            "GOOD/Img_SRRH_17_1_30_03.24.38_MIG16.BMP       2022-01-17 08:20:08       173878\n",
            "GOOD/Img_SRRH_17_1_31_03.29.03_MIG16.BMP       2022-01-17 08:24:34       173878\n",
            "GOOD/Img_SRRH_17_1_32_03.32.59_MIG16.BMP       2022-01-17 08:28:30       173878\n",
            "GOOD/Img_SRRH_17_1_33_03.36.33_MIG16.BMP       2022-01-17 08:32:04       173878\n",
            "GOOD/Img_SRRH_17_1_34_03.43.26_MIG16.BMP       2022-01-17 08:38:56       173878\n",
            "GOOD/Img_SRRH_17_1_35_03.48.22_MIG16.BMP       2022-01-17 08:43:52       173878\n",
            "GOOD/Img_SRRH_17_1_36_03.51.27_MIG16.BMP       2022-01-17 08:46:58       173878\n",
            "GOOD/Img_SRRH_17_1_37_03.54.51_MIG16.BMP       2022-01-17 08:50:22       173878\n",
            "GOOD/Img_SRRH_17_1_38_03.58.09_MIG16.BMP       2022-01-17 08:53:40       173878\n",
            "GOOD/Img_SRRH_17_1_39_04.01.17_MIG16.BMP       2022-01-17 08:56:48       173878\n",
            "GOOD/Img_SRRH_17_1_3_00.18.39_MIG16.BMP        2022-01-17 05:14:10       173878\n",
            "GOOD/Img_SRRH_17_1_40_04.04.18_MIG16.BMP       2022-01-17 08:59:48       173878\n",
            "GOOD/Img_SRRH_17_1_41_04.08.22_MIG16.BMP       2022-01-17 09:03:52       173878\n",
            "GOOD/Img_SRRH_17_1_42_04.11.06_MIG16.BMP       2022-01-17 09:06:36       173878\n",
            "GOOD/Img_SRRH_17_1_43_04.15.27_MIG16.BMP       2022-01-17 09:10:58       173878\n",
            "GOOD/Img_SRRH_17_1_44_04.18.58_MIG16.BMP       2022-01-17 09:14:28       173878\n",
            "GOOD/Img_SRRH_17_1_45_04.23.04_MIG16.BMP       2022-01-17 09:18:34       173878\n",
            "GOOD/Img_SRRH_17_1_46_04.26.48_MIG16.BMP       2022-01-17 09:22:18       173878\n",
            "GOOD/Img_SRRH_17_1_47_04.31.25_MIG16.BMP       2022-01-17 09:26:56       173878\n",
            "GOOD/Img_SRRH_17_1_48_04.34.51_MIG16.BMP       2022-01-17 09:30:22       173878\n",
            "GOOD/Img_SRRH_17_1_49_04.38.24_MIG16.BMP       2022-01-17 09:33:54       173878\n",
            "GOOD/Img_SRRH_17_1_4_00.27.16_MIG16.BMP        2022-01-17 05:22:46       173878\n",
            "GOOD/Img_SRRH_17_1_50_04.46.35_MIG16.BMP       2022-01-17 09:42:06       173878\n",
            "GOOD/Img_SRRH_17_1_51_04.50.07_MIG16.BMP       2022-01-17 09:45:38       173878\n",
            "GOOD/Img_SRRH_17_1_52_04.53.50_MIG16.BMP       2022-01-17 09:49:20       173878\n",
            "GOOD/Img_SRRH_17_1_53_04.56.59_MIG16.BMP       2022-01-17 09:52:30       173878\n",
            "GOOD/Img_SRRH_17_1_54_05.00.52_MIG16.BMP       2022-01-17 09:56:22       173878\n",
            "GOOD/Img_SRRH_17_1_55_05.04.38_MIG16.BMP       2022-01-17 10:00:08       173878\n",
            "GOOD/Img_SRRH_17_1_5_00.31.25_MIG16.BMP        2022-01-17 05:26:56       173878\n",
            "GOOD/Img_SRRH_17_1_6_00.34.39_MIG16.BMP        2022-01-17 05:30:10       173878\n",
            "GOOD/Img_SRRH_17_1_7_00.38.42_MIG16.BMP        2022-01-17 05:34:12       173878\n",
            "GOOD/Img_SRRH_17_1_8_00.45.51_MIG16.BMP        2022-01-17 05:41:20       173878\n",
            "GOOD/Img_SRRH_17_1_9_00.51.58_MIG16.BMP        2022-01-17 05:47:28       173878\n",
            "GOOD/Img_SRRH_17_2_10_19.44.08_MIG16.BMP       2022-01-17 00:39:38       173878\n",
            "GOOD/Img_SRRH_17_2_6_19.20.59_MIG16.BMP        2022-01-17 00:16:28       173878\n",
            "GOOD/Img_SRRH_17_2_7_19.25.44_MIG16.BMP        2022-01-17 00:21:14       173878\n",
            "GOOD/Img_SRRH_17_2_8_19.29.13_MIG16.BMP        2022-01-17 00:24:42       173878\n",
            "GOOD/Img_SRRH_17_2_9_19.33.22_MIG16.BMP        2022-01-17 00:28:52       173878\n",
            "GOOD/Img_SRRH_17_3_0_19.49.48_MIG16.BMP        2022-01-17 00:45:18       173878\n",
            "GOOD/Img_SRRH_17_3_10_20.47.33_MIG16.BMP       2022-01-17 01:43:02       173878\n",
            "GOOD/Img_SRRH_17_3_11_20.51.15_MIG16.BMP       2022-01-17 01:46:44       173878\n",
            "GOOD/Img_SRRH_17_3_12_20.55.38_MIG16.BMP       2022-01-17 01:51:08       173878\n",
            "GOOD/Img_SRRH_17_3_13_20.58.54_MIG16.BMP       2022-01-17 01:54:24       173878\n",
            "GOOD/Img_SRRH_17_3_14_21.02.34_MIG16.BMP       2022-01-17 01:58:04       173878\n",
            "GOOD/Img_SRRH_17_3_15_21.06.11_MIG16.BMP       2022-01-17 02:01:40       173878\n",
            "GOOD/Img_SRRH_17_3_16_21.10.06_MIG16.BMP       2022-01-17 02:05:36       173878\n",
            "GOOD/Img_SRRH_17_3_17_21.13.47_MIG16.BMP       2022-01-17 02:09:16       173878\n",
            "GOOD/Img_SRRH_17_3_18_21.17.32_MIG16.BMP       2022-01-17 02:13:02       173878\n",
            "GOOD/Img_SRRH_17_3_19_21.23.37_MIG16.BMP       2022-01-17 02:19:06       173878\n",
            "GOOD/Img_SRRH_17_3_1_20.00.03_MIG16.BMP        2022-01-17 00:55:32       173878\n",
            "GOOD/Img_SRRH_17_3_20_21.28.34_MIG16.BMP       2022-01-17 02:24:04       173878\n",
            "GOOD/Img_SRRH_17_3_21_21.32.55_MIG16.BMP       2022-01-17 02:28:24       173878\n",
            "GOOD/Img_SRRH_17_3_22_21.36.13_MIG16.BMP       2022-01-17 02:31:44       173878\n",
            "GOOD/Img_SRRH_17_3_23_21.43.28_MIG16.BMP       2022-01-17 02:38:58       173878\n",
            "GOOD/Img_SRRH_17_3_24_21.47.46_MIG16.BMP       2022-01-17 02:43:16       173878\n",
            "GOOD/Img_SRRH_17_3_25_21.51.20_MIG16.BMP       2022-01-17 02:46:50       173878\n",
            "GOOD/Img_SRRH_17_3_26_21.56.18_MIG16.BMP       2022-01-17 02:51:48       173878\n",
            "GOOD/Img_SRRH_17_3_27_22.04.25_MIG16.BMP       2022-01-17 02:59:54       173878\n",
            "GOOD/Img_SRRH_17_3_28_22.51.16_MIG16.BMP       2022-01-17 03:46:46       173878\n",
            "GOOD/Img_SRRH_17_3_2_20.04.25_MIG16.BMP        2022-01-17 00:59:54       173878\n",
            "GOOD/Img_SRRH_17_3_30_23.00.08_MIG16.BMP       2022-01-17 03:55:38       173878\n",
            "GOOD/Img_SRRH_17_3_31_23.09.09_MIG16.BMP       2022-01-17 04:04:38       173878\n",
            "GOOD/Img_SRRH_17_3_32_23.12.59_MIG16.BMP       2022-01-17 04:08:30       173878\n",
            "GOOD/Img_SRRH_17_3_33_23.17.17_MIG16.BMP       2022-01-17 04:12:48       173878\n",
            "GOOD/Img_SRRH_17_3_34_23.21.08_MIG16.BMP       2022-01-17 04:16:38       173878\n",
            "GOOD/Img_SRRH_17_3_35_23.24.54_MIG16.BMP       2022-01-17 04:20:24       173878\n",
            "GOOD/Img_SRRH_17_3_36_23.30.36_MIG16.BMP       2022-01-17 04:26:06       173878\n",
            "GOOD/Img_SRRH_17_3_37_23.35.26_MIG16.BMP       2022-01-17 04:30:56       173878\n",
            "GOOD/Img_SRRH_17_3_38_23.40.46_MIG16.BMP       2022-01-17 04:36:16       173878\n",
            "GOOD/Img_SRRH_17_3_39_23.48.54_MIG16.BMP       2022-01-17 04:44:24       173878\n",
            "GOOD/Img_SRRH_17_3_3_20.10.10_MIG16.BMP        2022-01-17 01:05:40       173878\n",
            "GOOD/Img_SRRH_17_3_4_20.14.33_MIG16.BMP        2022-01-17 01:10:02       173878\n",
            "GOOD/Img_SRRH_17_3_5_20.18.26_MIG16.BMP        2022-01-17 01:13:56       173878\n",
            "GOOD/Img_SRRH_17_3_7_20.27.15_MIG16.BMP        2022-01-17 01:22:44       173878\n",
            "GOOD/Img_SRRH_17_3_8_20.34.56_MIG16.BMP        2022-01-17 01:30:26       173878\n",
            "GOOD/Img_SRRH_17_3_9_20.42.54_MIG16.BMP        2022-01-17 01:38:24       173878\n",
            "GOOD/Img_SRRH_31_1_100_06.24.59_MIG16.BMP      2022-01-31 11:44:54       173878\n",
            "GOOD/Img_SRRH_31_1_101_06.28.46_MIG16.BMP      2022-01-31 11:48:40       173878\n",
            "GOOD/Img_SRRH_31_1_102_06.32.05_MIG16.BMP      2022-01-31 11:52:00       173878\n",
            "GOOD/Img_SRRH_31_1_103_06.35.47_MIG16.BMP      2022-01-31 11:55:42       173878\n",
            "GOOD/Img_SRRH_31_1_104_06.38.57_MIG16.BMP      2022-01-31 11:58:52       173878\n",
            "GOOD/Img_SRRH_31_1_105_06.43.43_MIG16.BMP      2022-01-31 12:03:38       173878\n",
            "GOOD/Img_SRRH_31_1_106_07.06.25_MIG16.BMP      2022-01-31 12:26:20       173878\n",
            "GOOD/Img_SRRH_31_1_107_07.10.09_MIG16.BMP      2022-01-31 12:30:04       173878\n",
            "GOOD/Img_SRRH_31_1_108_07.14.19_MIG16.BMP      2022-01-31 12:34:14       173878\n",
            "GOOD/Img_SRRH_31_1_109_07.18.18_MIG16.BMP      2022-01-31 12:38:12       173878\n",
            "GOOD/Img_SRRH_31_1_10_23.53.17_MIG16.BMP       2022-01-31 05:13:12       173878\n",
            "GOOD/Img_SRRH_31_1_110_07.22.02_MIG16.BMP      2022-01-31 12:41:56       173878\n",
            "GOOD/Img_SRRH_31_1_111_07.26.24_MIG16.BMP      2022-01-31 12:46:18       173878\n",
            "GOOD/Img_SRRH_31_1_112_07.30.36_MIG16.BMP      2022-01-31 12:50:30       173878\n",
            "GOOD/Img_SRRH_31_1_113_07.34.34_MIG16.BMP      2022-01-31 12:54:28       173878\n",
            "GOOD/Img_SRRH_31_1_114_07.38.36_MIG16.BMP      2022-01-31 12:58:30       173878\n",
            "GOOD/Img_SRRH_31_1_115_07.42.59_MIG16.BMP      2022-01-31 13:02:54       173878\n",
            "GOOD/Img_SRRH_31_1_116_07.53.43_MIG16.BMP      2022-01-31 13:13:38       173878\n",
            "GOOD/Img_SRRH_31_1_117_07.58.23_MIG16.BMP      2022-01-31 13:18:18       173878\n",
            "GOOD/Img_SRRH_31_1_118_08.04.22_MIG16.BMP      2022-01-31 13:24:16       173878\n",
            "GOOD/Img_SRRH_31_1_119_08.15.14_MIG16.BMP      2022-01-31 13:35:10       173878\n",
            "GOOD/Img_SRRH_31_1_11_23.56.02_MIG16.BMP       2022-01-31 05:15:56       173878\n",
            "GOOD/Img_SRRH_31_1_120_08.20.30_MIG16.BMP      2022-01-31 13:40:24       173878\n",
            "GOOD/Img_SRRH_31_1_121_08.24.17_MIG16.BMP      2022-01-31 13:44:12       173878\n",
            "GOOD/Img_SRRH_31_1_122_08.28.03_MIG16.BMP      2022-01-31 13:47:58       173878\n",
            "GOOD/Img_SRRH_31_1_123_08.31.25_MIG16.BMP      2022-01-31 13:51:20       173878\n",
            "GOOD/Img_SRRH_31_1_124_08.35.24_MIG16.BMP      2022-01-31 13:55:20       173878\n",
            "GOOD/Img_SRRH_31_1_125_08.38.29_MIG16.BMP      2022-01-31 13:58:24       173878\n",
            "GOOD/Img_SRRH_31_1_126_08.43.20_MIG16.BMP      2022-01-31 14:03:14       173878\n",
            "GOOD/Img_SRRH_31_1_127_08.47.04_MIG16.BMP      2022-01-31 14:06:58       173878\n",
            "GOOD/Img_SRRH_31_1_128_08.51.18_MIG16.BMP      2022-01-31 14:11:12       173878\n",
            "GOOD/Img_SRRH_31_1_12_23.59.00_MIG16.BMP       2022-01-31 05:18:54       173878\n",
            "GOOD/Img_SRRH_31_1_130_08.55.02_MIG16.BMP      2022-01-31 14:14:56       173878\n",
            "GOOD/Img_SRRH_31_1_130_08.58.22_MIG16.BMP      2022-01-31 14:18:18       173878\n",
            "GOOD/Img_SRRH_31_1_131_09.03.39_MIG16.BMP      2022-01-31 14:23:34       173878\n",
            "GOOD/Img_SRRH_31_1_132_09.20.07_MIG16.BMP      2022-01-31 14:40:02       173878\n",
            "GOOD/Img_SRRH_31_1_13_00.02.12_MIG16.BMP       2022-01-31 05:22:06       173878\n",
            "GOOD/Img_SRRH_31_1_13_11.37.37_MIG16.BMP       2022-01-31 16:57:32       173878\n",
            "GOOD/Img_SRRH_31_1_14_00.04.45_MIG16.BMP       2022-01-31 05:24:38       173878\n",
            "GOOD/Img_SRRH_31_1_15_00.07.50_MIG16.BMP       2022-01-31 05:27:44       173878\n",
            "GOOD/Img_SRRH_31_1_16_00.10.58_MIG16.BMP       2022-01-31 05:30:52       173878\n",
            "GOOD/Img_SRRH_31_1_17_00.14.59_MIG16.BMP       2022-01-31 05:34:52       173878\n",
            "GOOD/Img_SRRH_31_1_18_00.18.49_MIG16.BMP       2022-01-31 05:38:42       173878\n",
            "GOOD/Img_SRRH_31_1_19_00.21.43_MIG16.BMP       2022-01-31 05:41:36       173878\n",
            "GOOD/Img_SRRH_31_1_19_12.07.12_MIG16.BMP       2022-01-31 17:27:06       173878\n",
            "GOOD/Img_SRRH_31_1_20_00.27.32_MIG16.BMP       2022-01-31 05:47:26       173878\n",
            "GOOD/Img_SRRH_31_1_21_00.30.48_MIG16.BMP       2022-01-31 05:50:42       173878\n",
            "GOOD/Img_SRRH_31_1_23_00.33.21_MIG16.BMP       2022-01-31 05:53:16       173878\n",
            "GOOD/Img_SRRH_31_1_25_00.39.03_MIG16.BMP       2022-01-31 05:58:56       173878\n",
            "GOOD/Img_SRRH_31_1_26_00.41.43_MIG16.BMP       2022-01-31 06:01:36       173878\n",
            "GOOD/Img_SRRH_31_1_26_12.38.37_MIG16.BMP       2022-01-31 17:58:32       173878\n",
            "GOOD/Img_SRRH_31_1_27_00.44.11_MIG16.BMP       2022-01-31 06:04:06       173878\n",
            "GOOD/Img_SRRH_31_1_28_00.46.37_MIG16.BMP       2022-01-31 06:06:30       173878\n",
            "GOOD/Img_SRRH_31_1_29_00.49.53_MIG16.BMP       2022-01-31 06:09:48       173878\n",
            "GOOD/Img_SRRH_31_1_2_23.30.43_MIG16.BMP        2022-01-31 04:50:36       173878\n",
            "GOOD/Img_SRRH_31_1_30_00.53.18_MIG16.BMP       2022-01-31 06:13:12       173878\n",
            "GOOD/Img_SRRH_31_1_31_13.09.01_MIG16.BMP       2022-01-31 18:28:56       173878\n",
            "GOOD/Img_SRRH_31_1_32_00.57.54_MIG16.BMP       2022-01-31 06:17:48       173878\n",
            "GOOD/Img_SRRH_31_1_33_01.00.41_MIG16.BMP       2022-01-31 06:20:34       173878\n",
            "GOOD/Img_SRRH_31_1_34_01.03.59_MIG16.BMP       2022-01-31 06:23:54       173878\n",
            "GOOD/Img_SRRH_31_1_34_13.22.50_MIG16.BMP       2022-01-31 18:42:44       173878\n",
            "GOOD/Img_SRRH_31_1_35_01.06.43_MIG16.BMP       2022-01-31 06:26:38       173878\n",
            "GOOD/Img_SRRH_31_1_36_01.09.57_MIG16.BMP       2022-01-31 06:29:52       173878\n",
            "GOOD/Img_SRRH_31_1_38_02.01.37_MIG16.BMP       2022-01-31 07:21:30       173878\n",
            "GOOD/Img_SRRH_31_1_39_02.05.18_MIG16.BMP       2022-01-31 07:25:12       173878\n",
            "GOOD/Img_SRRH_31_1_3_23.33.21_MIG16.BMP        2022-01-31 04:53:14       173878\n",
            "GOOD/Img_SRRH_31_1_40_02.12.34_MIG16.BMP       2022-01-31 07:32:28       173878\n",
            "GOOD/Img_SRRH_31_1_40_14.43.43_MIG16.BMP       2022-01-31 20:03:38       173878\n",
            "GOOD/Img_SRRH_31_1_41_02.15.32_MIG16.BMP       2022-01-31 07:35:26       173878\n",
            "GOOD/Img_SRRH_31_1_42_02.18.28_MIG16.BMP       2022-01-31 07:38:22       173878\n",
            "GOOD/Img_SRRH_31_1_44_02.22.26_MIG16.BMP       2022-01-31 07:42:20       173878\n",
            "GOOD/Img_SRRH_31_1_44_15.00.52_MIG16.BMP       2022-01-31 20:20:46       173878\n",
            "GOOD/Img_SRRH_31_1_45_02.25.51_MIG16.BMP       2022-01-31 07:45:46       173878\n",
            "GOOD/Img_SRRH_31_1_45_02.29.01_MIG16.BMP       2022-01-31 07:48:54       173878\n",
            "GOOD/Img_SRRH_31_1_46_02.33.45_MIG16.BMP       2022-01-31 07:53:40       173878\n",
            "GOOD/Img_SRRH_31_1_47_02.36.54_MIG16.BMP       2022-01-31 07:56:48       173878\n",
            "GOOD/Img_SRRH_31_1_47_15.13.50_MIG16.BMP       2022-01-31 20:33:46       173878\n",
            "GOOD/Img_SRRH_31_1_48_02.40.06_MIG16.BMP       2022-01-31 08:00:00       173878\n",
            "GOOD/Img_SRRH_31_1_49_02.43.32_MIG16.BMP       2022-01-31 08:03:26       173878\n",
            "GOOD/Img_SRRH_31_1_4_23.36.15_MIG16.BMP        2022-01-31 04:56:08       173878\n",
            "GOOD/Img_SRRH_31_1_50_02.54.03_MIG16.BMP       2022-01-31 08:13:58       173878\n",
            "GOOD/Img_SRRH_31_1_50_15.54.34_MIG16.BMP       2022-01-31 21:14:30       173878\n",
            "GOOD/Img_SRRH_31_1_51_02.57.16_MIG16.BMP       2022-01-31 08:17:10       173878\n",
            "GOOD/Img_SRRH_31_1_52_03.02.07_MIG16.BMP       2022-01-31 08:22:02       173878\n",
            "GOOD/Img_SRRH_31_1_53_03.06.32_MIG16.BMP       2022-01-31 08:26:26       173878\n",
            "GOOD/Img_SRRH_31_1_54_03.10.14_MIG16.BMP       2022-01-31 08:30:08       173878\n",
            "GOOD/Img_SRRH_31_1_54_16.25.23_MIG16.BMP       2022-01-31 21:45:18       173878\n",
            "GOOD/Img_SRRH_31_1_55_03.13.44_MIG16.BMP       2022-01-31 08:33:38       173878\n",
            "GOOD/Img_SRRH_31_1_56_03.16.52_MIG16.BMP       2022-01-31 08:36:46       173878\n",
            "GOOD/Img_SRRH_31_1_57_03.20.05_MIG16.BMP       2022-01-31 08:40:00       173878\n",
            "GOOD/Img_SRRH_31_1_58_03.23.06_MIG16.BMP       2022-01-31 08:43:00       173878\n",
            "GOOD/Img_SRRH_31_1_59_03.27.00_MIG16.BMP       2022-01-31 08:46:54       173878\n",
            "GOOD/Img_SRRH_31_1_5_23.39.29_MIG16.BMP        2022-01-31 04:59:22       173878\n",
            "GOOD/Img_SRRH_31_1_60_03.30.39_MIG16.BMP       2022-01-31 08:50:34       173878\n",
            "GOOD/Img_SRRH_31_1_61_03.33.56_MIG16.BMP       2022-01-31 08:53:50       173878\n",
            "GOOD/Img_SRRH_31_1_62_03.37.23_MIG16.BMP       2022-01-31 08:57:18       173878\n",
            "GOOD/Img_SRRH_31_1_63_03.40.46_MIG16.BMP       2022-01-31 09:00:40       173878\n",
            "GOOD/Img_SRRH_31_1_64_03.46.45_MIG16.BMP       2022-01-31 09:06:40       173878\n",
            "GOOD/Img_SRRH_31_1_65_03.50.32_MIG16.BMP       2022-01-31 09:10:26       173878\n",
            "GOOD/Img_SRRH_31_1_66_03.59.24_MIG16.BMP       2022-01-31 09:19:18       173878\n",
            "GOOD/Img_SRRH_31_1_67_04.02.40_MIG16.BMP       2022-01-31 09:22:34       173878\n",
            "GOOD/Img_SRRH_31_1_68_04.12.37_MIG16.BMP       2022-01-31 09:32:32       173878\n",
            "GOOD/Img_SRRH_31_1_69_04.17.29_MIG16.BMP       2022-01-31 09:37:22       173878\n",
            "GOOD/Img_SRRH_31_1_6_23.42.03_MIG16.BMP        2022-01-31 05:01:58       173878\n",
            "GOOD/Img_SRRH_31_1_70_04.21.46_MIG16.BMP       2022-01-31 09:41:40       173878\n",
            "GOOD/Img_SRRH_31_1_71_04.26.24_MIG16.BMP       2022-01-31 09:46:18       173878\n",
            "GOOD/Img_SRRH_31_1_72_04.29.43_MIG16.BMP       2022-01-31 09:49:38       173878\n",
            "GOOD/Img_SRRH_31_1_73_04.33.49_MIG16.BMP       2022-01-31 09:53:44       173878\n",
            "GOOD/Img_SRRH_31_1_74_04.42.08_MIG16.BMP       2022-01-31 10:02:02       173878\n",
            "GOOD/Img_SRRH_31_1_75_04.45.33_MIG16.BMP       2022-01-31 10:05:26       173878\n",
            "GOOD/Img_SRRH_31_1_76_04.49.28_MIG16.BMP       2022-01-31 10:09:22       173878\n",
            "GOOD/Img_SRRH_31_1_77_04.52.52_MIG16.BMP       2022-01-31 10:12:46       173878\n",
            "GOOD/Img_SRRH_31_1_78_04.59.20_MIG16.BMP       2022-01-31 10:19:14       173878\n",
            "GOOD/Img_SRRH_31_1_79_05.02.35_MIG16.BMP       2022-01-31 10:22:28       173878\n",
            "GOOD/Img_SRRH_31_1_7_23.44.30_MIG16.BMP        2022-01-31 05:04:24       173878\n",
            "GOOD/Img_SRRH_31_1_80_05.06.06_MIG16.BMP       2022-01-31 10:26:00       173878\n",
            "GOOD/Img_SRRH_31_1_81_05.09.29_MIG16.BMP       2022-01-31 10:29:24       173878\n",
            "GOOD/Img_SRRH_31_1_82_05.15.21_MIG16.BMP       2022-01-31 10:35:16       173878\n",
            "GOOD/Img_SRRH_31_1_83_05.20.49_MIG16.BMP       2022-01-31 10:40:44       173878\n",
            "GOOD/Img_SRRH_31_1_84_05.24.24_MIG16.BMP       2022-01-31 10:44:18       173878\n",
            "GOOD/Img_SRRH_31_1_85_05.28.09_MIG16.BMP       2022-01-31 10:48:02       173878\n",
            "GOOD/Img_SRRH_31_1_86_05.31.52_MIG16.BMP       2022-01-31 10:51:46       173878\n",
            "GOOD/Img_SRRH_31_1_87_05.34.59_MIG16.BMP       2022-01-31 10:54:54       173878\n",
            "GOOD/Img_SRRH_31_1_88_05.38.35_MIG16.BMP       2022-01-31 10:58:30       173878\n",
            "GOOD/Img_SRRH_31_1_89_05.46.29_MIG16.BMP       2022-01-31 11:06:24       173878\n",
            "GOOD/Img_SRRH_31_1_8_23.47.07_MIG16.BMP        2022-01-31 05:07:00       173878\n",
            "GOOD/Img_SRRH_31_1_90_05.50.59_MIG16.BMP       2022-01-31 11:10:54       173878\n",
            "GOOD/Img_SRRH_31_1_91_05.55.31_MIG16.BMP       2022-01-31 11:15:26       173878\n",
            "GOOD/Img_SRRH_31_1_92_05.58.25_MIG16.BMP       2022-01-31 11:18:20       173878\n",
            "GOOD/Img_SRRH_31_1_93_06.01.21_MIG16.BMP       2022-01-31 11:21:16       173878\n",
            "GOOD/Img_SRRH_31_1_94_06.04.35_MIG16.BMP       2022-01-31 11:24:30       173878\n",
            "GOOD/Img_SRRH_31_1_95_06.07.38_MIG16.BMP       2022-01-31 11:27:32       173878\n",
            "GOOD/Img_SRRH_31_1_96_06.11.21_MIG16.BMP       2022-01-31 11:31:16       173878\n",
            "GOOD/Img_SRRH_31_1_97_06.14.47_MIG16.BMP       2022-01-31 11:34:42       173878\n",
            "GOOD/Img_SRRH_31_1_98_06.18.21_MIG16.BMP       2022-01-31 11:38:16       173878\n",
            "GOOD/Img_SRRH_31_1_99_06.21.38_MIG16.BMP       2022-01-31 11:41:32       173878\n",
            "GOOD/Img_SRRH_31_1_9_23.49.56_MIG16.BMP        2022-01-31 05:09:50       173878\n",
            "GOOD/Img_SRRH_31_2_0_10.02.23_MIG16.BMP        2022-01-31 15:22:18       173878\n",
            "GOOD/Img_SRRH_31_2_10_02.13.28_MIG16.BMP       2022-01-31 00:01:20       173878\n",
            "GOOD/Img_SRRH_31_2_10_02.17.20_MIG16.BMP       2022-01-31 00:05:14       173878\n",
            "GOOD/Img_SRRH_31_2_10_10.58.54_MIG16.BMP       2022-01-31 16:18:48       173878\n",
            "GOOD/Img_SRRH_31_2_11_02.20.54_MIG16.BMP       2022-01-31 00:08:48       173878\n",
            "GOOD/Img_SRRH_31_2_11_11.25.53_MIG16.BMP       2022-01-31 16:45:48       173878\n",
            "GOOD/Img_SRRH_31_2_12_02.23.51_MIG16.BMP       2022-01-31 00:11:44       173878\n",
            "GOOD/Img_SRRH_31_2_12_11.29.41_MIG16.BMP       2022-01-31 16:49:36       173878\n",
            "GOOD/Img_SRRH_31_2_13_02.26.40_MIG16.BMP       2022-01-31 00:14:32       173878\n",
            "GOOD/Img_SRRH_31_2_13_02.28.21_MIG16.BMP       2022-01-31 00:16:14       173878\n",
            "GOOD/Img_SRRH_31_2_13_11.33.34_MIG16.BMP       2022-01-31 16:53:30       173878\n",
            "GOOD/Img_SRRH_31_2_14_19.12.15_MIG16.BMP       2022-01-31 00:32:08       173878\n",
            "GOOD/Img_SRRH_31_2_15_11.41.27_MIG16.BMP       2022-01-31 17:01:22       173878\n",
            "GOOD/Img_SRRH_31_2_16_11.45.27_MIG16.BMP       2022-01-31 17:05:22       173878\n",
            "GOOD/Img_SRRH_31_2_17_11.49.29_MIG16.BMP       2022-01-31 17:09:24       173878\n",
            "GOOD/Img_SRRH_31_2_18_11.58.01_MIG16.BMP       2022-01-31 17:17:56       173878\n",
            "GOOD/Img_SRRH_31_2_18_19.15.26_MIG16.BMP       2022-01-31 00:35:18       173878\n",
            "GOOD/Img_SRRH_31_2_19_12.01.52_MIG16.BMP       2022-01-31 17:21:48       173878\n",
            "GOOD/Img_SRRH_31_2_19_19.18.10_MIG16.BMP       2022-01-31 00:38:04       173878\n",
            "GOOD/Img_SRRH_31_2_1_10.06.09_MIG16.BMP        2022-01-31 15:26:04       173878\n",
            "GOOD/Img_SRRH_31_2_20_19.20.58_MIG16.BMP       2022-01-31 00:40:52       173878\n",
            "GOOD/Img_SRRH_31_2_21_12.11.14_MIG16.BMP       2022-01-31 17:31:08       173878\n",
            "GOOD/Img_SRRH_31_2_22_12.15.18_MIG16.BMP       2022-01-31 17:35:14       173878\n",
            "GOOD/Img_SRRH_31_2_23_12.20.10_MIG16.BMP       2022-01-31 17:40:04       173878\n",
            "GOOD/Img_SRRH_31_2_24_12.24.04_MIG16.BMP       2022-01-31 17:44:00       173878\n",
            "GOOD/Img_SRRH_31_2_25_12.28.44_MIG16.BMP       2022-01-31 17:48:40       173878\n",
            "GOOD/Img_SRRH_31_2_26_12.33.40_MIG16.BMP       2022-01-31 17:53:36       173878\n",
            "GOOD/Img_SRRH_31_2_28_12.42.31_MIG16.BMP       2022-01-31 18:02:26       173878\n",
            "GOOD/Img_SRRH_31_2_29_12.51.01_MIG16.BMP       2022-01-31 18:10:56       173878\n",
            "GOOD/Img_SRRH_31_2_2_10.10.39_MIG16.BMP        2022-01-31 15:30:34       173878\n",
            "GOOD/Img_SRRH_31_2_30_13.00.00_MIG16.BMP       2022-01-31 18:19:54       173878\n",
            "GOOD/Img_SRRH_31_2_31_13.03.51_MIG16.BMP       2022-01-31 18:23:46       173878\n",
            "GOOD/Img_SRRH_31_2_33_13.13.05_MIG16.BMP       2022-01-31 18:33:00       173878\n",
            "GOOD/Img_SRRH_31_2_34_13.17.21_MIG16.BMP       2022-01-31 18:37:16       173878\n",
            "GOOD/Img_SRRH_31_2_36_13.30.16_MIG16.BMP       2022-01-31 18:50:10       173878\n",
            "GOOD/Img_SRRH_31_2_38_14.26.31_MIG16.BMP       2022-01-31 19:46:26       173878\n",
            "GOOD/Img_SRRH_31_2_39_14.31.25_MIG16.BMP       2022-01-31 19:51:20       173878\n",
            "GOOD/Img_SRRH_31_2_40_14.38.27_MIG16.BMP       2022-01-31 19:58:22       173878\n",
            "GOOD/Img_SRRH_31_2_42_14.48.58_MIG16.BMP       2022-01-31 20:08:54       173878\n",
            "GOOD/Img_SRRH_31_2_43_14.53.01_MIG16.BMP       2022-01-31 20:12:56       173878\n",
            "GOOD/Img_SRRH_31_2_44_14.57.06_MIG16.BMP       2022-01-31 20:17:02       173878\n",
            "GOOD/Img_SRRH_31_2_46_15.05.11_MIG16.BMP       2022-01-31 20:25:06       173878\n",
            "GOOD/Img_SRRH_31_2_47_15.08.55_MIG16.BMP       2022-01-31 20:28:50       173878\n",
            "GOOD/Img_SRRH_31_2_4_10.19.20_MIG16.BMP        2022-01-31 15:39:14       173878\n",
            "GOOD/Img_SRRH_31_2_50_15.50.15_MIG16.BMP       2022-01-31 21:10:10       173878\n",
            "GOOD/Img_SRRH_31_2_52_15.58.08_MIG16.BMP       2022-01-31 21:18:04       173878\n",
            "GOOD/Img_SRRH_31_2_53_16.02.13_MIG16.BMP       2022-01-31 21:22:08       173878\n",
            "GOOD/Img_SRRH_31_2_54_16.19.50_MIG16.BMP       2022-01-31 21:39:46       173878\n",
            "GOOD/Img_SRRH_31_2_57_16.29.18_MIG16.BMP       2022-01-31 21:49:14       173878\n",
            "GOOD/Img_SRRH_31_2_58_16.57.02_MIG16.BMP       2022-01-31 22:16:58       173878\n",
            "GOOD/Img_SRRH_31_2_59_17.02.29_MIG16.BMP       2022-01-31 22:22:24       173878\n",
            "GOOD/Img_SRRH_31_2_5_01.58.00_MIG16.BMP        2022-01-30 23:45:52       173878\n",
            "GOOD/Img_SRRH_31_2_5_10.27.30_MIG16.BMP        2022-01-31 15:47:26       173878\n",
            "GOOD/Img_SRRH_31_2_60_17.12.01_MIG16.BMP       2022-01-31 22:31:56       173878\n",
            "GOOD/Img_SRRH_31_2_61_17.55.45_MIG16.BMP       2022-01-31 23:15:42       173878\n",
            "GOOD/Img_SRRH_31_2_62_17.59.00_MIG16.BMP       2022-01-31 23:18:56       173878\n",
            "GOOD/Img_SRRH_31_2_63_18.01.47_MIG16.BMP       2022-01-31 23:21:42       173878\n",
            "GOOD/Img_SRRH_31_2_64_18.05.40_MIG16.BMP       2022-01-31 23:25:36       173878\n",
            "GOOD/Img_SRRH_31_2_65_18.09.55_MIG16.BMP       2022-01-31 23:29:50       173878\n",
            "GOOD/Img_SRRH_31_2_65_18.18.39_MIG16.BMP       2022-01-31 23:38:34       173878\n",
            "GOOD/Img_SRRH_31_2_66_18.13.54_MIG16.BMP       2022-01-31 23:33:50       173878\n",
            "GOOD/Img_SRRH_31_2_66_18.21.25_MIG16.BMP       2022-01-31 23:41:20       173878\n",
            "GOOD/Img_SRRH_31_2_6_02.02.22_MIG16.BMP        2022-01-30 23:50:14       173878\n",
            "GOOD/Img_SRRH_31_2_6_10.41.31_MIG16.BMP        2022-01-31 16:01:26       173878\n",
            "GOOD/Img_SRRH_31_2_7_02.05.18_MIG16.BMP        2022-01-30 23:53:12       173878\n",
            "GOOD/Img_SRRH_31_2_7_10.45.30_MIG16.BMP        2022-01-31 16:05:24       173878\n",
            "GOOD/Img_SRRH_31_2_8_02.07.52_MIG16.BMP        2022-01-30 23:55:46       173878\n",
            "GOOD/Img_SRRH_31_2_8_10.50.34_MIG16.BMP        2022-01-31 16:10:30       173878\n",
            "GOOD/Img_SRRH_31_2_9_02.10.25_MIG16.BMP        2022-01-30 23:58:18       173878\n",
            "GOOD/Img_SRRH_31_3_0_19.24.43_MIG16.BMP        2022-01-31 00:44:36       173878\n",
            "GOOD/Img_SRRH_31_3_10_19.53.27_MIG16.BMP       2022-01-31 01:13:20       173878\n",
            "GOOD/Img_SRRH_31_3_11_19.56.53_MIG16.BMP       2022-01-31 01:16:46       173878\n",
            "GOOD/Img_SRRH_31_3_12_19.59.38_MIG16.BMP       2022-01-31 01:19:32       173878\n",
            "GOOD/Img_SRRH_31_3_13_20.02.35_MIG16.BMP       2022-01-31 01:22:28       173878\n",
            "GOOD/Img_SRRH_31_3_14_20.05.15_MIG16.BMP       2022-01-31 01:25:08       173878\n",
            "GOOD/Img_SRRH_31_3_15_20.07.54_MIG16.BMP       2022-01-31 01:27:48       173878\n",
            "GOOD/Img_SRRH_31_3_16_20.10.39_MIG16.BMP       2022-01-31 01:30:32       173878\n",
            "GOOD/Img_SRRH_31_3_17_20.13.20_MIG16.BMP       2022-01-31 01:33:14       173878\n",
            "GOOD/Img_SRRH_31_3_18_20.16.05_MIG16.BMP       2022-01-31 01:35:58       173878\n",
            "GOOD/Img_SRRH_31_3_19_20.18.47_MIG16.BMP       2022-01-31 01:38:40       173878\n",
            "GOOD/Img_SRRH_31_3_1_19.26.35_MIG16.BMP        2022-01-31 00:46:28       173878\n",
            "GOOD/Img_SRRH_31_3_20_20.21.35_MIG16.BMP       2022-01-31 01:41:28       173878\n",
            "GOOD/Img_SRRH_31_3_21_20.24.23_MIG16.BMP       2022-01-31 01:44:16       173878\n",
            "GOOD/Img_SRRH_31_3_22_20.27.18_MIG16.BMP       2022-01-31 01:47:12       173878\n",
            "GOOD/Img_SRRH_31_3_23_20.30.02_MIG16.BMP       2022-01-31 01:49:56       173878\n",
            "GOOD/Img_SRRH_31_3_24_20.32.38_MIG16.BMP       2022-01-31 01:52:32       173878\n",
            "GOOD/Img_SRRH_31_3_25_20.35.33_MIG16.BMP       2022-01-31 01:55:26       173878\n",
            "GOOD/Img_SRRH_31_3_26_20.38.18_MIG16.BMP       2022-01-31 01:58:12       173878\n",
            "GOOD/Img_SRRH_31_3_27_20.40.57_MIG16.BMP       2022-01-31 02:00:50       173878\n",
            "GOOD/Img_SRRH_31_3_28_20.44.38_MIG16.BMP       2022-01-31 02:04:32       173878\n",
            "GOOD/Img_SRRH_31_3_28_21.09.48_MIG16.BMP       2022-01-31 02:29:42       173878\n",
            "GOOD/Img_SRRH_31_3_29_20.48.11_MIG16.BMP       2022-01-31 02:08:04       173878\n",
            "GOOD/Img_SRRH_31_3_29_21.13.16_MIG16.BMP       2022-01-31 02:33:10       173878\n",
            "GOOD/Img_SRRH_31_3_2_10.14.59_MIG16.BMP        2022-01-31 15:34:54       173878\n",
            "GOOD/Img_SRRH_31_3_2_19.29.38_MIG16.BMP        2022-01-31 00:49:32       173878\n",
            "GOOD/Img_SRRH_31_3_30_20.49.45_MIG16.BMP       2022-01-31 02:09:38       173878\n",
            "GOOD/Img_SRRH_31_3_30_21.17.20_MIG16.BMP       2022-01-31 02:37:14       173878\n",
            "GOOD/Img_SRRH_31_3_31_20.51.10_MIG16.BMP       2022-01-31 02:11:04       173878\n",
            "GOOD/Img_SRRH_31_3_31_21.20.47_MIG16.BMP       2022-01-31 02:40:40       173878\n",
            "GOOD/Img_SRRH_31_3_32_20.54.20_MIG16.BMP       2022-01-31 02:14:14       173878\n",
            "GOOD/Img_SRRH_31_3_32_21.24.31_MIG16.BMP       2022-01-31 02:44:24       173878\n",
            "GOOD/Img_SRRH_31_3_33_20.58.34_MIG16.BMP       2022-01-31 02:18:28       173878\n",
            "GOOD/Img_SRRH_31_3_33_21.27.16_MIG16.BMP       2022-01-31 02:47:10       173878\n",
            "GOOD/Img_SRRH_31_3_34_21.02.58_MIG16.BMP       2022-01-31 02:22:52       173878\n",
            "GOOD/Img_SRRH_31_3_34_21.30.29_MIG16.BMP       2022-01-31 02:50:22       173878\n",
            "GOOD/Img_SRRH_31_3_35_21.33.11_MIG16.BMP       2022-01-31 02:53:04       173878\n",
            "GOOD/Img_SRRH_31_3_36_21.36.01_MIG16.BMP       2022-01-31 02:55:54       173878\n",
            "GOOD/Img_SRRH_31_3_37_21.38.46_MIG16.BMP       2022-01-31 02:58:40       173878\n",
            "GOOD/Img_SRRH_31_3_38_21.41.16_MIG16.BMP       2022-01-31 03:01:10       173878\n",
            "GOOD/Img_SRRH_31_3_39_22.11.56_MIG16.BMP       2022-01-31 03:31:50       173878\n",
            "GOOD/Img_SRRH_31_3_3_19.32.40_MIG16.BMP        2022-01-31 00:52:32       173878\n",
            "GOOD/Img_SRRH_31_3_40_22.14.54_MIG16.BMP       2022-01-31 03:34:48       173878\n",
            "GOOD/Img_SRRH_31_3_41_22.17.41_MIG16.BMP       2022-01-31 03:37:34       173878\n",
            "GOOD/Img_SRRH_31_3_42_22.20.33_MIG16.BMP       2022-01-31 03:40:26       173878\n",
            "GOOD/Img_SRRH_31_3_43_22.23.11_MIG16.BMP       2022-01-31 03:43:06       173878\n",
            "GOOD/Img_SRRH_31_3_44_22.25.55_MIG16.BMP       2022-01-31 03:45:48       173878\n",
            "GOOD/Img_SRRH_31_3_45_22.29.00_MIG16.BMP       2022-01-31 03:48:54       173878\n",
            "GOOD/Img_SRRH_31_3_46_22.31.36_MIG16.BMP       2022-01-31 03:51:30       173878\n",
            "GOOD/Img_SRRH_31_3_47_22.34.14_MIG16.BMP       2022-01-31 03:54:08       173878\n",
            "GOOD/Img_SRRH_31_3_48_22.37.12_MIG16.BMP       2022-01-31 03:57:06       173878\n",
            "GOOD/Img_SRRH_31_3_49_22.39.57_MIG16.BMP       2022-01-31 03:59:50       173878\n",
            "GOOD/Img_SRRH_31_3_4_19.35.36_MIG16.BMP        2022-01-31 00:55:30       173878\n",
            "GOOD/Img_SRRH_31_3_50_22.42.32_MIG16.BMP       2022-01-31 04:02:26       173878\n",
            "GOOD/Img_SRRH_31_3_51_22.45.18_MIG16.BMP       2022-01-31 04:05:12       173878\n",
            "GOOD/Img_SRRH_31_3_52_22.48.01_MIG16.BMP       2022-01-31 04:07:54       173878\n",
            "GOOD/Img_SRRH_31_3_54_22.59.11_MIG16.BMP       2022-01-31 04:19:04       173878\n",
            "GOOD/Img_SRRH_31_3_55_23.02.01_MIG16.BMP       2022-01-31 04:21:54       173878\n",
            "GOOD/Img_SRRH_31_3_56_23.04.34_MIG16.BMP       2022-01-31 04:24:28       173878\n",
            "GOOD/Img_SRRH_31_3_57_23.07.22_MIG16.BMP       2022-01-31 04:27:16       173878\n",
            "GOOD/Img_SRRH_31_3_58_23.10.22_MIG16.BMP       2022-01-31 04:30:16       173878\n",
            "GOOD/Img_SRRH_31_3_59_23.13.10_MIG16.BMP       2022-01-31 04:33:04       173878\n",
            "GOOD/Img_SRRH_31_3_5_19.38.26_MIG16.BMP        2022-01-31 00:58:20       173878\n",
            "GOOD/Img_SRRH_31_3_60_23.16.10_MIG16.BMP       2022-01-31 04:36:04       173878\n",
            "GOOD/Img_SRRH_31_3_61_23.18.39_MIG16.BMP       2022-01-31 04:38:32       173878\n",
            "GOOD/Img_SRRH_31_3_62_23.21.28_MIG16.BMP       2022-01-31 04:41:22       173878\n",
            "GOOD/Img_SRRH_31_3_63_23.24.49_MIG16.BMP       2022-01-31 04:44:42       173878\n",
            "GOOD/Img_SRRH_31_3_64_23.27.50_MIG16.BMP       2022-01-31 04:47:44       173878\n",
            "GOOD/Img_SRRH_31_3_6_19.41.02_MIG16.BMP        2022-01-31 01:00:56       173878\n",
            "GOOD/Img_SRRH_31_3_8_19.45.25_MIG16.BMP        2022-01-31 01:05:18       173878\n",
            "GOOD/Img_SRRH_31_3_8_19.48.50_MIG16.BMP        2022-01-31 01:08:44       173878\n",
            "GOOD/Img_SRRH_31_3_9_19.51.06_MIG16.BMP        2022-01-31 01:11:00       173878\n",
            "GOOD/Img_SRRH_57_1_0_15.46.44_MIG16.BMP        2022-02-26 15:45:28       173878\n",
            "GOOD/Img_SRRH_57_1_100_14.42.02_MIG16.BMP      2022-02-26 14:40:46       173878\n",
            "GOOD/Img_SRRH_57_1_101_14.45.54_MIG16.BMP      2022-02-26 14:44:38       173878\n",
            "GOOD/Img_SRRH_57_1_102_14.48.44_MIG16.BMP      2022-02-26 14:47:28       173878\n",
            "GOOD/Img_SRRH_57_1_27_20.00.59_MIG16.BMP       2022-02-26 19:59:44       173878\n",
            "GOOD/Img_SRRH_57_1_43_10.58.56_MIG16.BMP       2022-02-26 10:57:40       173878\n",
            "GOOD/Img_SRRH_57_1_44_11.34.01_MIG16.BMP       2022-02-26 11:32:46       173878\n",
            "GOOD/Img_SRRH_57_1_45_11.37.02_MIG16.BMP       2022-02-26 11:35:46       173878\n",
            "GOOD/Img_SRRH_57_1_46_11.41.45_MIG16.BMP       2022-02-26 11:40:30       173878\n",
            "GOOD/Img_SRRH_57_1_47_11.44.51_MIG16.BMP       2022-02-26 11:43:36       173878\n",
            "GOOD/Img_SRRH_57_1_48_11.50.14_MIG16.BMP       2022-02-26 11:48:58       173878\n",
            "GOOD/Img_SRRH_57_1_49_11.53.01_MIG16.BMP       2022-02-26 11:51:44       173878\n",
            "GOOD/Img_SRRH_57_1_50_11.56.52_MIG16.BMP       2022-02-26 11:55:36       173878\n",
            "GOOD/Img_SRRH_57_1_51_11.59.57_MIG16.BMP       2022-02-26 11:58:42       173878\n",
            "GOOD/Img_SRRH_57_1_52_12.02.42_MIG16.BMP       2022-02-26 12:01:26       173878\n",
            "GOOD/Img_SRRH_57_1_53_12.05.46_MIG16.BMP       2022-02-26 12:04:30       173878\n",
            "GOOD/Img_SRRH_57_1_54_12.08.40_MIG16.BMP       2022-02-26 12:07:24       173878\n",
            "GOOD/Img_SRRH_57_1_55_12.11.30_MIG16.BMP       2022-02-26 12:10:14       173878\n",
            "GOOD/Img_SRRH_57_1_56_12.14.21_MIG16.BMP       2022-02-26 12:13:06       173878\n",
            "GOOD/Img_SRRH_57_1_57_12.17.02_MIG16.BMP       2022-02-26 12:15:46       173878\n",
            "GOOD/Img_SRRH_57_1_58_12.19.47_MIG16.BMP       2022-02-26 12:18:32       173878\n",
            "GOOD/Img_SRRH_57_1_59_12.22.36_MIG16.BMP       2022-02-26 12:21:20       173878\n",
            "GOOD/Img_SRRH_57_1_60_12.26.40_MIG16.BMP       2022-02-26 12:25:24       173878\n",
            "GOOD/Img_SRRH_57_1_61_12.29.22_MIG16.BMP       2022-02-26 12:28:06       173878\n",
            "GOOD/Img_SRRH_57_1_62_12.33.07_MIG16.BMP       2022-02-26 12:31:52       173878\n",
            "GOOD/Img_SRRH_57_1_63_12.36.06_MIG16.BMP       2022-02-26 12:34:50       173878\n",
            "GOOD/Img_SRRH_57_1_64_12.39.04_MIG16.BMP       2022-02-26 12:37:48       173878\n",
            "GOOD/Img_SRRH_57_1_65_12.41.51_MIG16.BMP       2022-02-26 12:40:36       173878\n",
            "GOOD/Img_SRRH_57_1_66_12.44.37_MIG16.BMP       2022-02-26 12:43:22       173878\n",
            "GOOD/Img_SRRH_57_1_67_12.50.42_MIG16.BMP       2022-02-26 12:49:26       173878\n",
            "GOOD/Img_SRRH_57_1_68_12.53.34_MIG16.BMP       2022-02-26 12:52:18       173878\n",
            "GOOD/Img_SRRH_57_1_69_12.56.21_MIG16.BMP       2022-02-26 12:55:04       173878\n",
            "GOOD/Img_SRRH_57_1_70_12.59.04_MIG16.BMP       2022-02-26 12:57:48       173878\n",
            "GOOD/Img_SRRH_57_1_71_13.02.00_MIG16.BMP       2022-02-26 13:00:44       173878\n",
            "GOOD/Img_SRRH_57_1_72_13.14.23_MIG16.BMP       2022-02-26 13:13:08       173878\n",
            "GOOD/Img_SRRH_57_1_73_13.18.31_MIG16.BMP       2022-02-26 13:17:14       173878\n",
            "GOOD/Img_SRRH_57_1_74_13.21.25_MIG16.BMP       2022-02-26 13:20:10       173878\n",
            "GOOD/Img_SRRH_57_1_75_13.25.38_MIG16.BMP       2022-02-26 13:24:22       173878\n",
            "GOOD/Img_SRRH_57_1_76_13.30.26_MIG16.BMP       2022-02-26 13:29:10       173878\n",
            "GOOD/Img_SRRH_57_1_77_13.33.18_MIG16.BMP       2022-02-26 13:32:02       173878\n",
            "GOOD/Img_SRRH_57_1_78_13.37.01_MIG16.BMP       2022-02-26 13:35:46       173878\n",
            "GOOD/Img_SRRH_57_1_79_13.39.42_MIG16.BMP       2022-02-26 13:38:26       173878\n",
            "GOOD/Img_SRRH_57_1_80_13.44.27_MIG16.BMP       2022-02-26 13:43:12       173878\n",
            "GOOD/Img_SRRH_57_1_81_13.47.15_MIG16.BMP       2022-02-26 13:46:00       173878\n",
            "GOOD/Img_SRRH_57_1_82_13.50.00_MIG16.BMP       2022-02-26 13:48:44       173878\n",
            "GOOD/Img_SRRH_57_1_83_13.52.49_MIG16.BMP       2022-02-26 13:51:34       173878\n",
            "GOOD/Img_SRRH_57_1_84_13.55.27_MIG16.BMP       2022-02-26 13:54:12       173878\n",
            "GOOD/Img_SRRH_57_1_85_13.58.12_MIG16.BMP       2022-02-26 13:56:56       173878\n",
            "GOOD/Img_SRRH_57_1_86_14.00.56_MIG16.BMP       2022-02-26 13:59:40       173878\n",
            "GOOD/Img_SRRH_57_1_87_14.04.04_MIG16.BMP       2022-02-26 14:02:48       173878\n",
            "GOOD/Img_SRRH_57_1_88_14.07.02_MIG16.BMP       2022-02-26 14:05:46       173878\n",
            "GOOD/Img_SRRH_57_1_89_14.10.01_MIG16.BMP       2022-02-26 14:08:46       173878\n",
            "GOOD/Img_SRRH_57_1_90_14.12.45_MIG16.BMP       2022-02-26 14:11:30       173878\n",
            "GOOD/Img_SRRH_57_1_91_14.15.40_MIG16.BMP       2022-02-26 14:14:24       173878\n",
            "GOOD/Img_SRRH_57_1_92_14.18.18_MIG16.BMP       2022-02-26 14:17:02       173878\n",
            "GOOD/Img_SRRH_57_1_93_14.21.41_MIG16.BMP       2022-02-26 14:20:26       173878\n",
            "GOOD/Img_SRRH_57_1_94_14.24.35_MIG16.BMP       2022-02-26 14:23:20       173878\n",
            "GOOD/Img_SRRH_57_1_95_14.27.18_MIG16.BMP       2022-02-26 14:26:02       173878\n",
            "GOOD/Img_SRRH_57_1_96_14.29.58_MIG16.BMP       2022-02-26 14:28:42       173878\n",
            "GOOD/Img_SRRH_57_1_97_14.32.45_MIG16.BMP       2022-02-26 14:31:30       173878\n",
            "GOOD/Img_SRRH_57_1_98_14.36.10_MIG16.BMP       2022-02-26 14:34:54       173878\n",
            "GOOD/Img_SRRH_57_1_99_14.39.21_MIG16.BMP       2022-02-26 14:38:06       173878\n",
            "GOOD/Img_SRRH_57_2_0_15.39.35_MIG16.BMP        2022-02-26 15:38:20       173878\n",
            "GOOD/Img_SRRH_57_2_10_16.59.07_MIG16.BMP       2022-02-26 16:57:52       173878\n",
            "GOOD/Img_SRRH_57_2_11_17.05.06_MIG16.BMP       2022-02-26 17:03:50       173878\n",
            "GOOD/Img_SRRH_57_2_12_17.29.45_MIG16.BMP       2022-02-26 17:28:30       173878\n",
            "GOOD/Img_SRRH_57_2_13_17.35.16_MIG16.BMP       2022-02-26 17:34:00       173878\n",
            "GOOD/Img_SRRH_57_2_14_17.40.19_MIG16.BMP       2022-02-26 17:39:04       173878\n",
            "GOOD/Img_SRRH_57_2_15_17.45.04_MIG16.BMP       2022-02-26 17:43:48       173878\n",
            "GOOD/Img_SRRH_57_2_16_17.49.40_MIG16.BMP       2022-02-26 17:48:24       173878\n",
            "GOOD/Img_SRRH_57_2_17_17.55.47_MIG16.BMP       2022-02-26 17:54:32       173878\n",
            "GOOD/Img_SRRH_57_2_18_18.05.32_MIG16.BMP       2022-02-26 18:04:18       173878\n",
            "GOOD/Img_SRRH_57_2_19_18.09.34_MIG16.BMP       2022-02-26 18:08:18       173878\n",
            "GOOD/Img_SRRH_57_2_1_15.51.58_MIG16.BMP        2022-02-26 15:50:42       173878\n",
            "GOOD/Img_SRRH_57_2_20_18.14.11_MIG16.BMP       2022-02-26 18:12:56       173878\n",
            "GOOD/Img_SRRH_57_2_21_18.18.44_MIG16.BMP       2022-02-26 18:17:30       173878\n",
            "GOOD/Img_SRRH_57_2_22_18.27.04_MIG16.BMP       2022-02-26 18:25:50       173878\n",
            "GOOD/Img_SRRH_57_2_23_18.37.23_MIG16.BMP       2022-02-26 18:36:08       173878\n",
            "GOOD/Img_SRRH_57_2_24_18.43.04_MIG16.BMP       2022-02-26 18:41:48       173878\n",
            "GOOD/Img_SRRH_57_2_25_19.40.06_MIG16.BMP       2022-02-26 19:38:52       173878\n",
            "GOOD/Img_SRRH_57_2_26_19.50.32_MIG16.BMP       2022-02-26 19:49:18       173878\n",
            "GOOD/Img_SRRH_57_2_27_19.56.55_MIG16.BMP       2022-02-26 19:55:40       173878\n",
            "GOOD/Img_SRRH_57_2_29_20.09.46_MIG16.BMP       2022-02-26 20:08:32       173878\n",
            "GOOD/Img_SRRH_57_2_2_15.59.24_MIG16.BMP        2022-02-26 15:58:08       173878\n",
            "GOOD/Img_SRRH_57_2_30_20.14.32_MIG16.BMP       2022-02-26 20:13:16       173878\n",
            "GOOD/Img_SRRH_57_2_31_20.18.37_MIG16.BMP       2022-02-26 20:17:24       173878\n",
            "GOOD/Img_SRRH_57_2_32_20.22.52_MIG16.BMP       2022-02-26 20:21:38       173878\n",
            "GOOD/Img_SRRH_57_2_33_20.28.02_MIG16.BMP       2022-02-26 20:26:48       173878\n",
            "GOOD/Img_SRRH_57_2_34_20.38.57_MIG16.BMP       2022-02-26 20:37:42       173878\n",
            "GOOD/Img_SRRH_57_2_35_20.53.37_MIG16.BMP       2022-02-26 20:52:22       173878\n",
            "GOOD/Img_SRRH_57_2_36_20.58.14_MIG16.BMP       2022-02-26 20:56:58       173878\n",
            "GOOD/Img_SRRH_57_2_37_21.02.07_MIG16.BMP       2022-02-26 21:00:52       173878\n",
            "GOOD/Img_SRRH_57_2_38_21.06.54_MIG16.BMP       2022-02-26 21:05:40       173878\n",
            "GOOD/Img_SRRH_57_2_39_21.11.21_MIG16.BMP       2022-02-26 21:10:06       173878\n",
            "GOOD/Img_SRRH_57_2_3_16.09.06_MIG16.BMP        2022-02-26 16:07:52       173878\n",
            "GOOD/Img_SRRH_57_2_40_21.16.52_MIG16.BMP       2022-02-26 21:15:38       173878\n",
            "GOOD/Img_SRRH_57_2_41_21.22.11_MIG16.BMP       2022-02-26 21:20:56       173878\n",
            "GOOD/Img_SRRH_57_2_42_21.32.18_MIG16.BMP       2022-02-26 21:31:02       173878\n",
            "GOOD/Img_SRRH_57_2_43_21.36.21_MIG16.BMP       2022-02-26 21:35:06       173878\n",
            "GOOD/Img_SRRH_57_2_44_21.40.42_MIG16.BMP       2022-02-26 21:39:28       173878\n",
            "GOOD/Img_SRRH_57_2_45_21.46.01_MIG16.BMP       2022-02-26 21:44:46       173878\n",
            "GOOD/Img_SRRH_57_2_46_21.50.58_MIG16.BMP       2022-02-26 21:49:44       173878\n",
            "GOOD/Img_SRRH_57_2_4_16.14.19_MIG16.BMP        2022-02-26 16:13:04       173878\n",
            "GOOD/Img_SRRH_57_2_50_23.26.39_MIG16.BMP       2022-02-26 23:25:24       173878\n",
            "GOOD/Img_SRRH_57_2_52_23.35.01_MIG16.BMP       2022-02-26 23:33:46       173878\n",
            "GOOD/Img_SRRH_57_2_55_23.43.25_MIG16.BMP       2022-02-26 23:42:10       173878\n",
            "GOOD/Img_SRRH_57_2_56_23.47.47_MIG16.BMP       2022-02-26 23:46:32       173878\n",
            "GOOD/Img_SRRH_57_2_56_23.52.11_MIG16.BMP       2022-02-26 23:50:56       173878\n",
            "GOOD/Img_SRRH_57_2_5_16.21.00_MIG16.BMP        2022-02-26 16:19:44       173878\n",
            "GOOD/Img_SRRH_57_2_6_16.30.01_MIG16.BMP        2022-02-26 16:28:46       173878\n",
            "GOOD/Img_SRRH_57_2_7_16.35.23_MIG16.BMP        2022-02-26 16:34:08       173878\n",
            "GOOD/Img_SRRH_57_2_8_16.44.45_MIG16.BMP        2022-02-26 16:43:30       173878\n",
            "GOOD/Img_SRRH_57_2_9_16.51.35_MIG16.BMP        2022-02-26 16:50:20       173878\n",
            "GOOD/Img_SRRH_60_1_16_08.29.15_MIG16.BMP       2022-03-01 16:52:22       173878\n",
            "GOOD/Img_SRRH_60_1_19_21.23.45_MIG16.BMP       2022-03-01 05:46:52       173878\n",
            "GOOD/Img_SRRH_60_1_20_21.26.58_MIG16.BMP       2022-03-01 05:50:04       173878\n",
            "GOOD/Img_SRRH_60_1_21_21.47.45_MIG16.BMP       2022-03-01 06:10:52       173878\n",
            "GOOD/Img_SRRH_60_1_25_21.57.26_MIG16.BMP       2022-03-01 06:20:32       173878\n",
            "GOOD/Img_SRRH_60_1_26_21.59.36_MIG16.BMP       2022-03-01 06:22:42       173878\n",
            "GOOD/Img_SRRH_60_1_27_22.02.29_MIG16.BMP       2022-03-01 06:25:34       173878\n",
            "GOOD/Img_SRRH_60_1_28_22.06.13_MIG16.BMP       2022-03-01 06:29:18       173878\n",
            "GOOD/Img_SRRH_60_1_29_22.08.17_MIG16.BMP       2022-03-01 06:31:22       173878\n",
            "GOOD/Img_SRRH_60_1_30_22.11.13_MIG16.BMP       2022-03-01 06:34:18       173878\n",
            "GOOD/Img_SRRH_60_1_31_22.14.41_MIG16.BMP       2022-03-01 06:37:46       173878\n",
            "GOOD/Img_SRRH_60_1_33_22.20.09_MIG16.BMP       2022-03-01 06:43:16       173878\n",
            "GOOD/Img_SRRH_60_1_35_22.54.02_MIG16.BMP       2022-03-01 07:17:08       173878\n",
            "GOOD/Img_SRRH_60_1_36_22.59.17_MIG16.BMP       2022-03-01 07:22:24       173878\n",
            "GOOD/Img_SRRH_60_1_37_23.05.29_MIG16.BMP       2022-03-01 07:28:34       173878\n",
            "GOOD/Img_SRRH_60_1_38_23.09.11_MIG16.BMP       2022-03-01 07:32:16       173878\n",
            "GOOD/Img_SRRH_60_1_39_23.12.06_MIG16.BMP       2022-03-01 07:35:12       173878\n",
            "GOOD/Img_SRRH_60_1_40_23.15.11_MIG16.BMP       2022-03-01 07:38:16       173878\n",
            "GOOD/Img_SRRH_60_1_41_23.20.16_MIG16.BMP       2022-03-01 07:43:22       173878\n",
            "GOOD/Img_SRRH_60_1_42_23.22.29_MIG16.BMP       2022-03-01 07:45:36       173878\n",
            "GOOD/Img_SRRH_60_1_43_23.25.46_MIG16.BMP       2022-03-01 07:48:52       173878\n",
            "GOOD/Img_SRRH_60_1_44_23.28.44_MIG16.BMP       2022-03-01 07:51:50       173878\n",
            "GOOD/Img_SRRH_60_1_45_23.31.29_MIG16.BMP       2022-03-01 07:54:34       173878\n",
            "GOOD/Img_SRRH_60_1_46_23.34.36_MIG16.BMP       2022-03-01 07:57:42       173878\n",
            "GOOD/Img_SRRH_60_1_47_23.38.41_MIG16.BMP       2022-03-01 08:01:46       173878\n",
            "GOOD/Img_SRRH_60_1_48_23.47.34_MIG16.BMP       2022-03-01 08:10:40       173878\n",
            "GOOD/Img_SRRH_60_1_49_23.50.31_MIG16.BMP       2022-03-01 08:13:36       173878\n",
            "GOOD/Img_SRRH_60_1_52_12.16.56_MIG16.BMP       2022-03-01 20:40:02       173878\n",
            "GOOD/Img_SRRH_60_1_63_00.34.19_MIG16.BMP       2022-03-01 08:57:24       173878\n",
            "GOOD/Img_SRRH_60_1_64_00.37.32_MIG16.BMP       2022-03-01 09:00:38       173878\n",
            "GOOD/Img_SRRH_60_1_65_00.48.04_MIG16.BMP       2022-03-01 09:11:10       173878\n",
            "GOOD/Img_SRRH_60_1_66_00.50.58_MIG16.BMP       2022-03-01 09:14:04       173878\n",
            "GOOD/Img_SRRH_60_1_67_00.53.52_MIG16.BMP       2022-03-01 09:16:58       173878\n",
            "GOOD/Img_SRRH_60_1_69_00.56.52_MIG16.BMP       2022-03-01 09:19:58       173878\n",
            "GOOD/Img_SRRH_60_1_69_00.59.40_MIG16.BMP       2022-03-01 09:22:46       173878\n",
            "GOOD/Img_SRRH_60_1_70_01.02.31_MIG16.BMP       2022-03-01 09:25:36       173878\n",
            "GOOD/Img_SRRH_60_1_71_01.05.15_MIG16.BMP       2022-03-01 09:28:20       173878\n",
            "GOOD/Img_SRRH_60_1_72_01.08.37_MIG16.BMP       2022-03-01 09:31:44       173878\n",
            "GOOD/Img_SRRH_60_1_73_01.11.24_MIG16.BMP       2022-03-01 09:34:30       173878\n",
            "GOOD/Img_SRRH_60_1_74_01.14.29_MIG16.BMP       2022-03-01 09:37:36       173878\n",
            "GOOD/Img_SRRH_60_1_75_01.18.54_MIG16.BMP       2022-03-01 09:42:00       173878\n",
            "GOOD/Img_SRRH_60_1_76_01.21.54_MIG16.BMP       2022-03-01 09:45:00       173878\n",
            "GOOD/Img_SRRH_60_1_77_01.25.01_MIG16.BMP       2022-03-01 09:48:08       173878\n",
            "GOOD/Img_SRRH_60_1_78_01.28.01_MIG16.BMP       2022-03-01 09:51:08       173878\n",
            "GOOD/Img_SRRH_60_1_79_01.32.25_MIG16.BMP       2022-03-01 09:55:32       173878\n",
            "GOOD/Img_SRRH_60_1_80_01.35.09_MIG16.BMP       2022-03-01 09:58:14       173878\n",
            "GOOD/Img_SRRH_60_1_81_01.39.23_MIG16.BMP       2022-03-01 10:02:30       173878\n",
            "GOOD/Img_SRRH_60_1_82_01.47.49_MIG16.BMP       2022-03-01 10:10:56       173878\n",
            "GOOD/Img_SRRH_60_1_83_01.50.47_MIG16.BMP       2022-03-01 10:13:52       173878\n",
            "GOOD/Img_SRRH_60_1_84_01.54.16_MIG16.BMP       2022-03-01 10:17:22       173878\n",
            "GOOD/Img_SRRH_60_1_85_01.57.40_MIG16.BMP       2022-03-01 10:20:46       173878\n",
            "GOOD/Img_SRRH_60_1_86_02.01.08_MIG16.BMP       2022-03-01 10:24:14       173878\n",
            "GOOD/Img_SRRH_60_1_87_02.03.57_MIG16.BMP       2022-03-01 10:27:04       173878\n",
            "GOOD/Img_SRRH_60_1_88_02.06.46_MIG16.BMP       2022-03-01 10:29:52       173878\n",
            "GOOD/Img_SRRH_60_1_89_02.09.52_MIG16.BMP       2022-03-01 10:32:58       173878\n",
            "GOOD/Img_SRRH_60_1_90_02.13.01_MIG16.BMP       2022-03-01 10:36:08       173878\n",
            "GOOD/Img_SRRH_60_1_91_02.15.45_MIG16.BMP       2022-03-01 10:38:52       173878\n",
            "GOOD/Img_SRRH_60_1_92_02.18.48_MIG16.BMP       2022-03-01 10:41:54       173878\n",
            "GOOD/Img_SRRH_60_1_93_02.22.14_MIG16.BMP       2022-03-01 10:45:20       173878\n",
            "GOOD/Img_SRRH_60_1_94_02.25.04_MIG16.BMP       2022-03-01 10:48:10       173878\n",
            "GOOD/Img_SRRH_60_1_96_02.31.04_MIG16.BMP       2022-03-01 10:54:10       173878\n",
            "GOOD/Img_SRRH_60_1_97_02.34.00_MIG16.BMP       2022-03-01 10:57:06       173878\n",
            "GOOD/Img_SRRH_60_2_10_07.45.29_MIG16.BMP       2022-03-01 16:08:36       173878\n",
            "GOOD/Img_SRRH_60_2_11_07.49.27_MIG16.BMP       2022-03-01 16:12:34       173878\n",
            "GOOD/Img_SRRH_60_2_12_07.53.37_MIG16.BMP       2022-03-01 16:16:44       173878\n",
            "GOOD/Img_SRRH_60_2_13_07.57.53_MIG16.BMP       2022-03-01 16:21:00       173878\n",
            "GOOD/Img_SRRH_60_2_14_08.06.16_MIG16.BMP       2022-03-01 16:29:22       173878\n",
            "GOOD/Img_SRRH_60_2_15_08.10.31_MIG16.BMP       2022-03-01 16:33:38       173878\n",
            "GOOD/Img_SRRH_60_2_16_08.24.38_MIG16.BMP       2022-03-01 16:47:46       173878\n",
            "GOOD/Img_SRRH_60_2_19_08.40.43_MIG16.BMP       2022-03-01 17:03:50       173878\n",
            "GOOD/Img_SRRH_60_2_20_08.45.42_MIG16.BMP       2022-03-01 17:08:48       173878\n",
            "GOOD/Img_SRRH_60_2_21_08.51.11_MIG16.BMP       2022-03-01 17:14:18       173878\n",
            "GOOD/Img_SRRH_60_2_22_08.55.42_MIG16.BMP       2022-03-01 17:18:48       173878\n",
            "GOOD/Img_SRRH_60_2_23_08.59.59_MIG16.BMP       2022-03-01 17:23:06       173878\n",
            "GOOD/Img_SRRH_60_2_43_11.27.56_MIG16.BMP       2022-03-01 19:51:02       173878\n",
            "GOOD/Img_SRRH_60_2_44_11.33.22_MIG16.BMP       2022-03-01 19:56:30       173878\n",
            "GOOD/Img_SRRH_60_2_45_11.37.26_MIG16.BMP       2022-03-01 20:00:34       173878\n",
            "GOOD/Img_SRRH_60_2_46_11.41.31_MIG16.BMP       2022-03-01 20:04:38       173878\n",
            "GOOD/Img_SRRH_60_2_47_11.45.33_MIG16.BMP       2022-03-01 20:08:40       173878\n",
            "GOOD/Img_SRRH_60_2_48_11.49.24_MIG16.BMP       2022-03-01 20:12:32       173878\n",
            "GOOD/Img_SRRH_60_2_49_11.53.59_MIG16.BMP       2022-03-01 20:17:06       173878\n",
            "GOOD/Img_SRRH_60_2_50_11.58.26_MIG16.BMP       2022-03-01 20:21:32       173878\n",
            "GOOD/Img_SRRH_60_2_51_12.05.37_MIG16.BMP       2022-03-01 20:28:44       173878\n",
            "GOOD/Img_SRRH_60_2_52_12.10.46_MIG16.BMP       2022-03-01 20:33:52       173878\n",
            "GOOD/Img_SRRH_60_2_53_12.22.16_MIG16.BMP       2022-03-01 20:45:24       173878\n",
            "GOOD/Img_SRRH_60_2_54_12.29.14_MIG16.BMP       2022-03-01 20:52:22       173878\n",
            "GOOD/Img_SRRH_60_2_55_12.35.57_MIG16.BMP       2022-03-01 20:59:04       173878\n",
            "GOOD/Img_SRRH_60_2_56_12.43.35_MIG16.BMP       2022-03-01 21:06:42       173878\n",
            "GOOD/Img_SRRH_60_2_57_12.50.21_MIG16.BMP       2022-03-01 21:13:28       173878\n",
            "GOOD/Img_SRRH_60_2_58_12.55.49_MIG16.BMP       2022-03-01 21:18:56       173878\n",
            "GOOD/Img_SRRH_60_2_59_13.06.31_MIG16.BMP       2022-03-01 21:29:38       173878\n",
            "GOOD/Img_SRRH_60_2_5_07.20.53_MIG16.BMP        2022-03-01 15:44:00       173878\n",
            "GOOD/Img_SRRH_60_2_60_13.24.30_MIG16.BMP       2022-03-01 21:47:38       173878\n",
            "GOOD/Img_SRRH_60_2_61_13.28.52_MIG16.BMP       2022-03-01 21:52:00       173878\n",
            "GOOD/Img_SRRH_60_2_62_13.33.19_MIG16.BMP       2022-03-01 21:56:26       173878\n",
            "GOOD/Img_SRRH_60_2_63_13.37.03_MIG16.BMP       2022-03-01 22:00:10       173878\n",
            "GOOD/Img_SRRH_60_2_64_13.41.32_MIG16.BMP       2022-03-01 22:04:40       173878\n",
            "GOOD/Img_SRRH_60_2_65_13.52.20_MIG16.BMP       2022-03-01 22:15:28       173878\n",
            "GOOD/Img_SRRH_60_2_66_13.56.25_MIG16.BMP       2022-03-01 22:19:32       173878\n",
            "GOOD/Img_SRRH_60_2_67_14.01.36_MIG16.BMP       2022-03-01 22:24:44       173878\n",
            "GOOD/Img_SRRH_60_2_68_14.05.33_MIG16.BMP       2022-03-01 22:28:40       173878\n",
            "GOOD/Img_SRRH_60_2_69_14.11.08_MIG16.BMP       2022-03-01 22:34:16       173878\n",
            "GOOD/Img_SRRH_60_2_6_07.25.01_MIG16.BMP        2022-03-01 15:48:08       173878\n",
            "GOOD/Img_SRRH_60_2_70_14.46.28_MIG16.BMP       2022-03-01 23:09:36       173878\n",
            "GOOD/Img_SRRH_60_2_71_14.54.33_MIG16.BMP       2022-03-01 23:17:42       173878\n",
            "GOOD/Img_SRRH_60_2_72_14.57.35_MIG16.BMP       2022-03-01 23:20:42       173878\n",
            "GOOD/Img_SRRH_60_2_73_15.00.08_MIG16.BMP       2022-03-01 23:23:16       173878\n",
            "GOOD/Img_SRRH_60_2_74_15.03.18_MIG16.BMP       2022-03-01 23:26:26       173878\n",
            "GOOD/Img_SRRH_60_2_75_15.06.18_MIG16.BMP       2022-03-01 23:29:26       173878\n",
            "GOOD/Img_SRRH_60_2_76_15.08.57_MIG16.BMP       2022-03-01 23:32:04       173878\n",
            "GOOD/Img_SRRH_60_2_77_15.00.03_MIG16.BMP       2022-02-28 23:51:56       173878\n",
            "GOOD/Img_SRRH_60_2_77_15.11.46_MIG16.BMP       2022-03-01 23:34:54       173878\n",
            "GOOD/Img_SRRH_60_2_78_15.02.43_MIG16.BMP       2022-02-28 23:54:36       173878\n",
            "GOOD/Img_SRRH_60_2_78_15.14.59_MIG16.BMP       2022-03-01 23:38:06       173878\n",
            "GOOD/Img_SRRH_60_2_79_15.06.22_MIG16.BMP       2022-02-28 23:58:16       173878\n",
            "GOOD/Img_SRRH_60_2_79_15.17.23_MIG16.BMP       2022-03-01 23:40:30       173878\n",
            "GOOD/Img_SRRH_60_2_7_07.29.06_MIG16.BMP        2022-03-01 15:52:12       173878\n",
            "GOOD/Img_SRRH_60_2_80_15.09.23_MIG16.BMP       2022-03-01 00:01:16       173878\n",
            "GOOD/Img_SRRH_60_2_80_15.20.11_MIG16.BMP       2022-03-01 23:43:18       173878\n",
            "GOOD/Img_SRRH_60_2_81_15.13.04_MIG16.BMP       2022-03-01 00:04:58       173878\n",
            "GOOD/Img_SRRH_60_2_81_15.22.58_MIG16.BMP       2022-03-01 23:46:06       173878\n",
            "GOOD/Img_SRRH_60_2_82_15.17.14_MIG16.BMP       2022-03-01 00:09:08       173878\n",
            "GOOD/Img_SRRH_60_2_82_15.25.33_MIG16.BMP       2022-03-01 23:48:40       173878\n",
            "GOOD/Img_SRRH_60_2_83_15.22.50_MIG16.BMP       2022-03-01 00:14:44       173878\n",
            "GOOD/Img_SRRH_60_2_85_15.25.17_MIG16.BMP       2022-03-01 00:17:10       173878\n",
            "GOOD/Img_SRRH_60_2_86_15.28.15_MIG16.BMP       2022-03-01 00:20:10       173878\n",
            "GOOD/Img_SRRH_60_2_87_15.31.04_MIG16.BMP       2022-03-01 00:22:58       173878\n",
            "GOOD/Img_SRRH_60_2_88_15.34.00_MIG16.BMP       2022-03-01 00:25:54       173878\n",
            "GOOD/Img_SRRH_60_2_89_15.37.31_MIG16.BMP       2022-03-01 00:29:26       173878\n",
            "GOOD/Img_SRRH_60_2_8_07.36.38_MIG16.BMP        2022-03-01 15:59:46       173878\n",
            "GOOD/Img_SRRH_60_2_90_15.40.30_MIG16.BMP       2022-03-01 00:32:24       173878\n",
            "GOOD/Img_SRRH_60_2_91_15.44.25_MIG16.BMP       2022-03-01 00:36:18       173878\n",
            "GOOD/Img_SRRH_60_2_92_15.48.49_MIG16.BMP       2022-03-01 00:40:42       173878\n",
            "GOOD/Img_SRRH_60_2_9_07.41.25_MIG16.BMP        2022-03-01 16:04:32       173878\n",
            "GOOD/Img_SRRH_60_3_0_16.01.41_MIG16.BMP        2022-03-01 00:53:34       173878\n",
            "GOOD/Img_SRRH_60_3_10_16.31.04_MIG16.BMP       2022-03-01 01:22:58       173878\n",
            "GOOD/Img_SRRH_60_3_11_16.32.51_MIG16.BMP       2022-03-01 01:24:44       173878\n",
            "GOOD/Img_SRRH_60_3_12_16.35.45_MIG16.BMP       2022-03-01 01:27:38       173878\n",
            "GOOD/Img_SRRH_60_3_13_16.38.35_MIG16.BMP       2022-03-01 01:30:28       173878\n",
            "GOOD/Img_SRRH_60_3_14_16.41.14_MIG16.BMP       2022-03-01 01:33:08       173878\n",
            "GOOD/Img_SRRH_60_3_15_16.44.04_MIG16.BMP       2022-03-01 01:35:58       173878\n",
            "GOOD/Img_SRRH_60_3_16_16.46.49_MIG16.BMP       2022-03-01 01:38:42       173878\n",
            "GOOD/Img_SRRH_60_3_17_16.49.44_MIG16.BMP       2022-03-01 01:41:38       173878\n",
            "GOOD/Img_SRRH_60_3_18_16.52.21_MIG16.BMP       2022-03-01 01:44:14       173878\n",
            "GOOD/Img_SRRH_60_3_19_16.55.14_MIG16.BMP       2022-03-01 01:47:08       173878\n",
            "GOOD/Img_SRRH_60_3_1_16.04.49_MIG16.BMP        2022-03-01 00:56:44       173878\n",
            "GOOD/Img_SRRH_60_3_20_16.57.53_MIG16.BMP       2022-03-01 01:49:46       173878\n",
            "GOOD/Img_SRRH_60_3_21_17.00.43_MIG16.BMP       2022-03-01 01:52:36       173878\n",
            "GOOD/Img_SRRH_60_3_22_17.03.27_MIG16.BMP       2022-03-01 01:55:20       173878\n",
            "GOOD/Img_SRRH_60_3_23_17.06.12_MIG16.BMP       2022-03-01 01:58:06       173878\n",
            "GOOD/Img_SRRH_60_3_24_17.08.58_MIG16.BMP       2022-03-01 02:00:52       173878\n",
            "GOOD/Img_SRRH_60_3_25_17.12.14_MIG16.BMP       2022-03-01 02:04:08       173878\n",
            "GOOD/Img_SRRH_60_3_26_17.15.10_MIG16.BMP       2022-03-01 02:07:04       173878\n",
            "GOOD/Img_SRRH_60_3_27_17.17.51_MIG16.BMP       2022-03-01 02:09:46       173878\n",
            "GOOD/Img_SRRH_60_3_28_17.20.28_MIG16.BMP       2022-03-01 02:12:22       173878\n",
            "GOOD/Img_SRRH_60_3_29_17.23.29_MIG16.BMP       2022-03-01 02:15:22       173878\n",
            "GOOD/Img_SRRH_60_3_2_16.07.25_MIG16.BMP        2022-03-01 00:59:18       173878\n",
            "GOOD/Img_SRRH_60_3_31_17.29.53_MIG16.BMP       2022-03-01 02:21:46       173878\n",
            "GOOD/Img_SRRH_60_3_32_17.33.04_MIG16.BMP       2022-03-01 02:24:58       173878\n",
            "GOOD/Img_SRRH_60_3_33_17.35.56_MIG16.BMP       2022-03-01 02:27:50       173878\n",
            "GOOD/Img_SRRH_60_3_34_17.38.36_MIG16.BMP       2022-03-01 02:30:30       173878\n",
            "GOOD/Img_SRRH_60_3_35_17.41.19_MIG16.BMP       2022-03-01 02:33:12       173878\n",
            "GOOD/Img_SRRH_60_3_36_17.44.24_MIG16.BMP       2022-03-01 02:36:18       173878\n",
            "GOOD/Img_SRRH_60_3_37_17.47.07_MIG16.BMP       2022-03-01 02:39:00       173878\n",
            "GOOD/Img_SRRH_60_3_38_17.49.50_MIG16.BMP       2022-03-01 02:41:44       173878\n",
            "GOOD/Img_SRRH_60_3_39_17.52.44_MIG16.BMP       2022-03-01 02:44:38       173878\n",
            "GOOD/Img_SRRH_60_3_3_16.10.24_MIG16.BMP        2022-03-01 01:02:18       173878\n",
            "GOOD/Img_SRRH_60_3_40_17.55.36_MIG16.BMP       2022-03-01 02:47:30       173878\n",
            "GOOD/Img_SRRH_60_3_41_17.58.12_MIG16.BMP       2022-03-01 02:50:06       173878\n",
            "GOOD/Img_SRRH_60_3_47_19.21.09_MIG16.BMP       2022-03-01 03:44:14       173878\n",
            "GOOD/Img_SRRH_60_3_48_19.25.20_MIG16.BMP       2022-03-01 03:48:26       173878\n",
            "GOOD/Img_SRRH_60_3_49_19.28.09_MIG16.BMP       2022-03-01 03:51:14       173878\n",
            "GOOD/Img_SRRH_60_3_4_16.13.07_MIG16.BMP        2022-03-01 01:05:00       173878\n",
            "GOOD/Img_SRRH_60_3_50_19.31.02_MIG16.BMP       2022-03-01 03:54:08       173878\n",
            "GOOD/Img_SRRH_60_3_52_19.36.45_MIG16.BMP       2022-03-01 03:59:50       173878\n",
            "GOOD/Img_SRRH_60_3_53_19.39.27_MIG16.BMP       2022-03-01 04:02:32       173878\n",
            "GOOD/Img_SRRH_60_3_54_19.42.08_MIG16.BMP       2022-03-01 04:05:14       173878\n",
            "GOOD/Img_SRRH_60_3_55_19.44.48_MIG16.BMP       2022-03-01 04:07:54       173878\n",
            "GOOD/Img_SRRH_60_3_56_19.47.43_MIG16.BMP       2022-03-01 04:10:48       173878\n",
            "GOOD/Img_SRRH_60_3_57_19.50.28_MIG16.BMP       2022-03-01 04:13:34       173878\n",
            "GOOD/Img_SRRH_60_3_58_19.53.19_MIG16.BMP       2022-03-01 04:16:24       173878\n",
            "GOOD/Img_SRRH_60_3_5_16.15.54_MIG16.BMP        2022-03-01 01:07:48       173878\n",
            "GOOD/Img_SRRH_60_3_6_16.19.01_MIG16.BMP        2022-03-01 01:10:54       173878\n",
            "GOOD/Img_SRRH_60_3_7_16.21.34_MIG16.BMP        2022-03-01 01:13:28       173878\n",
            "GOOD/Img_SRRH_60_3_8_16.24.32_MIG16.BMP        2022-03-01 01:16:26       173878\n",
            "GOOD/Img_SRRH_60_3_9_16.27.17_MIG16.BMP        2022-03-01 01:19:12       173878\n",
            "GOOD/Img_SRRH_69_1_100_05.04.45_MIG16.BMP      2022-03-10 13:41:08       173878\n",
            "GOOD/Img_SRRH_69_1_101_05.07.35_MIG16.BMP      2022-03-10 13:43:56       173878\n",
            "GOOD/Img_SRRH_69_1_102_05.10.17_MIG16.BMP      2022-03-10 13:46:40       173878\n",
            "GOOD/Img_SRRH_69_1_42_19.07.53_MIG16.BMP       2022-03-10 20:00:00       173878\n",
            "GOOD/Img_SRRH_69_1_50_19.42.51_MIG16.BMP       2022-03-10 20:34:54       173878\n",
            "GOOD/Img_SRRH_69_1_60_20.21.23_MIG16.BMP       2022-03-10 21:13:28       173878\n",
            "GOOD/Img_SRRH_69_1_79_01.52.18_MIG16.BMP       2022-03-10 10:28:40       173878\n",
            "GOOD/Img_SRRH_69_1_80_01.55.00_MIG16.BMP       2022-03-10 10:31:22       173878\n",
            "GOOD/Img_SRRH_69_1_81_01.57.44_MIG16.BMP       2022-03-10 10:34:06       173878\n",
            "GOOD/Img_SRRH_69_1_82_02.00.29_MIG16.BMP       2022-03-10 10:36:50       173878\n",
            "GOOD/Img_SRRH_69_1_83_02.03.28_MIG16.BMP       2022-03-10 10:39:50       173878\n",
            "GOOD/Img_SRRH_69_1_85_02.45.59_MIG16.BMP       2022-03-10 11:22:20       173878\n",
            "GOOD/Img_SRRH_69_1_86_02.48.44_MIG16.BMP       2022-03-10 11:25:06       173878\n",
            "GOOD/Img_SRRH_69_1_87_02.51.59_MIG16.BMP       2022-03-10 11:28:22       173878\n",
            "GOOD/Img_SRRH_69_1_88_04.12.28_MIG16.BMP       2022-03-10 12:48:50       173878\n",
            "GOOD/Img_SRRH_69_1_89_04.15.19_MIG16.BMP       2022-03-10 12:51:40       173878\n",
            "GOOD/Img_SRRH_69_1_98_04.58.43_MIG16.BMP       2022-03-10 13:35:06       173878\n",
            "GOOD/Img_SRRH_69_1_99_05.01.25_MIG16.BMP       2022-03-10 13:37:48       173878\n",
            "GOOD/Img_SRRH_69_2_0_07.09.37_MIG16.BMP        2022-03-10 15:46:00       173878\n",
            "GOOD/Img_SRRH_69_2_10_07.54.42_MIG16.BMP       2022-03-10 16:31:04       173878\n",
            "GOOD/Img_SRRH_69_2_11_07.58.27_MIG16.BMP       2022-03-10 16:34:50       173878\n",
            "GOOD/Img_SRRH_69_2_12_08.06.27_MIG16.BMP       2022-03-10 16:42:50       173878\n",
            "GOOD/Img_SRRH_69_2_13_08.09.56_MIG16.BMP       2022-03-10 16:46:18       173878\n",
            "GOOD/Img_SRRH_69_2_14_08.14.42_MIG16.BMP       2022-03-10 16:51:04       173878\n",
            "GOOD/Img_SRRH_69_2_1_07.14.31_MIG16.BMP        2022-03-10 15:50:54       173878\n",
            "GOOD/Img_SRRH_69_2_24_09.03.16_MIG16.BMP       2022-03-10 17:39:38       173878\n",
            "GOOD/Img_SRRH_69_2_25_09.08.41_MIG16.BMP       2022-03-10 17:45:04       173878\n",
            "GOOD/Img_SRRH_69_2_26_09.14.23_MIG16.BMP       2022-03-10 17:50:46       173878\n",
            "GOOD/Img_SRRH_69_2_27_09.18.37_MIG16.BMP       2022-03-10 17:55:00       173878\n",
            "GOOD/Img_SRRH_69_2_28_09.24.12_MIG16.BMP       2022-03-10 18:00:34       173878\n",
            "GOOD/Img_SRRH_69_2_2_07.18.54_MIG16.BMP        2022-03-10 15:55:16       173878\n",
            "GOOD/Img_SRRH_69_2_32_09.38.25_MIG16.BMP       2022-03-10 18:14:48       173878\n",
            "GOOD/Img_SRRH_69_2_33_09.42.11_MIG16.BMP       2022-03-10 18:18:34       173878\n",
            "GOOD/Img_SRRH_69_2_34_09.45.20_MIG16.BMP       2022-03-10 18:21:42       173878\n",
            "GOOD/Img_SRRH_69_2_35_09.48.36_MIG16.BMP       2022-03-10 18:24:58       173878\n",
            "GOOD/Img_SRRH_69_2_3_07.22.45_MIG16.BMP        2022-03-10 15:59:08       173878\n",
            "GOOD/Img_SRRH_69_2_45_19.11.30_MIG16.BMP       2022-03-10 20:03:38       173878\n",
            "GOOD/Img_SRRH_69_2_46_19.21.28_MIG16.BMP       2022-03-10 20:13:32       173878\n",
            "GOOD/Img_SRRH_69_2_47_19.25.29_MIG16.BMP       2022-03-10 20:17:34       173878\n",
            "GOOD/Img_SRRH_69_2_48_19.30.27_MIG16.BMP       2022-03-10 20:22:32       173878\n",
            "GOOD/Img_SRRH_69_2_49_19.34.13_MIG16.BMP       2022-03-10 20:26:18       173878\n",
            "GOOD/Img_SRRH_69_2_4_07.26.34_MIG16.BMP        2022-03-10 16:02:56       173878\n",
            "GOOD/Img_SRRH_69_2_50_19.37.35_MIG16.BMP       2022-03-10 20:29:40       173878\n",
            "GOOD/Img_SRRH_69_2_53_19.49.34_MIG16.BMP       2022-03-10 20:41:38       173878\n",
            "GOOD/Img_SRRH_69_2_54_19.52.42_MIG16.BMP       2022-03-10 20:44:46       173878\n",
            "GOOD/Img_SRRH_69_2_55_19.56.18_MIG16.BMP       2022-03-10 20:48:22       173878\n",
            "GOOD/Img_SRRH_69_2_56_19.59.36_MIG16.BMP       2022-03-10 20:51:40       173878\n",
            "GOOD/Img_SRRH_69_2_58_20.07.24_MIG16.BMP       2022-03-10 20:59:28       173878\n",
            "GOOD/Img_SRRH_69_2_59_20.11.02_MIG16.BMP       2022-03-10 21:03:06       173878\n",
            "GOOD/Img_SRRH_69_2_60_20.16.43_MIG16.BMP       2022-03-10 21:08:48       173878\n",
            "GOOD/Img_SRRH_69_2_79_22.13.54_MIG16.BMP       2022-03-10 23:05:58       173878\n",
            "GOOD/Img_SRRH_69_2_80_22.23.19_MIG16.BMP       2022-03-10 23:15:24       173878\n",
            "GOOD/Img_SRRH_69_2_81_22.26.29_MIG16.BMP       2022-03-10 23:18:34       173878\n",
            "GOOD/Img_SRRH_69_2_82_22.29.24_MIG16.BMP       2022-03-10 23:21:28       173878\n",
            "GOOD/Img_SRRH_6_1_100_00.59.18_MIG16.BMP       2022-01-06 11:25:22       173878\n",
            "GOOD/Img_SRRH_6_1_101_01.01.55_MIG16.BMP       2022-01-06 11:28:00       173878\n",
            "GOOD/Img_SRRH_6_1_102_01.04.35_MIG16.BMP       2022-01-06 11:30:40       173878\n",
            "GOOD/Img_SRRH_6_1_103_01.07.33_MIG16.BMP       2022-01-06 11:33:38       173878\n",
            "GOOD/Img_SRRH_6_1_104_01.10.21_MIG16.BMP       2022-01-06 11:36:26       173878\n",
            "GOOD/Img_SRRH_6_1_105_01.13.20_MIG16.BMP       2022-01-06 11:39:24       173878\n",
            "GOOD/Img_SRRH_6_1_106_01.16.00_MIG16.BMP       2022-01-06 11:42:04       173878\n",
            "GOOD/Img_SRRH_6_1_107_01.18.49_MIG16.BMP       2022-01-06 11:44:54       173878\n",
            "GOOD/Img_SRRH_6_1_108_01.21.29_MIG16.BMP       2022-01-06 11:47:34       173878\n",
            "GOOD/Img_SRRH_6_1_109_01.24.18_MIG16.BMP       2022-01-06 11:50:22       173878\n",
            "GOOD/Img_SRRH_6_1_110_01.27.05_MIG16.BMP       2022-01-06 11:53:10       173878\n",
            "GOOD/Img_SRRH_6_1_111_01.29.56_MIG16.BMP       2022-01-06 11:56:00       173878\n",
            "GOOD/Img_SRRH_6_1_112_01.33.33_MIG16.BMP       2022-01-06 11:59:38       173878\n",
            "GOOD/Img_SRRH_6_1_113_01.38.42_MIG16.BMP       2022-01-06 12:04:46       173878\n",
            "GOOD/Img_SRRH_6_1_115_02.04.55_MIG16.BMP       2022-01-06 12:31:00       173878\n",
            "GOOD/Img_SRRH_6_1_116_02.08.39_MIG16.BMP       2022-01-06 12:34:44       173878\n",
            "GOOD/Img_SRRH_6_1_117_02.11.52_MIG16.BMP       2022-01-06 12:37:56       173878\n",
            "GOOD/Img_SRRH_6_1_118_02.15.10_MIG16.BMP       2022-01-06 12:41:14       173878\n",
            "GOOD/Img_SRRH_6_1_119_02.18.48_MIG16.BMP       2022-01-06 12:44:54       173878\n",
            "GOOD/Img_SRRH_6_1_120_02.23.15_MIG16.BMP       2022-01-06 12:49:20       173878\n",
            "GOOD/Img_SRRH_6_1_121_02.26.36_MIG16.BMP       2022-01-06 12:52:40       173878\n",
            "GOOD/Img_SRRH_6_1_122_02.29.22_MIG16.BMP       2022-01-06 12:55:26       173878\n",
            "GOOD/Img_SRRH_6_1_123_02.32.07_MIG16.BMP       2022-01-06 12:58:12       173878\n",
            "GOOD/Img_SRRH_6_1_124_02.34.53_MIG16.BMP       2022-01-06 13:00:58       173878\n",
            "GOOD/Img_SRRH_6_1_125_02.38.45_MIG16.BMP       2022-01-06 13:04:50       173878\n",
            "GOOD/Img_SRRH_6_1_126_02.41.30_MIG16.BMP       2022-01-06 13:07:34       173878\n",
            "GOOD/Img_SRRH_6_1_127_02.44.24_MIG16.BMP       2022-01-06 13:10:28       173878\n",
            "GOOD/Img_SRRH_6_1_128_02.47.00_MIG16.BMP       2022-01-06 13:13:04       173878\n",
            "GOOD/Img_SRRH_6_1_129_02.49.56_MIG16.BMP       2022-01-06 13:16:02       173878\n",
            "GOOD/Img_SRRH_6_1_130_02.53.11_MIG16.BMP       2022-01-06 13:19:18       173878\n",
            "GOOD/Img_SRRH_6_1_131_02.56.14_MIG16.BMP       2022-01-06 13:22:20       173878\n",
            "GOOD/Img_SRRH_6_1_132_02.59.20_MIG16.BMP       2022-01-06 13:25:26       173878\n",
            "GOOD/Img_SRRH_6_1_133_03.02.34_MIG16.BMP       2022-01-06 13:28:40       173878\n",
            "GOOD/Img_SRRH_6_1_135_03.11.52_MIG16.BMP       2022-01-06 13:37:58       173878\n",
            "GOOD/Img_SRRH_6_1_136_03.16.12_MIG16.BMP       2022-01-06 13:42:18       173878\n",
            "GOOD/Img_SRRH_6_1_137_03.19.02_MIG16.BMP       2022-01-06 13:45:08       173878\n",
            "GOOD/Img_SRRH_6_1_138_03.22.05_MIG16.BMP       2022-01-06 13:48:12       173878\n",
            "GOOD/Img_SRRH_6_1_139_03.25.07_MIG16.BMP       2022-01-06 13:51:12       173878\n",
            "GOOD/Img_SRRH_6_1_140_03.29.11_MIG16.BMP       2022-01-06 13:55:16       173878\n",
            "GOOD/Img_SRRH_6_1_141_03.32.03_MIG16.BMP       2022-01-06 13:58:08       173878\n",
            "GOOD/Img_SRRH_6_1_142_03.35.09_MIG16.BMP       2022-01-06 14:01:16       173878\n",
            "GOOD/Img_SRRH_6_1_143_03.38.10_MIG16.BMP       2022-01-06 14:04:16       173878\n",
            "GOOD/Img_SRRH_6_1_144_03.41.23_MIG16.BMP       2022-01-06 14:07:28       173878\n",
            "GOOD/Img_SRRH_6_1_145_03.45.18_MIG16.BMP       2022-01-06 14:11:24       173878\n",
            "GOOD/Img_SRRH_6_1_146_03.48.44_MIG16.BMP       2022-01-06 14:14:50       173878\n",
            "GOOD/Img_SRRH_6_1_147_03.51.38_MIG16.BMP       2022-01-06 14:17:44       173878\n",
            "GOOD/Img_SRRH_6_1_148_03.54.26_MIG16.BMP       2022-01-06 14:20:32       173878\n",
            "GOOD/Img_SRRH_6_1_149_03.57.31_MIG16.BMP       2022-01-06 14:23:36       173878\n",
            "GOOD/Img_SRRH_6_1_150_04.00.33_MIG16.BMP       2022-01-06 14:26:40       173878\n",
            "GOOD/Img_SRRH_6_1_151_04.04.12_MIG16.BMP       2022-01-06 14:30:18       173878\n",
            "GOOD/Img_SRRH_6_1_152_04.07.06_MIG16.BMP       2022-01-06 14:33:12       173878\n",
            "GOOD/Img_SRRH_6_1_153_04.09.55_MIG16.BMP       2022-01-06 14:36:02       173878\n",
            "GOOD/Img_SRRH_6_1_65_22.52.36_MIG16.BMP        2022-01-06 09:18:40       173878\n",
            "GOOD/Img_SRRH_6_1_68_23.00.22_MIG16.BMP        2022-01-06 09:26:26       173878\n",
            "GOOD/Img_SRRH_6_1_69_23.03.34_MIG16.BMP        2022-01-06 09:29:38       173878\n",
            "GOOD/Img_SRRH_6_1_70_23.08.11_MIG16.BMP        2022-01-06 09:34:14       173878\n",
            "GOOD/Img_SRRH_6_1_71_23.10.56_MIG16.BMP        2022-01-06 09:37:00       173878\n",
            "GOOD/Img_SRRH_6_1_72_23.13.43_MIG16.BMP        2022-01-06 09:39:48       173878\n",
            "GOOD/Img_SRRH_6_1_74_23.37.07_MIG16.BMP        2022-01-06 10:03:12       173878\n",
            "GOOD/Img_SRRH_6_1_75_23.40.13_MIG16.BMP        2022-01-06 10:06:18       173878\n",
            "GOOD/Img_SRRH_6_1_76_23.43.14_MIG16.BMP        2022-01-06 10:09:18       173878\n",
            "GOOD/Img_SRRH_6_1_77_23.46.52_MIG16.BMP        2022-01-06 10:12:56       173878\n",
            "GOOD/Img_SRRH_6_1_78_23.49.40_MIG16.BMP        2022-01-06 10:15:44       173878\n",
            "GOOD/Img_SRRH_6_1_79_23.52.47_MIG16.BMP        2022-01-06 10:18:52       173878\n",
            "GOOD/Img_SRRH_6_1_80_23.55.28_MIG16.BMP        2022-01-06 10:21:32       173878\n",
            "GOOD/Img_SRRH_6_1_81_23.58.50_MIG16.BMP        2022-01-06 10:24:54       173878\n",
            "GOOD/Img_SRRH_6_1_82_00.01.34_MIG16.BMP        2022-01-06 10:27:38       173878\n",
            "GOOD/Img_SRRH_6_1_83_00.04.23_MIG16.BMP        2022-01-06 10:30:28       173878\n",
            "GOOD/Img_SRRH_6_1_84_00.07.09_MIG16.BMP        2022-01-06 10:33:14       173878\n",
            "GOOD/Img_SRRH_6_1_85_00.10.00_MIG16.BMP        2022-01-06 10:36:04       173878\n",
            "GOOD/Img_SRRH_6_1_86_00.12.47_MIG16.BMP        2022-01-06 10:38:52       173878\n",
            "GOOD/Img_SRRH_6_1_87_00.15.59_MIG16.BMP        2022-01-06 10:42:04       173878\n",
            "GOOD/Img_SRRH_6_1_88_00.18.43_MIG16.BMP        2022-01-06 10:44:48       173878\n",
            "GOOD/Img_SRRH_6_1_89_00.21.29_MIG16.BMP        2022-01-06 10:47:34       173878\n",
            "GOOD/Img_SRRH_6_1_90_00.26.54_MIG16.BMP        2022-01-06 10:52:58       173878\n",
            "GOOD/Img_SRRH_6_1_91_00.29.39_MIG16.BMP        2022-01-06 10:55:44       173878\n",
            "GOOD/Img_SRRH_6_1_93_00.35.13_MIG16.BMP        2022-01-06 11:01:18       173878\n",
            "GOOD/Img_SRRH_6_1_94_00.38.30_MIG16.BMP        2022-01-06 11:04:34       173878\n",
            "GOOD/Img_SRRH_6_1_96_00.45.16_MIG16.BMP        2022-01-06 11:11:20       173878\n",
            "GOOD/Img_SRRH_6_1_98_00.53.33_MIG16.BMP        2022-01-06 11:19:38       173878\n",
            "GOOD/Img_SRRH_6_1_99_00.56.26_MIG16.BMP        2022-01-06 11:22:30       173878\n",
            "GOOD/Img_SRRH_6_2_0_04.12.55_MIG16.BMP         2022-01-06 14:39:02       173878\n",
            "GOOD/Img_SRRH_6_2_12_06.05.52_MIG16.BMP        2022-01-06 16:31:58       173878\n",
            "GOOD/Img_SRRH_6_2_13_06.09.36_MIG16.BMP        2022-01-06 16:35:42       173878\n",
            "GOOD/Img_SRRH_6_2_14_06.17.01_MIG16.BMP        2022-01-06 16:43:06       173878\n",
            "GOOD/Img_SRRH_6_2_15_06.23.37_MIG16.BMP        2022-01-06 16:49:42       173878\n",
            "GOOD/Img_SRRH_6_2_16_06.28.24_MIG16.BMP        2022-01-06 16:54:30       173878\n",
            "GOOD/Img_SRRH_6_2_17_06.32.59_MIG16.BMP        2022-01-06 16:59:06       173878\n",
            "GOOD/Img_SRRH_6_2_18_06.37.37_MIG16.BMP        2022-01-06 17:03:42       173878\n",
            "GOOD/Img_SRRH_6_2_19_06.41.53_MIG16.BMP        2022-01-06 17:08:00       173878\n",
            "GOOD/Img_SRRH_6_2_1_04.18.40_MIG16.BMP         2022-01-06 14:44:46       173878\n",
            "GOOD/Img_SRRH_6_2_20_06.45.53_MIG16.BMP        2022-01-06 17:12:00       173878\n",
            "GOOD/Img_SRRH_6_2_21_06.50.11_MIG16.BMP        2022-01-06 17:16:16       173878\n",
            "GOOD/Img_SRRH_6_2_22_06.56.21_MIG16.BMP        2022-01-06 17:22:26       173878\n",
            "GOOD/Img_SRRH_6_2_23_07.00.07_MIG16.BMP        2022-01-06 17:26:12       173878\n",
            "GOOD/Img_SRRH_6_2_24_07.04.23_MIG16.BMP        2022-01-06 17:30:30       173878\n",
            "GOOD/Img_SRRH_6_2_25_07.09.11_MIG16.BMP        2022-01-06 17:35:18       173878\n",
            "GOOD/Img_SRRH_6_2_26_07.23.59_MIG16.BMP        2022-01-06 17:50:04       173878\n",
            "GOOD/Img_SRRH_6_2_27_07.28.10_MIG16.BMP        2022-01-06 17:54:16       173878\n",
            "GOOD/Img_SRRH_6_2_28_07.32.09_MIG16.BMP        2022-01-06 17:58:16       173878\n",
            "GOOD/Img_SRRH_6_2_29_07.36.26_MIG16.BMP        2022-01-06 18:02:32       173878\n",
            "GOOD/Img_SRRH_6_2_30_07.41.26_MIG16.BMP        2022-01-06 18:07:32       173878\n",
            "GOOD/Img_SRRH_6_2_31_07.46.40_MIG16.BMP        2022-01-06 18:12:46       173878\n",
            "GOOD/Img_SRRH_6_2_32_07.50.56_MIG16.BMP        2022-01-06 18:17:02       173878\n",
            "GOOD/Img_SRRH_6_2_33_08.01.09_MIG16.BMP        2022-01-06 18:27:16       173878\n",
            "GOOD/Img_SRRH_6_2_34_08.05.58_MIG16.BMP        2022-01-06 18:32:04       173878\n",
            "GOOD/Img_SRRH_6_2_35_08.13.38_MIG16.BMP        2022-01-06 18:39:44       173878\n",
            "GOOD/Img_SRRH_6_2_36_08.18.06_MIG16.BMP        2022-01-06 18:44:12       173878\n",
            "GOOD/Img_SRRH_6_2_37_08.25.33_MIG16.BMP        2022-01-06 18:51:40       173878\n",
            "GOOD/Img_SRRH_6_2_38_08.31.07_MIG16.BMP        2022-01-06 18:57:14       173878\n",
            "GOOD/Img_SRRH_6_2_39_08.34.44_MIG16.BMP        2022-01-06 19:00:50       173878\n",
            "GOOD/Img_SRRH_6_2_39_08.36.42_MIG16.BMP        2022-01-06 19:02:48       173878\n",
            "GOOD/Img_SRRH_6_2_3_05.24.45_MIG16.BMP         2022-01-06 15:50:50       173878\n",
            "GOOD/Img_SRRH_6_2_41_08.41.49_MIG16.BMP        2022-01-06 19:07:56       173878\n",
            "GOOD/Img_SRRH_6_2_42_08.44.37_MIG16.BMP        2022-01-06 19:10:44       173878\n",
            "GOOD/Img_SRRH_6_2_43_08.53.15_MIG16.BMP        2022-01-06 19:19:22       173878\n",
            "GOOD/Img_SRRH_6_2_44_08.56.41_MIG16.BMP        2022-01-06 19:22:48       173878\n",
            "GOOD/Img_SRRH_6_2_45_09.01.00_MIG16.BMP        2022-01-06 19:27:06       173878\n",
            "GOOD/Img_SRRH_6_2_46_09.04.17_MIG16.BMP        2022-01-06 19:30:24       173878\n",
            "GOOD/Img_SRRH_6_2_47_09.07.02_MIG16.BMP        2022-01-06 19:33:08       173878\n",
            "GOOD/Img_SRRH_6_2_48_09.11.04_MIG16.BMP        2022-01-06 19:37:10       173878\n",
            "GOOD/Img_SRRH_6_2_49_09.15.28_MIG16.BMP        2022-01-06 19:41:34       173878\n",
            "GOOD/Img_SRRH_6_2_4_05.28.41_MIG16.BMP         2022-01-06 15:54:48       173878\n",
            "GOOD/Img_SRRH_6_2_50_09.18.07_MIG16.BMP        2022-01-06 19:44:14       173878\n",
            "GOOD/Img_SRRH_6_2_51_09.20.49_MIG16.BMP        2022-01-06 19:46:56       173878\n",
            "GOOD/Img_SRRH_6_2_52_09.23.53_MIG16.BMP        2022-01-06 19:50:00       173878\n",
            "GOOD/Img_SRRH_6_2_53_09.26.20_MIG16.BMP        2022-01-06 19:52:26       173878\n",
            "GOOD/Img_SRRH_6_2_54_09.30.15_MIG16.BMP        2022-01-06 19:56:20       173878\n",
            "GOOD/Img_SRRH_6_2_55_09.33.32_MIG16.BMP        2022-01-06 19:59:38       173878\n",
            "GOOD/Img_SRRH_6_2_56_09.37.09_MIG16.BMP        2022-01-06 20:03:16       173878\n",
            "GOOD/Img_SRRH_6_2_57_09.40.18_MIG16.BMP        2022-01-06 20:06:24       173878\n",
            "GOOD/Img_SRRH_6_2_5_05.32.41_MIG16.BMP         2022-01-06 15:58:48       173878\n",
            "GOOD/Img_SRRH_6_2_60_09.57.50_MIG16.BMP        2022-01-06 20:23:56       173878\n",
            "GOOD/Img_SRRH_6_2_61_10.04.13_MIG16.BMP        2022-01-06 20:30:20       173878\n",
            "GOOD/Img_SRRH_6_2_63_10.13.59_MIG16.BMP        2022-01-06 20:40:06       173878\n",
            "GOOD/Img_SRRH_6_2_64_10.22.01_MIG16.BMP        2022-01-06 20:48:08       173878\n",
            "GOOD/Img_SRRH_6_2_65_10.20.32_MIG16.BMP        2022-01-06 20:46:38       173878\n",
            "GOOD/Img_SRRH_6_2_66_10.28.46_MIG16.BMP        2022-01-06 20:54:52       173878\n",
            "GOOD/Img_SRRH_6_2_67_10.32.43_MIG16.BMP        2022-01-06 20:58:50       173878\n",
            "GOOD/Img_SRRH_6_2_68_10.41.31_MIG16.BMP        2022-01-06 21:07:38       173878\n",
            "GOOD/Img_SRRH_6_2_69_10.48.41_MIG16.BMP        2022-01-06 21:14:48       173878\n",
            "GOOD/Img_SRRH_6_2_6_05.37.20_MIG16.BMP         2022-01-06 16:03:26       173878\n",
            "GOOD/Img_SRRH_6_2_70_10.53.10_MIG16.BMP        2022-01-06 21:19:16       173878\n",
            "GOOD/Img_SRRH_6_2_71_10.56.33_MIG16.BMP        2022-01-06 21:22:40       173878\n",
            "GOOD/Img_SRRH_6_2_72_11.00.15_MIG16.BMP        2022-01-06 21:26:22       173878\n",
            "GOOD/Img_SRRH_6_2_73_11.15.22_MIG16.BMP        2022-01-06 21:41:28       173878\n",
            "GOOD/Img_SRRH_6_2_74_11.29.35_MIG16.BMP        2022-01-06 21:55:42       173878\n",
            "GOOD/Img_SRRH_6_2_76_11.37.52_MIG16.BMP        2022-01-06 22:03:58       173878\n",
            "GOOD/Img_SRRH_6_2_77_11.40.33_MIG16.BMP        2022-01-06 22:06:40       173878\n",
            "GOOD/Img_SRRH_6_2_78_11.43.20_MIG16.BMP        2022-01-06 22:09:26       173878\n",
            "GOOD/Img_SRRH_6_2_79_11.46.10_MIG16.BMP        2022-01-06 22:12:16       173878\n",
            "GOOD/Img_SRRH_6_2_80_11.48.55_MIG16.BMP        2022-01-06 22:15:02       173878\n",
            "GOOD/Img_SRRH_6_2_81_11.51.40_MIG16.BMP        2022-01-06 22:17:46       173878\n",
            "GOOD/Img_SRRH_6_2_82_11.54.36_MIG16.BMP        2022-01-06 22:20:42       173878\n",
            "GOOD/Img_SRRH_6_2_83_11.57.40_MIG16.BMP        2022-01-06 22:23:46       173878\n",
            "GOOD/Img_SRRH_6_2_84_12.00.25_MIG16.BMP        2022-01-06 22:26:32       173878\n",
            "GOOD/Img_SRRH_6_2_85_12.05.19_MIG16.BMP        2022-01-06 22:31:26       173878\n",
            "GOOD/Img_SRRH_6_2_86_12.07.44_MIG16.BMP        2022-01-06 22:33:50       173878\n",
            "GOOD/Img_SRRH_6_2_87_12.10.36_MIG16.BMP        2022-01-06 22:36:42       173878\n",
            "GOOD/Img_SRRH_6_2_88_12.13.40_MIG16.BMP        2022-01-06 22:39:46       173878\n",
            "GOOD/Img_SRRH_6_2_89_12.16.01_MIG16.BMP        2022-01-06 22:42:08       173878\n",
            "GOOD/Img_SRRH_6_2_8_05.45.30_MIG16.BMP         2022-01-06 16:11:36       173878\n",
            "GOOD/Img_SRRH_6_2_90_12.18.47_MIG16.BMP        2022-01-06 22:44:54       173878\n",
            "GOOD/Img_SRRH_6_2_91_12.43.23_MIG16.BMP        2022-01-06 23:09:30       173878\n",
            "GOOD/Img_SRRH_6_2_93_13.01.54_MIG16.BMP        2022-01-06 23:28:00       173878\n",
            "GOOD/Img_SRRH_6_2_94_13.04.40_MIG16.BMP        2022-01-06 23:30:48       173878\n",
            "GOOD/Img_SRRH_6_2_95_13.07.34_MIG16.BMP        2022-01-06 23:33:40       173878\n",
            "GOOD/Img_SRRH_6_2_96_13.10.39_MIG16.BMP        2022-01-06 23:36:46       173878\n",
            "GOOD/Img_SRRH_6_2_9_05.49.17_MIG16.BMP         2022-01-06 16:15:22       173878\n",
            "GOOD/Img_SRRH_70_2_2_00.48.22_MIG16.BMP        2022-03-11 15:45:44       173878\n",
            "GOOD/Img_SRRH_70_2_3_00.53.48_MIG16.BMP        2022-03-11 15:51:10       173878\n",
            "GOOD/Img_SRRH_70_2_4_00.57.57_MIG16.BMP        2022-03-11 15:55:18       173878\n",
            "GOOD/Img_SRRH_70_2_5_01.05.04_MIG16.BMP        2022-03-11 16:02:26       173878\n",
            "GOOD/Img_SRRH_70_2_6_01.11.22_MIG16.BMP        2022-03-11 16:08:44       173878\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_names = [\"Good\", \"Bad\"]\n",
        "Good_data_dir = '/content/GOOD'\n",
        "Bad_data_dir = '/content/BAD'\n",
        "nb_good_samples = sum([len(files) for _, _, files in os.walk(Good_data_dir)])\n",
        "nb_bad_samples = sum([len(files) for _, _, files in os.walk(Bad_data_dir)])\n",
        "print('\\n - names of label (Binary): ', target_names)\n",
        "print(' - # of train samples: ', nb_good_samples, '\\n - # of validation samples: ', nb_bad_samples)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83JZP_rPU_AD",
        "outputId": "0b61b0ca-ed7f-48ae-a014-b068d67155cc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " - names of label (Binary):  ['Good', 'Bad']\n",
            " - # of train samples:  900 \n",
            " - # of validation samples:  108\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def assigning_label(img,weld_type):\n",
        "    return weld_type\n",
        "\n",
        "def make_train_data(weld_type,DIR):\n",
        "    for img in tqdm(os.listdir(DIR)):\n",
        "        label=assigning_label(img,weld_type)\n",
        "        path = os.path.join(DIR,img)\n",
        "        img = cv2.imread(path,cv2.IMREAD_COLOR)\n",
        "        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n",
        "        \n",
        "        X.append(np.array(img))\n",
        "        y.append(str(label))\n",
        "\n",
        "np.random.seed(45)\n",
        "tf.random.set_seed(45)\n",
        "X=[]\n",
        "y=[]\n",
        "IMG_SIZE=150"
      ],
      "metadata": {
        "id": "E5oP_XrMVYEp"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create training data\n",
        "make_train_data('Good',Good_data_dir)\n",
        "make_train_data('Bad',Bad_data_dir)\n",
        "print(len(X))\n",
        "\n",
        "labelEncoder=LabelEncoder()\n",
        "y=labelEncoder.fit_transform(y)\n",
        "y=to_categorical(y,2)\n",
        "X=np.array(X)\n",
        "X=X/255"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlEDsdbHIl56",
        "outputId": "041d889c-59b2-42de-c39a-a604ebec6692"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 900/900 [00:00<00:00, 1275.54it/s]\n",
            "100%|██████████| 108/108 [00:00<00:00, 1412.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1008\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "split = StratifiedShuffleSplit(n_splits=1, test_size=0.25, random_state=45)\n",
        "for train_index, test_index in split.split(X,y):\n",
        "    X_train = X[train_index]\n",
        "    X_test = X[test_index]\n",
        "    y_train = y[train_index]\n",
        "    y_test = y[test_index]"
      ],
      "metadata": {
        "id": "mk2z244pKRKf"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUJGaBkIKo_t",
        "outputId": "fc71d6e3-d9f8-41b0-9500-9819893fb05c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(756, 150, 150, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNv9pObRKzqs",
        "outputId": "09d69e61-0ba5-4fd6-cbcb-fd018bafd42e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(756, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWzppYsFupgi",
        "outputId": "09cf4679-1cea-4b2b-befd-d942eae49997"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(252, 150, 150, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYDrFZMJusB1",
        "outputId": "80210a36-ed30-42fe-e8f2-6d095450c1f9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(252, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[1:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VkOzIVGxI62",
        "outputId": "3a00f7db-f731-4317-a67e-48fccc2c7fed"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qaH7Uw6fyI_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_width = 150 \n",
        "img_height = 150"
      ],
      "metadata": {
        "id": "UDd2jEzW0T5f"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# configure a VGG16 module\n",
        "model_vgg16 = applications.VGG16(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))\n",
        "model_vgg16.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZV1oZyP31CJp",
        "outputId": "7f5a919f-5969-4eec-ba13-2af131de53aa"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 150, 150, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 150, 150, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 150, 150, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 75, 75, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 75, 75, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 75, 75, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 37, 37, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 37, 37, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 37, 37, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 37, 37, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 18, 18, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 18, 18, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 9, 9, 512)         0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model 1: VGG16 top layer removed and add fully connected layers (one with 256 nodes using ‘relu’ activation and output layer with 2 nodes and ‘softmax’ activation)\n",
        "for layer in model_vgg16.layers:\n",
        "    layer.trainable = False\n",
        "    \n",
        "for i, layer in enumerate(model_vgg16.layers):\n",
        "    print(i, layer.name, layer.trainable)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwKK1udKtDtY",
        "outputId": "65090e69-4d98-45d9-fb65-9eda8800910b"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 input_2 False\n",
            "1 block1_conv1 False\n",
            "2 block1_conv2 False\n",
            "3 block1_pool False\n",
            "4 block2_conv1 False\n",
            "5 block2_conv2 False\n",
            "6 block2_pool False\n",
            "7 block3_conv1 False\n",
            "8 block3_conv2 False\n",
            "9 block3_conv3 False\n",
            "10 block3_pool False\n",
            "11 block4_conv1 False\n",
            "12 block4_conv2 False\n",
            "13 block4_conv3 False\n",
            "14 block4_pool False\n",
            "15 block5_conv1 False\n",
            "16 block5_conv2 False\n",
            "17 block5_conv3 False\n",
            "18 block5_pool False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def model_1(learn_rate=0.001):\n",
        "    model_1 = tf.keras.Sequential([\n",
        "      model_vgg16,\n",
        "      tf.keras.layers.Flatten(name='flatten'),\n",
        "      tf.keras.layers.Dense(256, activation='relu', name='new_fc1', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "      tf.keras.layers.Dropout(0.5),\n",
        "      tf.keras.layers.Dense(2, activation='softmax', name='new_predictions')\n",
        "      ])\n",
        "    model_1.compile(loss = \"categorical_crossentropy\", optimizer = 'Adam', metrics=[\"accuracy\"])\n",
        "    return model_1"
      ],
      "metadata": {
        "id": "lw8CiS3z4HNv"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fine tune the model using grid search and early stopping\n",
        "checkpoint_path = './model_vgg16_frozen.h5'\n",
        "early_stop = EarlyStopping(monitor='accuracy', verbose=2, patience=5)\n",
        "model_checkpoint = ModelCheckpoint(filepath=checkpoint_path, monitor='accuracy', verbose=2, \n",
        "                     save_best_only=True)\n",
        "\n",
        "learn_rate = [0.0001,0.01]\n",
        "batch_size = [32,100]\n",
        "epochs = [5]\n",
        "classifier = KerasClassifier(build_fn=model_1)\n",
        "\n",
        "param_grid = dict(epochs=epochs, batch_size=batch_size, learn_rate = learn_rate)\n",
        "fit_model_1 = GridSearchCV(estimator = classifier, param_grid=param_grid, cv=5)\n",
        "\n",
        "grid_result_1 = fit_model_1.fit(X_train,y_train, verbose=2, callbacks=[early_stop,model_checkpoint])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQ9cqpRe8Pwz",
        "outputId": "8e511ec1-21a7-433d-80f8-47931b292c18"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\n",
            "Epoch 1: accuracy improved from -inf to 0.86093, saving model to ./model_vgg16_frozen.h5\n",
            "19/19 - 17s - loss: 3.0007 - accuracy: 0.8609 - 17s/epoch - 870ms/step\n",
            "Epoch 2/5\n",
            "\n",
            "Epoch 2: accuracy improved from 0.86093 to 0.90397, saving model to ./model_vgg16_frozen.h5\n",
            "19/19 - 3s - loss: 0.8090 - accuracy: 0.9040 - 3s/epoch - 160ms/step\n",
            "Epoch 3/5\n",
            "\n",
            "Epoch 3: accuracy improved from 0.90397 to 0.92715, saving model to ./model_vgg16_frozen.h5\n",
            "19/19 - 3s - loss: 0.5714 - accuracy: 0.9272 - 3s/epoch - 160ms/step\n",
            "Epoch 4/5\n",
            "\n",
            "Epoch 4: accuracy improved from 0.92715 to 0.94868, saving model to ./model_vgg16_frozen.h5\n",
            "19/19 - 3s - loss: 0.4219 - accuracy: 0.9487 - 3s/epoch - 159ms/step\n",
            "Epoch 5/5\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.94868\n",
            "19/19 - 3s - loss: 0.3616 - accuracy: 0.9487 - 3s/epoch - 147ms/step\n",
            "5/5 [==============================] - 3s 575ms/step - loss: 0.4015 - accuracy: 0.9145\n",
            "Epoch 1/5\n",
            "\n",
            "Epoch 1: accuracy did not improve from 0.94868\n",
            "19/19 - 6s - loss: 2.8765 - accuracy: 0.8661 - 6s/epoch - 295ms/step\n",
            "Epoch 2/5\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.94868\n",
            "19/19 - 3s - loss: 0.7237 - accuracy: 0.9157 - 3s/epoch - 148ms/step\n",
            "Epoch 3/5\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.94868\n",
            "19/19 - 3s - loss: 0.4932 - accuracy: 0.9471 - 3s/epoch - 148ms/step\n",
            "Epoch 4/5\n",
            "\n",
            "Epoch 4: accuracy improved from 0.94868 to 0.95372, saving model to ./model_vgg16_frozen.h5\n",
            "19/19 - 3s - loss: 0.3827 - accuracy: 0.9537 - 3s/epoch - 160ms/step\n",
            "Epoch 5/5\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.95372\n",
            "19/19 - 3s - loss: 0.3394 - accuracy: 0.9521 - 3s/epoch - 149ms/step\n",
            "5/5 [==============================] - 3s 584ms/step - loss: 0.3451 - accuracy: 0.9470\n",
            "Epoch 1/5\n",
            "\n",
            "Epoch 1: accuracy did not improve from 0.95372\n",
            "19/19 - 4s - loss: 2.8431 - accuracy: 0.8430 - 4s/epoch - 192ms/step\n",
            "Epoch 2/5\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.95372\n",
            "19/19 - 3s - loss: 0.7360 - accuracy: 0.8876 - 3s/epoch - 148ms/step\n",
            "Epoch 3/5\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.95372\n",
            "19/19 - 3s - loss: 0.5008 - accuracy: 0.9322 - 3s/epoch - 149ms/step\n",
            "Epoch 4/5\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.95372\n",
            "19/19 - 3s - loss: 0.3978 - accuracy: 0.9471 - 3s/epoch - 148ms/step\n",
            "Epoch 5/5\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.95372\n",
            "19/19 - 3s - loss: 0.3505 - accuracy: 0.9504 - 3s/epoch - 148ms/step\n",
            "5/5 [==============================] - 1s 163ms/step - loss: 0.2486 - accuracy: 0.9868\n",
            "Epoch 1/5\n",
            "\n",
            "Epoch 1: accuracy did not improve from 0.95372\n",
            "19/19 - 4s - loss: 2.8266 - accuracy: 0.8694 - 4s/epoch - 195ms/step\n",
            "Epoch 2/5\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.95372\n",
            "19/19 - 3s - loss: 0.7250 - accuracy: 0.8975 - 3s/epoch - 148ms/step\n",
            "Epoch 3/5\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.95372\n",
            "19/19 - 3s - loss: 0.4823 - accuracy: 0.9421 - 3s/epoch - 147ms/step\n",
            "Epoch 4/5\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.95372\n",
            "19/19 - 3s - loss: 0.3935 - accuracy: 0.9388 - 3s/epoch - 147ms/step\n",
            "Epoch 5/5\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.95372\n",
            "19/19 - 3s - loss: 0.3332 - accuracy: 0.9438 - 3s/epoch - 147ms/step\n",
            "5/5 [==============================] - 1s 149ms/step - loss: 0.2946 - accuracy: 0.9205\n",
            "Epoch 1/5\n",
            "\n",
            "Epoch 1: accuracy did not improve from 0.95372\n",
            "19/19 - 4s - loss: 2.9050 - accuracy: 0.8298 - 4s/epoch - 190ms/step\n",
            "Epoch 2/5\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.95372\n",
            "19/19 - 3s - loss: 0.7476 - accuracy: 0.8760 - 3s/epoch - 147ms/step\n",
            "Epoch 3/5\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.95372\n",
            "19/19 - 3s - loss: 0.5202 - accuracy: 0.9174 - 3s/epoch - 148ms/step\n",
            "Epoch 4/5\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.95372\n",
            "19/19 - 3s - loss: 0.3891 - accuracy: 0.9488 - 3s/epoch - 147ms/step\n",
            "Epoch 5/5\n",
            "\n",
            "Epoch 5: accuracy improved from 0.95372 to 0.95702, saving model to ./model_vgg16_frozen.h5\n",
            "19/19 - 3s - loss: 0.3315 - accuracy: 0.9570 - 3s/epoch - 160ms/step\n",
            "5/5 [==============================] - 1s 167ms/step - loss: 0.2585 - accuracy: 0.9868\n",
            "Epoch 1/5\n",
            "\n",
            "Epoch 1: accuracy did not improve from 0.95702\n",
            "19/19 - 4s - loss: 3.1153 - accuracy: 0.8560 - 4s/epoch - 190ms/step\n",
            "Epoch 2/5\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.95702\n",
            "19/19 - 3s - loss: 0.8438 - accuracy: 0.9023 - 3s/epoch - 148ms/step\n",
            "Epoch 3/5\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.95702\n",
            "19/19 - 3s - loss: 0.5813 - accuracy: 0.9272 - 3s/epoch - 147ms/step\n",
            "Epoch 4/5\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.95702\n",
            "19/19 - 3s - loss: 0.4384 - accuracy: 0.9570 - 3s/epoch - 148ms/step\n",
            "Epoch 5/5\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.95702\n",
            "19/19 - 3s - loss: 0.3622 - accuracy: 0.9520 - 3s/epoch - 148ms/step\n",
            "5/5 [==============================] - 1s 150ms/step - loss: 0.4033 - accuracy: 0.9145\n",
            "Epoch 1/5\n",
            "\n",
            "Epoch 1: accuracy did not improve from 0.95702\n",
            "19/19 - 4s - loss: 3.1603 - accuracy: 0.8331 - 4s/epoch - 209ms/step\n",
            "Epoch 2/5\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.95702\n",
            "19/19 - 3s - loss: 0.8727 - accuracy: 0.8992 - 3s/epoch - 148ms/step\n",
            "Epoch 3/5\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.95702\n",
            "19/19 - 3s - loss: 0.5809 - accuracy: 0.9488 - 3s/epoch - 148ms/step\n",
            "Epoch 4/5\n",
            "\n",
            "Epoch 4: accuracy improved from 0.95702 to 0.96033, saving model to ./model_vgg16_frozen.h5\n",
            "19/19 - 3s - loss: 0.4773 - accuracy: 0.9603 - 3s/epoch - 162ms/step\n",
            "Epoch 5/5\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.96033\n",
            "19/19 - 3s - loss: 0.3971 - accuracy: 0.9570 - 3s/epoch - 148ms/step\n",
            "5/5 [==============================] - 1s 160ms/step - loss: 0.3870 - accuracy: 0.9470\n",
            "Epoch 1/5\n",
            "\n",
            "Epoch 1: accuracy did not improve from 0.96033\n",
            "19/19 - 4s - loss: 3.1599 - accuracy: 0.8248 - 4s/epoch - 191ms/step\n",
            "Epoch 2/5\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.96033\n",
            "19/19 - 3s - loss: 0.9146 - accuracy: 0.8909 - 3s/epoch - 147ms/step\n",
            "Epoch 3/5\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.96033\n",
            "19/19 - 3s - loss: 0.6423 - accuracy: 0.9124 - 3s/epoch - 148ms/step\n",
            "Epoch 4/5\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.96033\n",
            "19/19 - 3s - loss: 0.4884 - accuracy: 0.9554 - 3s/epoch - 148ms/step\n",
            "Epoch 5/5\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.96033\n",
            "19/19 - 3s - loss: 0.4357 - accuracy: 0.9388 - 3s/epoch - 148ms/step\n",
            "5/5 [==============================] - 1s 148ms/step - loss: 0.3341 - accuracy: 0.9669\n",
            "Epoch 1/5\n",
            "\n",
            "Epoch 1: accuracy did not improve from 0.96033\n",
            "19/19 - 4s - loss: 2.9573 - accuracy: 0.8463 - 4s/epoch - 191ms/step\n",
            "Epoch 2/5\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.96033\n",
            "19/19 - 3s - loss: 0.8146 - accuracy: 0.8810 - 3s/epoch - 148ms/step\n",
            "Epoch 3/5\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.96033\n",
            "19/19 - 3s - loss: 0.5538 - accuracy: 0.9124 - 3s/epoch - 148ms/step\n",
            "Epoch 4/5\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.96033\n",
            "19/19 - 3s - loss: 0.4364 - accuracy: 0.9322 - 3s/epoch - 149ms/step\n",
            "Epoch 5/5\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.96033\n",
            "19/19 - 3s - loss: 0.3747 - accuracy: 0.9405 - 3s/epoch - 149ms/step\n",
            "5/5 [==============================] - 1s 149ms/step - loss: 0.3352 - accuracy: 0.9205\n",
            "Epoch 1/5\n",
            "\n",
            "Epoch 1: accuracy did not improve from 0.96033\n",
            "19/19 - 4s - loss: 2.6936 - accuracy: 0.8595 - 4s/epoch - 192ms/step\n",
            "Epoch 2/5\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.96033\n",
            "19/19 - 3s - loss: 0.6683 - accuracy: 0.9091 - 3s/epoch - 148ms/step\n",
            "Epoch 3/5\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.96033\n",
            "19/19 - 3s - loss: 0.4498 - accuracy: 0.9372 - 3s/epoch - 148ms/step\n",
            "Epoch 4/5\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.96033\n",
            "19/19 - 3s - loss: 0.3251 - accuracy: 0.9521 - 3s/epoch - 148ms/step\n",
            "Epoch 5/5\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.96033\n",
            "19/19 - 3s - loss: 0.2881 - accuracy: 0.9570 - 3s/epoch - 148ms/step\n",
            "5/5 [==============================] - 1s 164ms/step - loss: 0.2336 - accuracy: 0.9735\n",
            "Epoch 1/5\n",
            "\n",
            "Epoch 1: accuracy did not improve from 0.96033\n",
            "7/7 - 10s - loss: 4.8908 - accuracy: 0.8377 - 10s/epoch - 1s/step\n",
            "Epoch 2/5\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.96033\n",
            "7/7 - 3s - loss: 2.2247 - accuracy: 0.8493 - 3s/epoch - 382ms/step\n",
            "Epoch 3/5\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.96033\n",
            "7/7 - 3s - loss: 1.2478 - accuracy: 0.8957 - 3s/epoch - 382ms/step\n",
            "Epoch 4/5\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.96033\n",
            "7/7 - 3s - loss: 0.7320 - accuracy: 0.9172 - 3s/epoch - 381ms/step\n",
            "Epoch 5/5\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.96033\n",
            "7/7 - 3s - loss: 0.6791 - accuracy: 0.9007 - 3s/epoch - 379ms/step\n",
            "2/2 [==============================] - 4s 3s/step - loss: 0.6758 - accuracy: 0.8816\n",
            "Epoch 1/5\n",
            "\n",
            "Epoch 1: accuracy did not improve from 0.96033\n",
            "7/7 - 4s - loss: 4.6786 - accuracy: 0.8215 - 4s/epoch - 635ms/step\n",
            "Epoch 2/5\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.96033\n",
            "7/7 - 3s - loss: 2.1806 - accuracy: 0.8810 - 3s/epoch - 382ms/step\n",
            "Epoch 3/5\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.96033\n",
            "7/7 - 3s - loss: 1.1487 - accuracy: 0.8975 - 3s/epoch - 383ms/step\n",
            "Epoch 4/5\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.96033\n",
            "7/7 - 3s - loss: 0.8946 - accuracy: 0.8579 - 3s/epoch - 383ms/step\n",
            "Epoch 5/5\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.96033\n",
            "7/7 - 3s - loss: 0.5973 - accuracy: 0.9322 - 3s/epoch - 382ms/step\n",
            "2/2 [==============================] - 4s 3s/step - loss: 0.5641 - accuracy: 0.9272\n",
            "Epoch 1/5\n",
            "\n",
            "Epoch 1: accuracy did not improve from 0.96033\n",
            "7/7 - 4s - loss: 4.6558 - accuracy: 0.8364 - 4s/epoch - 504ms/step\n",
            "Epoch 2/5\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.96033\n",
            "7/7 - 3s - loss: 2.1456 - accuracy: 0.8893 - 3s/epoch - 382ms/step\n",
            "Epoch 3/5\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.96033\n",
            "7/7 - 3s - loss: 1.1439 - accuracy: 0.8893 - 3s/epoch - 382ms/step\n",
            "Epoch 4/5\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.96033\n",
            "7/7 - 3s - loss: 0.7268 - accuracy: 0.9058 - 3s/epoch - 383ms/step\n",
            "Epoch 5/5\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.96033\n",
            "7/7 - 3s - loss: 0.6192 - accuracy: 0.9157 - 3s/epoch - 382ms/step\n",
            "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa5e5757170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 1s 255ms/step - loss: 0.6362 - accuracy: 0.9470\n",
            "Epoch 1/5\n",
            "\n",
            "Epoch 1: accuracy did not improve from 0.96033\n",
            "7/7 - 3s - loss: 4.9812 - accuracy: 0.8612 - 3s/epoch - 499ms/step\n",
            "Epoch 2/5\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.96033\n",
            "7/7 - 3s - loss: 2.2479 - accuracy: 0.8364 - 3s/epoch - 381ms/step\n",
            "Epoch 3/5\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.96033\n",
            "7/7 - 3s - loss: 1.2757 - accuracy: 0.8959 - 3s/epoch - 381ms/step\n",
            "Epoch 4/5\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.96033\n",
            "7/7 - 3s - loss: 0.8628 - accuracy: 0.8959 - 3s/epoch - 382ms/step\n",
            "Epoch 5/5\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.96033\n",
            "7/7 - 3s - loss: 0.6462 - accuracy: 0.9322 - 3s/epoch - 380ms/step\n",
            "WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa5735eeb00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 1s 253ms/step - loss: 0.5453 - accuracy: 0.9603\n",
            "Epoch 1/5\n",
            "\n",
            "Epoch 1: accuracy did not improve from 0.96033\n",
            "7/7 - 4s - loss: 4.9122 - accuracy: 0.8562 - 4s/epoch - 504ms/step\n",
            "Epoch 2/5\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.96033\n",
            "7/7 - 3s - loss: 2.1783 - accuracy: 0.8364 - 3s/epoch - 386ms/step\n",
            "Epoch 3/5\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.96033\n",
            "7/7 - 3s - loss: 1.1806 - accuracy: 0.8744 - 3s/epoch - 383ms/step\n",
            "Epoch 4/5\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.96033\n",
            "7/7 - 3s - loss: 0.7499 - accuracy: 0.8975 - 3s/epoch - 383ms/step\n",
            "Epoch 5/5\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.96033\n",
            "7/7 - 3s - loss: 0.6227 - accuracy: 0.9041 - 3s/epoch - 382ms/step\n",
            "2/2 [==============================] - 1s 271ms/step - loss: 0.4954 - accuracy: 0.9735\n",
            "Epoch 1/5\n",
            "\n",
            "Epoch 1: accuracy did not improve from 0.96033\n",
            "7/7 - 4s - loss: 4.5708 - accuracy: 0.8096 - 4s/epoch - 504ms/step\n",
            "Epoch 2/5\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.96033\n",
            "7/7 - 3s - loss: 2.2853 - accuracy: 0.8990 - 3s/epoch - 384ms/step\n",
            "Epoch 3/5\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.96033\n",
            "7/7 - 3s - loss: 1.1079 - accuracy: 0.8841 - 3s/epoch - 382ms/step\n",
            "Epoch 4/5\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.96033\n",
            "7/7 - 3s - loss: 0.6473 - accuracy: 0.9238 - 3s/epoch - 382ms/step\n",
            "Epoch 5/5\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.96033\n",
            "7/7 - 3s - loss: 0.5715 - accuracy: 0.9255 - 3s/epoch - 382ms/step\n",
            "2/2 [==============================] - 1s 259ms/step - loss: 0.5544 - accuracy: 0.9079\n",
            "Epoch 1/5\n",
            "\n",
            "Epoch 1: accuracy did not improve from 0.96033\n",
            "7/7 - 3s - loss: 5.0606 - accuracy: 0.8198 - 3s/epoch - 499ms/step\n",
            "Epoch 2/5\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.96033\n",
            "7/7 - 3s - loss: 2.3968 - accuracy: 0.7901 - 3s/epoch - 383ms/step\n",
            "Epoch 3/5\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.96033\n",
            "7/7 - 3s - loss: 1.4511 - accuracy: 0.8942 - 3s/epoch - 385ms/step\n",
            "Epoch 4/5\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.96033\n",
            "7/7 - 3s - loss: 0.9946 - accuracy: 0.8397 - 3s/epoch - 382ms/step\n",
            "Epoch 5/5\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.96033\n",
            "7/7 - 3s - loss: 0.7811 - accuracy: 0.9107 - 3s/epoch - 384ms/step\n",
            "2/2 [==============================] - 1s 256ms/step - loss: 0.6978 - accuracy: 0.9205\n",
            "Epoch 1/5\n",
            "\n",
            "Epoch 1: accuracy did not improve from 0.96033\n",
            "7/7 - 4s - loss: 5.2030 - accuracy: 0.7802 - 4s/epoch - 503ms/step\n",
            "Epoch 2/5\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.96033\n",
            "7/7 - 3s - loss: 2.6683 - accuracy: 0.7983 - 3s/epoch - 384ms/step\n",
            "Epoch 3/5\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.96033\n",
            "7/7 - 3s - loss: 1.3854 - accuracy: 0.8744 - 3s/epoch - 384ms/step\n",
            "Epoch 4/5\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.96033\n",
            "7/7 - 3s - loss: 1.0058 - accuracy: 0.8529 - 3s/epoch - 384ms/step\n",
            "Epoch 5/5\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.96033\n",
            "7/7 - 3s - loss: 0.8128 - accuracy: 0.8975 - 3s/epoch - 385ms/step\n",
            "2/2 [==============================] - 1s 256ms/step - loss: 0.6528 - accuracy: 0.9934\n",
            "Epoch 1/5\n",
            "\n",
            "Epoch 1: accuracy did not improve from 0.96033\n",
            "7/7 - 4s - loss: 4.8479 - accuracy: 0.8727 - 4s/epoch - 504ms/step\n",
            "Epoch 2/5\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.96033\n",
            "7/7 - 3s - loss: 2.1553 - accuracy: 0.8446 - 3s/epoch - 384ms/step\n",
            "Epoch 3/5\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.96033\n",
            "7/7 - 3s - loss: 1.1486 - accuracy: 0.8826 - 3s/epoch - 386ms/step\n",
            "Epoch 4/5\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.96033\n",
            "7/7 - 3s - loss: 0.6766 - accuracy: 0.9174 - 3s/epoch - 384ms/step\n",
            "Epoch 5/5\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.96033\n",
            "7/7 - 3s - loss: 0.6242 - accuracy: 0.9074 - 3s/epoch - 384ms/step\n",
            "2/2 [==============================] - 1s 268ms/step - loss: 0.4989 - accuracy: 0.9338\n",
            "Epoch 1/5\n",
            "\n",
            "Epoch 1: accuracy did not improve from 0.96033\n",
            "7/7 - 4s - loss: 5.3597 - accuracy: 0.8149 - 4s/epoch - 500ms/step\n",
            "Epoch 2/5\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.96033\n",
            "7/7 - 3s - loss: 2.4270 - accuracy: 0.8661 - 3s/epoch - 384ms/step\n",
            "Epoch 3/5\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.96033\n",
            "7/7 - 3s - loss: 1.2259 - accuracy: 0.8893 - 3s/epoch - 381ms/step\n",
            "Epoch 4/5\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.96033\n",
            "7/7 - 3s - loss: 0.8669 - accuracy: 0.8909 - 3s/epoch - 382ms/step\n",
            "Epoch 5/5\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.96033\n",
            "7/7 - 3s - loss: 0.7080 - accuracy: 0.9091 - 3s/epoch - 382ms/step\n",
            "2/2 [==============================] - 1s 262ms/step - loss: 0.5794 - accuracy: 0.9735\n",
            "Epoch 1/5\n",
            "\n",
            "Epoch 1: accuracy did not improve from 0.96033\n",
            "24/24 - 6s - loss: 2.3432 - accuracy: 0.8704 - 6s/epoch - 247ms/step\n",
            "Epoch 2/5\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.96033\n",
            "24/24 - 4s - loss: 0.6066 - accuracy: 0.9008 - 4s/epoch - 147ms/step\n",
            "Epoch 3/5\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.96033\n",
            "24/24 - 4s - loss: 0.3798 - accuracy: 0.9550 - 4s/epoch - 147ms/step\n",
            "Epoch 4/5\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.96033\n",
            "24/24 - 4s - loss: 0.3152 - accuracy: 0.9497 - 4s/epoch - 148ms/step\n",
            "Epoch 5/5\n",
            "\n",
            "Epoch 5: accuracy improved from 0.96033 to 0.96296, saving model to ./model_vgg16_frozen.h5\n",
            "24/24 - 4s - loss: 0.2705 - accuracy: 0.9630 - 4s/epoch - 157ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"first model:\")\n",
        "print(grid_result_1.best_params_)\n",
        "print(grid_result_1.best_estimator_)\n",
        "print(grid_result_1.best_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofjL1UJoUlK0",
        "outputId": "157f25d0-6958-4597-f0ad-6c1ae214915a"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first model:\n",
            "{'batch_size': 32, 'epochs': 5, 'learn_rate': 0.0001}\n",
            "<keras.wrappers.scikit_learn.KerasClassifier object at 0x7fa5e5601550>\n",
            "0.9511066555976868\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1_final = load_model('./model_vgg16_frozen.h5')\n",
        "mdoel_1_final_train_evaluate = model_1_final.evaluate(X_train,y_train, verbose=0)\n",
        "mdoel_1_final_test_evaluate = model_1_final.evaluate(X_test,y_test, verbose=0)\n",
        "print(\"the first model accuracy on training dataset is:\", mdoel_1_final_train_evaluate[1])\n",
        "print(\"the first model accuracy on test dataset is:\", mdoel_1_final_test_evaluate[1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMrSj4qKVaDh",
        "outputId": "87c17b44-a24a-49b2-f293-0e63d4dc8df2"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the first model accuracy on training dataset is: 0.9563491940498352\n",
            "the first model accuracy on test dataset is: 0.9365079402923584\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model 2: VGG16 top layer removed and add fully connected layers (one with 256 nodes using ‘relu’ activation and output layer with 2 nodes and ‘softmax’ activation)\n",
        "for layer in model_vgg16.layers[:]:\n",
        "     layer.trainable = False\n",
        "for layer in model_vgg16.layers[15:19]: # only enable the last block (4 layers)\n",
        "      layer.trainable = True\n",
        "for i, layer in enumerate(model_vgg16.layers):\n",
        "    print(i, layer.name, layer.trainable)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmBiH3HRubzp",
        "outputId": "14c3db44-3e52-4eae-9d8d-aa3e18ab73b4"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 input_2 False\n",
            "1 block1_conv1 False\n",
            "2 block1_conv2 False\n",
            "3 block1_pool False\n",
            "4 block2_conv1 False\n",
            "5 block2_conv2 False\n",
            "6 block2_pool False\n",
            "7 block3_conv1 False\n",
            "8 block3_conv2 False\n",
            "9 block3_conv3 False\n",
            "10 block3_pool False\n",
            "11 block4_conv1 False\n",
            "12 block4_conv2 False\n",
            "13 block4_conv3 False\n",
            "14 block4_pool False\n",
            "15 block5_conv1 True\n",
            "16 block5_conv2 True\n",
            "17 block5_conv3 True\n",
            "18 block5_pool True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def model_2(learn_rate=0.001):\n",
        "    model_2 = tf.keras.Sequential([\n",
        "      model_vgg16,\n",
        "      tf.keras.layers.Flatten(name='flatten'),\n",
        "      tf.keras.layers.Dense(256, activation='relu', name='new_fc1', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "      tf.keras.layers.Dropout(0.5),\n",
        "      tf.keras.layers.Dense(2, activation='softmax', name='new_predictions')\n",
        "      ])\n",
        "    model_2.compile(loss = \"categorical_crossentropy\", optimizer = 'Adam', metrics=[\"accuracy\"])\n",
        "    return model_2\n"
      ],
      "metadata": {
        "id": "0YDYQts9XPzm"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fine tune the model using grid search and early stopping\n",
        "checkpoint_path = './model_vgg16_block5.h5'\n",
        "early_stop = EarlyStopping(monitor='accuracy', verbose=2, patience=5)\n",
        "model_checkpoint = ModelCheckpoint(filepath=checkpoint_path, monitor='accuracy', verbose=2, \n",
        "                     save_best_only=True)\n",
        "\n",
        "learn_rate = [0.0001,0.01]\n",
        "batch_size = [32,100]\n",
        "epochs = [5]\n",
        "classifier_2 = KerasClassifier(build_fn=model_2)\n",
        "\n",
        "param_grid = dict(epochs=epochs, batch_size=batch_size, learn_rate = learn_rate)\n",
        "fit_model_2 = GridSearchCV(estimator = classifier_2, param_grid=param_grid, cv=5)\n",
        "\n",
        "grid_result_2 = fit_model_2.fit(X_train,y_train, verbose=2, callbacks=[early_stop,model_checkpoint])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ousqBWZYfmq",
        "outputId": "7b93e159-678d-4e4b-c3c6-97e88a432ad0"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\n",
            "Epoch 1: accuracy improved from -inf to 0.83609, saving model to ./model_vgg16_block5.h5\n",
            "19/19 - 6s - loss: 3.0485 - accuracy: 0.8361 - 6s/epoch - 294ms/step\n",
            "Epoch 2/5\n",
            "\n",
            "Epoch 2: accuracy improved from 0.83609 to 0.87252, saving model to ./model_vgg16_block5.h5\n",
            "19/19 - 4s - loss: 0.9569 - accuracy: 0.8725 - 4s/epoch - 191ms/step\n",
            "Epoch 3/5\n",
            "\n",
            "Epoch 3: accuracy improved from 0.87252 to 0.90728, saving model to ./model_vgg16_block5.h5\n",
            "19/19 - 4s - loss: 0.5907 - accuracy: 0.9073 - 4s/epoch - 190ms/step\n",
            "Epoch 4/5\n",
            "\n",
            "Epoch 4: accuracy improved from 0.90728 to 0.97185, saving model to ./model_vgg16_block5.h5\n",
            "19/19 - 4s - loss: 0.4032 - accuracy: 0.9719 - 4s/epoch - 191ms/step\n",
            "Epoch 5/5\n",
            "\n",
            "Epoch 5: accuracy improved from 0.97185 to 0.98510, saving model to ./model_vgg16_block5.h5\n",
            "19/19 - 4s - loss: 0.3036 - accuracy: 0.9851 - 4s/epoch - 190ms/step\n",
            "5/5 [==============================] - 1s 147ms/step - loss: 0.4301 - accuracy: 0.9539\n",
            "Epoch 1/5\n",
            "\n",
            "Epoch 1: accuracy did not improve from 0.98510\n",
            "19/19 - 4s - loss: 2.1118 - accuracy: 0.9223 - 4s/epoch - 225ms/step\n",
            "Epoch 2/5\n",
            "\n",
            "Epoch 2: accuracy improved from 0.98510 to 0.98512, saving model to ./model_vgg16_block5.h5\n",
            "19/19 - 4s - loss: 0.1467 - accuracy: 0.9851 - 4s/epoch - 192ms/step\n",
            "Epoch 3/5\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.98512\n",
            "19/19 - 3s - loss: 0.0861 - accuracy: 0.9851 - 3s/epoch - 171ms/step\n",
            "Epoch 4/5\n",
            "\n",
            "Epoch 4: accuracy improved from 0.98512 to 0.99504, saving model to ./model_vgg16_block5.h5\n",
            "19/19 - 4s - loss: 0.0313 - accuracy: 0.9950 - 4s/epoch - 191ms/step\n",
            "Epoch 5/5\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.99504\n",
            "19/19 - 3s - loss: 0.0256 - accuracy: 0.9950 - 3s/epoch - 170ms/step\n",
            "5/5 [==============================] - 1s 163ms/step - loss: 0.0473 - accuracy: 0.9934\n",
            "Epoch 1/5\n",
            "\n",
            "Epoch 1: accuracy did not improve from 0.99504\n",
            "19/19 - 4s - loss: 2.0559 - accuracy: 0.9620 - 4s/epoch - 219ms/step\n",
            "Epoch 2/5\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.99504\n",
            "19/19 - 3s - loss: 0.1804 - accuracy: 0.9884 - 3s/epoch - 170ms/step\n",
            "Epoch 3/5\n",
            "\n",
            "Epoch 3: accuracy improved from 0.99504 to 0.99835, saving model to ./model_vgg16_block5.h5\n",
            "19/19 - 4s - loss: 0.0729 - accuracy: 0.9983 - 4s/epoch - 191ms/step\n",
            "Epoch 4/5\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.99835\n",
            "19/19 - 3s - loss: 0.1197 - accuracy: 0.9835 - 3s/epoch - 171ms/step\n",
            "Epoch 5/5\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.99835\n",
            "19/19 - 3s - loss: 0.0483 - accuracy: 0.9967 - 3s/epoch - 170ms/step\n",
            "5/5 [==============================] - 1s 146ms/step - loss: 0.0393 - accuracy: 1.0000\n",
            "Epoch 1/5\n",
            "\n",
            "Epoch 1: accuracy did not improve from 0.99835\n",
            "19/19 - 4s - loss: 2.3750 - accuracy: 0.9537 - 4s/epoch - 218ms/step\n",
            "Epoch 2/5\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.99835\n",
            "19/19 - 3s - loss: 0.4208 - accuracy: 0.9967 - 3s/epoch - 171ms/step\n",
            "Epoch 3/5\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.99835\n",
            "19/19 - 3s - loss: 0.2827 - accuracy: 0.9950 - 3s/epoch - 170ms/step\n",
            "Epoch 4/5\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.99835\n",
            "19/19 - 3s - loss: 0.1971 - accuracy: 0.9967 - 3s/epoch - 171ms/step\n",
            "Epoch 5/5\n",
            "\n",
            "Epoch 5: accuracy improved from 0.99835 to 1.00000, saving model to ./model_vgg16_block5.h5\n",
            "19/19 - 4s - loss: 0.1514 - accuracy: 1.0000 - 4s/epoch - 191ms/step\n",
            "5/5 [==============================] - 1s 151ms/step - loss: 0.1366 - accuracy: 1.0000\n",
            "Epoch 1/5\n",
            "\n",
            "Epoch 1: accuracy did not improve from 1.00000\n",
            "19/19 - 4s - loss: 2.1517 - accuracy: 0.9488 - 4s/epoch - 219ms/step\n",
            "Epoch 2/5\n",
            "\n",
            "Epoch 2: accuracy did not improve from 1.00000\n",
            "19/19 - 3s - loss: 0.3024 - accuracy: 0.9901 - 3s/epoch - 170ms/step\n",
            "Epoch 3/5\n",
            "\n",
            "Epoch 3: accuracy did not improve from 1.00000\n",
            "19/19 - 3s - loss: 0.1577 - accuracy: 0.9967 - 3s/epoch - 170ms/step\n",
            "Epoch 4/5\n",
            "\n",
            "Epoch 4: accuracy did not improve from 1.00000\n",
            "19/19 - 3s - loss: 0.1106 - accuracy: 0.9983 - 3s/epoch - 171ms/step\n",
            "Epoch 5/5\n",
            "\n",
            "Epoch 5: accuracy did not improve from 1.00000\n",
            "19/19 - 3s - loss: 0.1074 - accuracy: 0.9967 - 3s/epoch - 170ms/step\n",
            "5/5 [==============================] - 1s 147ms/step - loss: 0.0904 - accuracy: 1.0000\n",
            "Epoch 1/5\n",
            "\n",
            "Epoch 1: accuracy did not improve from 1.00000\n",
            "19/19 - 4s - loss: 2.0532 - accuracy: 0.9570 - 4s/epoch - 220ms/step\n",
            "Epoch 2/5\n",
            "\n",
            "Epoch 2: accuracy did not improve from 1.00000\n",
            "19/19 - 3s - loss: 0.2266 - accuracy: 0.9934 - 3s/epoch - 171ms/step\n",
            "Epoch 3/5\n",
            "\n",
            "Epoch 3: accuracy did not improve from 1.00000\n",
            "19/19 - 3s - loss: 0.1273 - accuracy: 0.9950 - 3s/epoch - 172ms/step\n",
            "Epoch 4/5\n",
            "\n",
            "Epoch 4: accuracy did not improve from 1.00000\n",
            "19/19 - 3s - loss: 0.0591 - accuracy: 1.0000 - 3s/epoch - 171ms/step\n",
            "Epoch 5/5\n",
            "\n",
            "Epoch 5: accuracy did not improve from 1.00000\n",
            "19/19 - 3s - loss: 0.0488 - accuracy: 1.0000 - 3s/epoch - 171ms/step\n",
            "5/5 [==============================] - 1s 165ms/step - loss: 0.0449 - accuracy: 1.0000\n",
            "Epoch 1/5\n",
            "\n",
            "Epoch 1: accuracy did not improve from 1.00000\n",
            "19/19 - 4s - loss: 2.1272 - accuracy: 0.9802 - 4s/epoch - 219ms/step\n",
            "Epoch 2/5\n",
            "\n",
            "Epoch 2: accuracy did not improve from 1.00000\n",
            "19/19 - 3s - loss: 0.2004 - accuracy: 0.9983 - 3s/epoch - 171ms/step\n",
            "Epoch 3/5\n",
            "\n",
            "Epoch 3: accuracy did not improve from 1.00000\n",
            "19/19 - 3s - loss: 0.1057 - accuracy: 1.0000 - 3s/epoch - 170ms/step\n",
            "Epoch 4/5\n",
            "\n",
            "Epoch 4: accuracy did not improve from 1.00000\n",
            "19/19 - 3s - loss: 0.0633 - accuracy: 1.0000 - 3s/epoch - 170ms/step\n",
            "Epoch 5/5\n",
            "\n",
            "Epoch 5: accuracy did not improve from 1.00000\n",
            "19/19 - 3s - loss: 0.0482 - accuracy: 1.0000 - 3s/epoch - 171ms/step\n",
            "5/5 [==============================] - 1s 147ms/step - loss: 0.0426 - accuracy: 1.0000\n",
            "Epoch 1/5\n",
            "\n",
            "Epoch 1: accuracy did not improve from 1.00000\n",
            "19/19 - 4s - loss: 2.0638 - accuracy: 0.9868 - 4s/epoch - 220ms/step\n",
            "Epoch 2/5\n",
            "\n",
            "Epoch 2: accuracy did not improve from 1.00000\n",
            "19/19 - 3s - loss: 0.1767 - accuracy: 0.9967 - 3s/epoch - 171ms/step\n",
            "Epoch 3/5\n",
            "\n",
            "Epoch 3: accuracy did not improve from 1.00000\n",
            "19/19 - 3s - loss: 0.1377 - accuracy: 0.9950 - 3s/epoch - 170ms/step\n",
            "Epoch 4/5\n",
            "\n",
            "Epoch 4: accuracy did not improve from 1.00000\n",
            "19/19 - 3s - loss: 0.1296 - accuracy: 0.9950 - 3s/epoch - 171ms/step\n",
            "Epoch 5/5\n",
            "\n",
            "Epoch 5: accuracy did not improve from 1.00000\n",
            "19/19 - 3s - loss: 0.0583 - accuracy: 1.0000 - 3s/epoch - 171ms/step\n",
            "5/5 [==============================] - 1s 149ms/step - loss: 0.0534 - accuracy: 1.0000\n",
            "Epoch 1/5\n",
            "\n",
            "Epoch 1: accuracy did not improve from 1.00000\n",
            "19/19 - 4s - loss: 2.0396 - accuracy: 0.9884 - 4s/epoch - 217ms/step\n",
            "Epoch 2/5\n",
            "\n",
            "Epoch 2: accuracy did not improve from 1.00000\n",
            "19/19 - 3s - loss: 0.1566 - accuracy: 0.9983 - 3s/epoch - 170ms/step\n",
            "Epoch 3/5\n",
            "\n",
            "Epoch 3: accuracy did not improve from 1.00000\n",
            "19/19 - 3s - loss: 0.0827 - accuracy: 0.9983 - 3s/epoch - 171ms/step\n",
            "Epoch 4/5\n",
            "\n",
            "Epoch 4: accuracy did not improve from 1.00000\n",
            "19/19 - 3s - loss: 0.0494 - accuracy: 1.0000 - 3s/epoch - 171ms/step\n",
            "Epoch 5/5\n",
            "\n",
            "Epoch 5: accuracy did not improve from 1.00000\n",
            "19/19 - 3s - loss: 0.0402 - accuracy: 1.0000 - 3s/epoch - 171ms/step\n",
            "5/5 [==============================] - 1s 165ms/step - loss: 0.0366 - accuracy: 1.0000\n",
            "Epoch 1/5\n",
            "\n",
            "Epoch 1: accuracy did not improve from 1.00000\n",
            "19/19 - 4s - loss: 2.0996 - accuracy: 0.9636 - 4s/epoch - 221ms/step\n",
            "Epoch 2/5\n",
            "\n",
            "Epoch 2: accuracy did not improve from 1.00000\n",
            "19/19 - 3s - loss: 0.1818 - accuracy: 0.9950 - 3s/epoch - 170ms/step\n",
            "Epoch 3/5\n",
            "\n",
            "Epoch 3: accuracy did not improve from 1.00000\n",
            "19/19 - 3s - loss: 0.1141 - accuracy: 0.9950 - 3s/epoch - 170ms/step\n",
            "Epoch 4/5\n",
            "\n",
            "Epoch 4: accuracy did not improve from 1.00000\n",
            "19/19 - 3s - loss: 0.0846 - accuracy: 0.9967 - 3s/epoch - 170ms/step\n",
            "Epoch 5/5\n",
            "\n",
            "Epoch 5: accuracy did not improve from 1.00000\n",
            "19/19 - 3s - loss: 0.0682 - accuracy: 0.9983 - 3s/epoch - 171ms/step\n",
            "5/5 [==============================] - 1s 147ms/step - loss: 0.0603 - accuracy: 1.0000\n",
            "Epoch 1/5\n",
            "\n",
            "Epoch 1: accuracy did not improve from 1.00000\n",
            "7/7 - 4s - loss: 3.9123 - accuracy: 0.9702 - 4s/epoch - 609ms/step\n",
            "Epoch 2/5\n",
            "\n",
            "Epoch 2: accuracy did not improve from 1.00000\n",
            "7/7 - 3s - loss: 1.4740 - accuracy: 1.0000 - 3s/epoch - 428ms/step\n",
            "Epoch 3/5\n",
            "\n",
            "Epoch 3: accuracy did not improve from 1.00000\n",
            "7/7 - 3s - loss: 0.4700 - accuracy: 1.0000 - 3s/epoch - 429ms/step\n",
            "Epoch 4/5\n",
            "\n",
            "Epoch 4: accuracy did not improve from 1.00000\n",
            "7/7 - 3s - loss: 0.1542 - accuracy: 1.0000 - 3s/epoch - 428ms/step\n",
            "Epoch 5/5\n",
            "\n",
            "Epoch 5: accuracy did not improve from 1.00000\n",
            "7/7 - 3s - loss: 0.0971 - accuracy: 1.0000 - 3s/epoch - 425ms/step\n",
            "2/2 [==============================] - 1s 270ms/step - loss: 0.0914 - accuracy: 1.0000\n",
            "Epoch 1/5\n",
            "\n",
            "Epoch 1: accuracy did not improve from 1.00000\n",
            "7/7 - 4s - loss: 3.9240 - accuracy: 0.9405 - 4s/epoch - 582ms/step\n",
            "Epoch 2/5\n",
            "\n",
            "Epoch 2: accuracy did not improve from 1.00000\n",
            "7/7 - 3s - loss: 1.4946 - accuracy: 0.9983 - 3s/epoch - 430ms/step\n",
            "Epoch 3/5\n",
            "\n",
            "Epoch 3: accuracy did not improve from 1.00000\n",
            "7/7 - 3s - loss: 0.4918 - accuracy: 1.0000 - 3s/epoch - 428ms/step\n",
            "Epoch 4/5\n",
            "\n",
            "Epoch 4: accuracy did not improve from 1.00000\n",
            "7/7 - 3s - loss: 0.1768 - accuracy: 1.0000 - 3s/epoch - 430ms/step\n",
            "Epoch 5/5\n",
            "\n",
            "Epoch 5: accuracy did not improve from 1.00000\n",
            "7/7 - 3s - loss: 0.1183 - accuracy: 1.0000 - 3s/epoch - 429ms/step\n",
            "2/2 [==============================] - 1s 250ms/step - loss: 0.1115 - accuracy: 1.0000\n",
            "Epoch 1/5\n",
            "\n",
            "Epoch 1: accuracy did not improve from 1.00000\n",
            "7/7 - 4s - loss: 3.8017 - accuracy: 0.9934 - 4s/epoch - 557ms/step\n",
            "Epoch 2/5\n",
            "\n",
            "Epoch 2: accuracy did not improve from 1.00000\n",
            "7/7 - 3s - loss: 1.4801 - accuracy: 1.0000 - 3s/epoch - 428ms/step\n",
            "Epoch 3/5\n",
            "\n",
            "Epoch 3: accuracy did not improve from 1.00000\n",
            "7/7 - 3s - loss: 0.4782 - accuracy: 0.9983 - 3s/epoch - 429ms/step\n",
            "Epoch 4/5\n",
            "\n",
            "Epoch 4: accuracy did not improve from 1.00000\n",
            "7/7 - 3s - loss: 0.3894 - accuracy: 0.9736 - 3s/epoch - 429ms/step\n",
            "Epoch 5/5\n",
            "\n",
            "Epoch 5: accuracy did not improve from 1.00000\n",
            "7/7 - 3s - loss: 0.3566 - accuracy: 0.9851 - 3s/epoch - 429ms/step\n",
            "2/2 [==============================] - 1s 260ms/step - loss: 0.1017 - accuracy: 1.0000\n",
            "Epoch 1/5\n",
            "\n",
            "Epoch 1: accuracy did not improve from 1.00000\n",
            "7/7 - 4s - loss: 4.4215 - accuracy: 0.8595 - 4s/epoch - 560ms/step\n",
            "Epoch 2/5\n",
            "\n",
            "Epoch 2: accuracy did not improve from 1.00000\n",
            "7/7 - 3s - loss: 1.5231 - accuracy: 1.0000 - 3s/epoch - 427ms/step\n",
            "Epoch 3/5\n",
            "\n",
            "Epoch 3: accuracy did not improve from 1.00000\n",
            "7/7 - 3s - loss: 0.5341 - accuracy: 0.9967 - 3s/epoch - 428ms/step\n",
            "Epoch 4/5\n",
            "\n",
            "Epoch 4: accuracy did not improve from 1.00000\n",
            "7/7 - 3s - loss: 0.2234 - accuracy: 0.9967 - 3s/epoch - 429ms/step\n",
            "Epoch 5/5\n",
            "\n",
            "Epoch 5: accuracy did not improve from 1.00000\n",
            "7/7 - 3s - loss: 0.1617 - accuracy: 0.9967 - 3s/epoch - 428ms/step\n",
            "2/2 [==============================] - 1s 270ms/step - loss: 0.1510 - accuracy: 1.0000\n",
            "Epoch 1/5\n",
            "\n",
            "Epoch 1: accuracy did not improve from 1.00000\n",
            "7/7 - 4s - loss: 3.9828 - accuracy: 0.8612 - 4s/epoch - 563ms/step\n",
            "Epoch 2/5\n",
            "\n",
            "Epoch 2: accuracy did not improve from 1.00000\n",
            "7/7 - 3s - loss: 1.4856 - accuracy: 1.0000 - 3s/epoch - 428ms/step\n",
            "Epoch 3/5\n",
            "\n",
            "Epoch 3: accuracy did not improve from 1.00000\n",
            "7/7 - 3s - loss: 0.4806 - accuracy: 1.0000 - 3s/epoch - 429ms/step\n",
            "Epoch 4/5\n",
            "\n",
            "Epoch 4: accuracy did not improve from 1.00000\n",
            "7/7 - 3s - loss: 0.1644 - accuracy: 1.0000 - 3s/epoch - 427ms/step\n",
            "Epoch 5/5\n",
            "\n",
            "Epoch 5: accuracy did not improve from 1.00000\n",
            "7/7 - 3s - loss: 0.1059 - accuracy: 1.0000 - 3s/epoch - 428ms/step\n",
            "2/2 [==============================] - 1s 254ms/step - loss: 0.0993 - accuracy: 1.0000\n",
            "Epoch 1/5\n",
            "\n",
            "Epoch 1: accuracy did not improve from 1.00000\n",
            "7/7 - 4s - loss: 3.9895 - accuracy: 0.9288 - 4s/epoch - 555ms/step\n",
            "Epoch 2/5\n",
            "\n",
            "Epoch 2: accuracy did not improve from 1.00000\n",
            "7/7 - 3s - loss: 1.5162 - accuracy: 1.0000 - 3s/epoch - 426ms/step\n",
            "Epoch 3/5\n",
            "\n",
            "Epoch 3: accuracy did not improve from 1.00000\n",
            "7/7 - 3s - loss: 0.5257 - accuracy: 1.0000 - 3s/epoch - 426ms/step\n",
            "Epoch 4/5\n",
            "\n",
            "Epoch 4: accuracy did not improve from 1.00000\n",
            "7/7 - 3s - loss: 0.2149 - accuracy: 1.0000 - 3s/epoch - 429ms/step\n",
            "Epoch 5/5\n",
            "\n",
            "Epoch 5: accuracy did not improve from 1.00000\n",
            "7/7 - 3s - loss: 0.1585 - accuracy: 1.0000 - 3s/epoch - 425ms/step\n",
            "2/2 [==============================] - 1s 259ms/step - loss: 0.1509 - accuracy: 1.0000\n",
            "Epoch 1/5\n",
            "\n",
            "Epoch 1: accuracy did not improve from 1.00000\n",
            "7/7 - 4s - loss: 3.9426 - accuracy: 0.9074 - 4s/epoch - 620ms/step\n",
            "Epoch 2/5\n",
            "\n",
            "Epoch 2: accuracy did not improve from 1.00000\n",
            "7/7 - 3s - loss: 1.4973 - accuracy: 1.0000 - 3s/epoch - 429ms/step\n",
            "Epoch 3/5\n",
            "\n",
            "Epoch 3: accuracy did not improve from 1.00000\n",
            "7/7 - 3s - loss: 0.5095 - accuracy: 0.9983 - 3s/epoch - 427ms/step\n",
            "Epoch 4/5\n",
            "\n",
            "Epoch 4: accuracy did not improve from 1.00000\n",
            "7/7 - 3s - loss: 0.2207 - accuracy: 0.9934 - 3s/epoch - 428ms/step\n",
            "Epoch 5/5\n",
            "\n",
            "Epoch 5: accuracy did not improve from 1.00000\n",
            "7/7 - 3s - loss: 0.2477 - accuracy: 0.9934 - 3s/epoch - 428ms/step\n",
            "2/2 [==============================] - 1s 263ms/step - loss: 0.1242 - accuracy: 1.0000\n",
            "Epoch 1/5\n",
            "\n",
            "Epoch 1: accuracy did not improve from 1.00000\n",
            "7/7 - 4s - loss: 3.9987 - accuracy: 0.9421 - 4s/epoch - 567ms/step\n",
            "Epoch 2/5\n",
            "\n",
            "Epoch 2: accuracy did not improve from 1.00000\n",
            "7/7 - 3s - loss: 1.4832 - accuracy: 1.0000 - 3s/epoch - 427ms/step\n",
            "Epoch 3/5\n",
            "\n",
            "Epoch 3: accuracy did not improve from 1.00000\n",
            "7/7 - 3s - loss: 0.4815 - accuracy: 1.0000 - 3s/epoch - 427ms/step\n",
            "Epoch 4/5\n",
            "\n",
            "Epoch 4: accuracy did not improve from 1.00000\n",
            "7/7 - 3s - loss: 0.1668 - accuracy: 1.0000 - 3s/epoch - 428ms/step\n",
            "Epoch 5/5\n",
            "\n",
            "Epoch 5: accuracy did not improve from 1.00000\n",
            "7/7 - 3s - loss: 0.1089 - accuracy: 1.0000 - 3s/epoch - 427ms/step\n",
            "2/2 [==============================] - 1s 257ms/step - loss: 0.1026 - accuracy: 1.0000\n",
            "Epoch 1/5\n",
            "\n",
            "Epoch 1: accuracy did not improve from 1.00000\n",
            "7/7 - 4s - loss: 4.0916 - accuracy: 0.8893 - 4s/epoch - 568ms/step\n",
            "Epoch 2/5\n",
            "\n",
            "Epoch 2: accuracy did not improve from 1.00000\n",
            "7/7 - 3s - loss: 1.5030 - accuracy: 1.0000 - 3s/epoch - 430ms/step\n",
            "Epoch 3/5\n",
            "\n",
            "Epoch 3: accuracy did not improve from 1.00000\n",
            "7/7 - 3s - loss: 0.5080 - accuracy: 1.0000 - 3s/epoch - 430ms/step\n",
            "Epoch 4/5\n",
            "\n",
            "Epoch 4: accuracy did not improve from 1.00000\n",
            "7/7 - 3s - loss: 0.1953 - accuracy: 1.0000 - 3s/epoch - 429ms/step\n",
            "Epoch 5/5\n",
            "\n",
            "Epoch 5: accuracy did not improve from 1.00000\n",
            "7/7 - 3s - loss: 0.1373 - accuracy: 1.0000 - 3s/epoch - 428ms/step\n",
            "2/2 [==============================] - 1s 278ms/step - loss: 0.1305 - accuracy: 1.0000\n",
            "Epoch 1/5\n",
            "\n",
            "Epoch 1: accuracy did not improve from 1.00000\n",
            "7/7 - 4s - loss: 3.9178 - accuracy: 0.9471 - 4s/epoch - 568ms/step\n",
            "Epoch 2/5\n",
            "\n",
            "Epoch 2: accuracy did not improve from 1.00000\n",
            "7/7 - 3s - loss: 1.5185 - accuracy: 1.0000 - 3s/epoch - 428ms/step\n",
            "Epoch 3/5\n",
            "\n",
            "Epoch 3: accuracy did not improve from 1.00000\n",
            "7/7 - 3s - loss: 0.5182 - accuracy: 1.0000 - 3s/epoch - 427ms/step\n",
            "Epoch 4/5\n",
            "\n",
            "Epoch 4: accuracy did not improve from 1.00000\n",
            "7/7 - 3s - loss: 0.2003 - accuracy: 1.0000 - 3s/epoch - 427ms/step\n",
            "Epoch 5/5\n",
            "\n",
            "Epoch 5: accuracy did not improve from 1.00000\n",
            "7/7 - 3s - loss: 0.1388 - accuracy: 1.0000 - 3s/epoch - 427ms/step\n",
            "2/2 [==============================] - 1s 259ms/step - loss: 0.1303 - accuracy: 1.0000\n",
            "Epoch 1/5\n",
            "\n",
            "Epoch 1: accuracy did not improve from 1.00000\n",
            "24/24 - 5s - loss: 1.8602 - accuracy: 0.9577 - 5s/epoch - 213ms/step\n",
            "Epoch 2/5\n",
            "\n",
            "Epoch 2: accuracy did not improve from 1.00000\n",
            "24/24 - 4s - loss: 0.1709 - accuracy: 1.0000 - 4s/epoch - 169ms/step\n",
            "Epoch 3/5\n",
            "\n",
            "Epoch 3: accuracy did not improve from 1.00000\n",
            "24/24 - 4s - loss: 0.1124 - accuracy: 1.0000 - 4s/epoch - 170ms/step\n",
            "Epoch 4/5\n",
            "\n",
            "Epoch 4: accuracy did not improve from 1.00000\n",
            "24/24 - 4s - loss: 0.0925 - accuracy: 1.0000 - 4s/epoch - 169ms/step\n",
            "Epoch 5/5\n",
            "\n",
            "Epoch 5: accuracy did not improve from 1.00000\n",
            "24/24 - 4s - loss: 0.0814 - accuracy: 1.0000 - 4s/epoch - 169ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"second model:\")\n",
        "print(grid_result_2.best_params_)\n",
        "print(grid_result_2.best_estimator_)\n",
        "print(grid_result_2.best_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3p7VKLa8a9TK",
        "outputId": "c08d6a42-90f4-49ae-d7b9-3186a1d47f48"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "second model:\n",
            "{'batch_size': 32, 'epochs': 5, 'learn_rate': 0.01}\n",
            "<keras.wrappers.scikit_learn.KerasClassifier object at 0x7fa573785b90>\n",
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2_final = load_model('./model_vgg16_block5.h5')\n",
        "mdoel_2_final_train_evaluate = model_2_final.evaluate(X_train,y_train, verbose=0)\n",
        "mdoel_2_final_test_evaluate = model_2_final.evaluate(X_test,y_test, verbose=0)\n",
        "print(\"the second model accuracy on training dataset is:\", mdoel_2_final_train_evaluate[1])\n",
        "print(\"the second model accuracy on test dataset is:\", mdoel_2_final_test_evaluate[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-J1aWVIbSUC",
        "outputId": "0cbb04c8-f2de-4859-8610-644923d7ac2b"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the second model accuracy on training dataset is: 1.0\n",
            "the second model accuracy on test dataset is: 0.988095223903656\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model 3: VGG16 top layer removed and add fully connected layers (one with 256 nodes using ‘relu’ activation and output layer with 5 nodes and ‘softmax’ activation)\n",
        "for layer in model_vgg16.layers[:]: # only enable the last block (4 layers)\n",
        "      layer.trainable = True\n",
        "for i, layer in enumerate(model_vgg16.layers):\n",
        "    print(i, layer.name, layer.trainable)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMj6TsPE6xND",
        "outputId": "c0f221a0-77a7-499e-8461-f321d3a6a351"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 input_2 True\n",
            "1 block1_conv1 True\n",
            "2 block1_conv2 True\n",
            "3 block1_pool True\n",
            "4 block2_conv1 True\n",
            "5 block2_conv2 True\n",
            "6 block2_pool True\n",
            "7 block3_conv1 True\n",
            "8 block3_conv2 True\n",
            "9 block3_conv3 True\n",
            "10 block3_pool True\n",
            "11 block4_conv1 True\n",
            "12 block4_conv2 True\n",
            "13 block4_conv3 True\n",
            "14 block4_pool True\n",
            "15 block5_conv1 True\n",
            "16 block5_conv2 True\n",
            "17 block5_conv3 True\n",
            "18 block5_pool True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def model_3(learn_rate=0.001):\n",
        "    for layer in model_vgg16.layers[:]: # all layers enabled\n",
        "      layer.trainable = True\n",
        "    model_3 = tf.keras.Sequential([\n",
        "      model_vgg16,\n",
        "      tf.keras.layers.Flatten(name='flatten'),\n",
        "      tf.keras.layers.Dense(256, activation='relu', name='new_fc1', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "      tf.keras.layers.Dropout(0.5),\n",
        "      tf.keras.layers.Dense(2, activation='softmax', name='new_predictions')\n",
        "      ])\n",
        "    model_3.compile(loss = \"categorical_crossentropy\", optimizer = 'Adam', metrics=[\"accuracy\"])\n",
        "    return model_3"
      ],
      "metadata": {
        "id": "XiTtLh_Hb3Ig"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fine tune the model using grid search and early stopping\n",
        "checkpoint_path = './model_vgg16_enable.h5'\n",
        "early_stop = EarlyStopping(monitor='accuracy', verbose=2, patience=5)\n",
        "model_checkpoint = ModelCheckpoint(filepath=checkpoint_path, monitor='accuracy', verbose=2, \n",
        "                     save_best_only=True)\n",
        "\n",
        "learn_rate = (0.0001,0.01)\n",
        "batch_size = [32,100]\n",
        "epochs = [5]\n",
        "classifier = KerasClassifier(build_fn=model_3)\n",
        "\n",
        "param_grid = dict(epochs=epochs, batch_size=batch_size, learn_rate = learn_rate)\n",
        "fit_model_3 = GridSearchCV(estimator = classifier, param_grid=param_grid, cv=5)\n",
        "\n",
        "grid_result_3 = fit_model_3.fit(X_train,y_train, verbose=2, callbacks=[early_stop,model_checkpoint])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQTyPHhFc7Kv",
        "outputId": "9dc506d0-cb62-4085-82f0-0c456baa8035"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\n",
            "Epoch 1: accuracy improved from -inf to 0.84603, saving model to ./model_vgg16_enable.h5\n",
            "19/19 - 14s - loss: 3.4160 - accuracy: 0.8460 - 14s/epoch - 751ms/step\n",
            "Epoch 2/5\n",
            "\n",
            "Epoch 2: accuracy improved from 0.84603 to 0.89735, saving model to ./model_vgg16_enable.h5\n",
            "19/19 - 8s - loss: 0.6914 - accuracy: 0.8974 - 8s/epoch - 440ms/step\n",
            "Epoch 3/5\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.89735\n",
            "19/19 - 8s - loss: 0.5229 - accuracy: 0.8974 - 8s/epoch - 410ms/step\n",
            "Epoch 4/5\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.89735\n",
            "19/19 - 8s - loss: 0.4795 - accuracy: 0.8974 - 8s/epoch - 410ms/step\n",
            "Epoch 5/5\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.89735\n",
            "19/19 - 8s - loss: 0.4668 - accuracy: 0.8974 - 8s/epoch - 411ms/step\n",
            "5/5 [==============================] - 1s 148ms/step - loss: 0.4776 - accuracy: 0.8750\n",
            "Epoch 1/5\n",
            "\n",
            "Epoch 1: accuracy did not improve from 0.89735\n",
            "19/19 - 11s - loss: 2.4073 - accuracy: 0.8661 - 11s/epoch - 588ms/step\n",
            "Epoch 2/5\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.89735\n",
            "19/19 - 8s - loss: 0.4544 - accuracy: 0.8909 - 8s/epoch - 411ms/step\n",
            "Epoch 3/5\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.89735\n",
            "19/19 - 8s - loss: 0.4008 - accuracy: 0.8909 - 8s/epoch - 411ms/step\n",
            "Epoch 4/5\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.89735\n",
            "19/19 - 8s - loss: 0.3970 - accuracy: 0.8909 - 8s/epoch - 411ms/step\n",
            "Epoch 5/5\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.89735\n",
            "19/19 - 8s - loss: 0.3964 - accuracy: 0.8909 - 8s/epoch - 411ms/step\n",
            "5/5 [==============================] - 1s 147ms/step - loss: 0.3368 - accuracy: 0.9007\n",
            "Epoch 1/5\n",
            "\n",
            "Epoch 1: accuracy did not improve from 0.89735\n",
            "19/19 - 9s - loss: 2.4028 - accuracy: 0.8744 - 9s/epoch - 472ms/step\n",
            "Epoch 2/5\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.89735\n",
            "19/19 - 8s - loss: 0.5287 - accuracy: 0.8860 - 8s/epoch - 411ms/step\n",
            "Epoch 3/5\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.89735\n",
            "19/19 - 8s - loss: 0.4456 - accuracy: 0.8876 - 8s/epoch - 411ms/step\n",
            "Epoch 4/5\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.89735\n",
            "19/19 - 8s - loss: 0.4038 - accuracy: 0.8876 - 8s/epoch - 410ms/step\n",
            "Epoch 5/5\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.89735\n",
            "19/19 - 8s - loss: 0.3858 - accuracy: 0.8876 - 8s/epoch - 410ms/step\n",
            "5/5 [==============================] - 1s 149ms/step - loss: 0.3311 - accuracy: 0.9139\n",
            "Epoch 1/5\n",
            "\n",
            "Epoch 1: accuracy did not improve from 0.89735\n",
            "19/19 - 9s - loss: 2.3184 - accuracy: 0.8744 - 9s/epoch - 472ms/step\n",
            "Epoch 2/5\n",
            "\n",
            "Epoch 2: accuracy improved from 0.89735 to 0.90083, saving model to ./model_vgg16_enable.h5\n",
            "19/19 - 8s - loss: 0.4290 - accuracy: 0.9008 - 8s/epoch - 440ms/step\n",
            "Epoch 3/5\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.90083\n",
            "19/19 - 8s - loss: 0.3547 - accuracy: 0.9008 - 8s/epoch - 409ms/step\n",
            "Epoch 4/5\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.90083\n",
            "19/19 - 8s - loss: 0.3486 - accuracy: 0.9008 - 8s/epoch - 409ms/step\n",
            "Epoch 5/5\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.90083\n",
            "19/19 - 8s - loss: 0.3537 - accuracy: 0.9008 - 8s/epoch - 411ms/step\n",
            "5/5 [==============================] - 1s 145ms/step - loss: 0.4089 - accuracy: 0.8609\n",
            "Epoch 1/5\n",
            "\n",
            "Epoch 1: accuracy did not improve from 0.90083\n",
            "19/19 - 9s - loss: 2.3496 - accuracy: 0.8661 - 9s/epoch - 471ms/step\n",
            "Epoch 2/5\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.90083\n",
            "19/19 - 8s - loss: 0.4681 - accuracy: 0.8876 - 8s/epoch - 409ms/step\n",
            "Epoch 3/5\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.90083\n",
            "19/19 - 8s - loss: 0.3894 - accuracy: 0.8876 - 8s/epoch - 409ms/step\n",
            "Epoch 4/5\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.90083\n",
            "19/19 - 8s - loss: 0.3780 - accuracy: 0.8876 - 8s/epoch - 409ms/step\n",
            "Epoch 5/5\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.90083\n",
            "19/19 - 8s - loss: 0.3747 - accuracy: 0.8876 - 8s/epoch - 409ms/step\n",
            "5/5 [==============================] - 1s 147ms/step - loss: 0.3682 - accuracy: 0.9139\n",
            "Epoch 1/5\n",
            "\n",
            "Epoch 1: accuracy did not improve from 0.90083\n",
            "19/19 - 9s - loss: 2.3477 - accuracy: 0.8526 - 9s/epoch - 471ms/step\n",
            "Epoch 2/5\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.90083\n",
            "19/19 - 8s - loss: 0.4418 - accuracy: 0.8974 - 8s/epoch - 409ms/step\n",
            "Epoch 3/5\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.90083\n",
            "19/19 - 8s - loss: 0.3784 - accuracy: 0.8974 - 8s/epoch - 409ms/step\n",
            "Epoch 4/5\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.90083\n",
            "19/19 - 8s - loss: 0.3606 - accuracy: 0.8974 - 8s/epoch - 410ms/step\n",
            "Epoch 5/5\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.90083\n",
            "19/19 - 8s - loss: 0.3543 - accuracy: 0.8974 - 8s/epoch - 409ms/step\n",
            "5/5 [==============================] - 1s 150ms/step - loss: 0.3876 - accuracy: 0.8750\n",
            "Epoch 1/5\n",
            "\n",
            "Epoch 1: accuracy did not improve from 0.90083\n",
            "19/19 - 9s - loss: 2.3075 - accuracy: 0.8893 - 9s/epoch - 473ms/step\n",
            "Epoch 2/5\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.90083\n",
            "19/19 - 8s - loss: 0.4363 - accuracy: 0.8909 - 8s/epoch - 409ms/step\n",
            "Epoch 3/5\n",
            "\n",
            "Epoch 3: accuracy improved from 0.90083 to 0.91901, saving model to ./model_vgg16_enable.h5\n",
            "19/19 - 8s - loss: 0.2629 - accuracy: 0.9190 - 8s/epoch - 444ms/step\n",
            "Epoch 4/5\n",
            "\n",
            "Epoch 4: accuracy improved from 0.91901 to 0.96033, saving model to ./model_vgg16_enable.h5\n",
            "19/19 - 9s - loss: 0.1826 - accuracy: 0.9603 - 9s/epoch - 449ms/step\n",
            "Epoch 5/5\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.96033\n",
            "19/19 - 8s - loss: 0.1498 - accuracy: 0.9603 - 8s/epoch - 408ms/step\n",
            "5/5 [==============================] - 1s 145ms/step - loss: 0.1962 - accuracy: 0.9536\n",
            "Epoch 1/5\n",
            "\n",
            "Epoch 1: accuracy did not improve from 0.96033\n",
            "19/19 - 9s - loss: 2.3399 - accuracy: 0.8793 - 9s/epoch - 470ms/step\n",
            "Epoch 2/5\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.96033\n",
            "19/19 - 8s - loss: 0.3377 - accuracy: 0.9471 - 8s/epoch - 408ms/step\n",
            "Epoch 3/5\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.96033\n",
            "19/19 - 8s - loss: 0.2741 - accuracy: 0.9587 - 8s/epoch - 409ms/step\n",
            "Epoch 4/5\n",
            "\n",
            "Epoch 4: accuracy improved from 0.96033 to 0.96364, saving model to ./model_vgg16_enable.h5\n",
            "19/19 - 8s - loss: 0.1863 - accuracy: 0.9636 - 8s/epoch - 438ms/step\n",
            "Epoch 5/5\n",
            "\n",
            "Epoch 5: accuracy improved from 0.96364 to 0.97686, saving model to ./model_vgg16_enable.h5\n",
            "19/19 - 8s - loss: 0.1270 - accuracy: 0.9769 - 8s/epoch - 440ms/step\n",
            "5/5 [==============================] - 1s 146ms/step - loss: 0.0667 - accuracy: 1.0000\n",
            "Epoch 1/5\n",
            "\n",
            "Epoch 1: accuracy did not improve from 0.97686\n",
            "19/19 - 9s - loss: 2.1797 - accuracy: 0.9174 - 9s/epoch - 468ms/step\n",
            "Epoch 2/5\n",
            "\n",
            "Epoch 2: accuracy improved from 0.97686 to 0.98843, saving model to ./model_vgg16_enable.h5\n",
            "19/19 - 8s - loss: 0.1708 - accuracy: 0.9884 - 8s/epoch - 436ms/step\n",
            "Epoch 3/5\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.98843\n",
            "19/19 - 8s - loss: 0.1116 - accuracy: 0.9835 - 8s/epoch - 408ms/step\n",
            "Epoch 4/5\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.98843\n",
            "19/19 - 8s - loss: 0.1797 - accuracy: 0.9835 - 8s/epoch - 408ms/step\n",
            "Epoch 5/5\n",
            "\n",
            "Epoch 5: accuracy improved from 0.98843 to 0.99504, saving model to ./model_vgg16_enable.h5\n",
            "19/19 - 8s - loss: 0.0664 - accuracy: 0.9950 - 8s/epoch - 439ms/step\n",
            "5/5 [==============================] - 1s 148ms/step - loss: 0.0907 - accuracy: 0.9934\n",
            "Epoch 1/5\n",
            "\n",
            "Epoch 1: accuracy did not improve from 0.99504\n",
            "19/19 - 9s - loss: 2.2171 - accuracy: 0.9174 - 9s/epoch - 471ms/step\n",
            "Epoch 2/5\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.99504\n",
            "19/19 - 8s - loss: 0.2111 - accuracy: 0.9901 - 8s/epoch - 408ms/step\n",
            "Epoch 3/5\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.99504\n",
            "19/19 - 8s - loss: 0.0980 - accuracy: 0.9950 - 8s/epoch - 409ms/step\n",
            "Epoch 4/5\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.99504\n",
            "19/19 - 8s - loss: 0.0789 - accuracy: 0.9917 - 8s/epoch - 408ms/step\n",
            "Epoch 5/5\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.99504\n",
            "19/19 - 8s - loss: 0.0641 - accuracy: 0.9917 - 8s/epoch - 408ms/step\n",
            "5/5 [==============================] - 1s 146ms/step - loss: 0.0419 - accuracy: 1.0000\n",
            "Epoch 1/5\n",
            "\n",
            "Epoch 1: accuracy did not improve from 0.99504\n",
            "7/7 - 15s - loss: 3.9134 - accuracy: 0.9503 - 15s/epoch - 2s/step\n",
            "Epoch 2/5\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.99504\n",
            "7/7 - 7s - loss: 1.6555 - accuracy: 0.9719 - 7s/epoch - 1s/step\n",
            "Epoch 3/5\n",
            "\n",
            "Epoch 3: accuracy improved from 0.99504 to 0.99834, saving model to ./model_vgg16_enable.h5\n",
            "7/7 - 8s - loss: 0.5590 - accuracy: 0.9983 - 8s/epoch - 1s/step\n",
            "Epoch 4/5\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.99834\n",
            "7/7 - 7s - loss: 0.2362 - accuracy: 0.9950 - 7s/epoch - 1s/step\n",
            "Epoch 5/5\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.99834\n",
            "7/7 - 7s - loss: 0.1530 - accuracy: 0.9983 - 7s/epoch - 1s/step\n",
            "2/2 [==============================] - 1s 265ms/step - loss: 0.1339 - accuracy: 1.0000\n",
            "Epoch 1/5\n",
            "\n",
            "Epoch 1: accuracy did not improve from 0.99834\n",
            "7/7 - 10s - loss: 4.0299 - accuracy: 0.8562 - 10s/epoch - 1s/step\n",
            "Epoch 2/5\n",
            "\n",
            "Epoch 2: accuracy improved from 0.99834 to 0.99835, saving model to ./model_vgg16_enable.h5\n",
            "7/7 - 8s - loss: 1.5750 - accuracy: 0.9983 - 8s/epoch - 1s/step\n",
            "Epoch 3/5\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.99835\n",
            "7/7 - 7s - loss: 0.5712 - accuracy: 0.9967 - 7s/epoch - 1s/step\n",
            "Epoch 4/5\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.99835\n",
            "7/7 - 7s - loss: 0.2770 - accuracy: 0.9917 - 7s/epoch - 1s/step\n",
            "Epoch 5/5\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.99835\n",
            "7/7 - 7s - loss: 0.2126 - accuracy: 0.9851 - 7s/epoch - 1s/step\n",
            "2/2 [==============================] - 1s 252ms/step - loss: 0.1558 - accuracy: 1.0000\n",
            "Epoch 1/5\n",
            "\n",
            "Epoch 1: accuracy did not improve from 0.99835\n",
            "7/7 - 9s - loss: 3.8814 - accuracy: 0.9653 - 9s/epoch - 1s/step\n",
            "Epoch 2/5\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.99835\n",
            "7/7 - 7s - loss: 1.5491 - accuracy: 0.9967 - 7s/epoch - 1s/step\n",
            "Epoch 3/5\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.99835\n",
            "7/7 - 7s - loss: 0.5831 - accuracy: 0.9934 - 7s/epoch - 1s/step\n",
            "Epoch 4/5\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.99835\n",
            "7/7 - 7s - loss: 0.6128 - accuracy: 0.9653 - 7s/epoch - 1s/step\n",
            "Epoch 5/5\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.99835\n",
            "7/7 - 7s - loss: 0.2207 - accuracy: 0.9851 - 7s/epoch - 1s/step\n",
            "2/2 [==============================] - 1s 248ms/step - loss: 0.1776 - accuracy: 0.9934\n",
            "Epoch 1/5\n",
            "\n",
            "Epoch 1: accuracy did not improve from 0.99835\n",
            "7/7 - 9s - loss: 4.1266 - accuracy: 0.8347 - 9s/epoch - 1s/step\n",
            "Epoch 2/5\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.99835\n",
            "7/7 - 7s - loss: 1.6288 - accuracy: 0.9785 - 7s/epoch - 1s/step\n",
            "Epoch 3/5\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.99835\n",
            "7/7 - 7s - loss: 0.5741 - accuracy: 0.9868 - 7s/epoch - 1s/step\n",
            "Epoch 4/5\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.99835\n",
            "7/7 - 7s - loss: 0.2259 - accuracy: 0.9967 - 7s/epoch - 1s/step\n",
            "Epoch 5/5\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.99835\n",
            "7/7 - 7s - loss: 0.1602 - accuracy: 0.9950 - 7s/epoch - 1s/step\n",
            "2/2 [==============================] - 1s 247ms/step - loss: 0.1447 - accuracy: 1.0000\n",
            "Epoch 1/5\n",
            "\n",
            "Epoch 1: accuracy did not improve from 0.99835\n",
            "7/7 - 9s - loss: 3.9389 - accuracy: 0.9504 - 9s/epoch - 1s/step\n",
            "Epoch 2/5\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.99835\n",
            "7/7 - 7s - loss: 1.5199 - accuracy: 0.9967 - 7s/epoch - 1s/step\n",
            "Epoch 3/5\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.99835\n",
            "7/7 - 7s - loss: 0.5185 - accuracy: 0.9983 - 7s/epoch - 1s/step\n",
            "Epoch 4/5\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.99835\n",
            "7/7 - 7s - loss: 0.2058 - accuracy: 0.9983 - 7s/epoch - 1s/step\n",
            "Epoch 5/5\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.99835\n",
            "7/7 - 7s - loss: 0.1432 - accuracy: 0.9967 - 7s/epoch - 1s/step\n",
            "2/2 [==============================] - 1s 252ms/step - loss: 0.1228 - accuracy: 1.0000\n",
            "Epoch 1/5\n",
            "\n",
            "Epoch 1: accuracy did not improve from 0.99835\n",
            "7/7 - 9s - loss: 3.9335 - accuracy: 0.9305 - 9s/epoch - 1s/step\n",
            "Epoch 2/5\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.99835\n",
            "7/7 - 7s - loss: 1.5598 - accuracy: 0.9967 - 7s/epoch - 1s/step\n",
            "Epoch 3/5\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.99835\n",
            "7/7 - 7s - loss: 0.5585 - accuracy: 0.9983 - 7s/epoch - 1s/step\n",
            "Epoch 4/5\n",
            "\n",
            "Epoch 4: accuracy improved from 0.99835 to 1.00000, saving model to ./model_vgg16_enable.h5\n",
            "7/7 - 8s - loss: 0.2293 - accuracy: 1.0000 - 8s/epoch - 1s/step\n",
            "Epoch 5/5\n",
            "\n",
            "Epoch 5: accuracy did not improve from 1.00000\n",
            "7/7 - 7s - loss: 0.1847 - accuracy: 0.9950 - 7s/epoch - 1s/step\n",
            "2/2 [==============================] - 1s 254ms/step - loss: 0.1472 - accuracy: 1.0000\n",
            "Epoch 1/5\n",
            "\n",
            "Epoch 1: accuracy did not improve from 1.00000\n",
            "7/7 - 9s - loss: 4.0228 - accuracy: 0.9322 - 9s/epoch - 1s/step\n",
            "Epoch 2/5\n",
            "\n",
            "Epoch 2: accuracy did not improve from 1.00000\n",
            "7/7 - 7s - loss: 1.5604 - accuracy: 0.9967 - 7s/epoch - 1s/step\n",
            "Epoch 3/5\n",
            "\n",
            "Epoch 3: accuracy did not improve from 1.00000\n",
            "7/7 - 7s - loss: 0.5752 - accuracy: 0.9950 - 7s/epoch - 1s/step\n",
            "Epoch 4/5\n",
            "\n",
            "Epoch 4: accuracy did not improve from 1.00000\n",
            "7/7 - 7s - loss: 0.2544 - accuracy: 0.9967 - 7s/epoch - 1s/step\n",
            "Epoch 5/5\n",
            "\n",
            "Epoch 5: accuracy did not improve from 1.00000\n",
            "7/7 - 7s - loss: 0.1798 - accuracy: 0.9983 - 7s/epoch - 1s/step\n",
            "2/2 [==============================] - 2s 263ms/step - loss: 0.1664 - accuracy: 1.0000\n",
            "Epoch 1/5\n",
            "\n",
            "Epoch 1: accuracy did not improve from 1.00000\n",
            "7/7 - 9s - loss: 3.9271 - accuracy: 0.9537 - 9s/epoch - 1s/step\n",
            "Epoch 2/5\n",
            "\n",
            "Epoch 2: accuracy did not improve from 1.00000\n",
            "7/7 - 7s - loss: 1.5499 - accuracy: 1.0000 - 7s/epoch - 1s/step\n",
            "Epoch 3/5\n",
            "\n",
            "Epoch 3: accuracy did not improve from 1.00000\n",
            "7/7 - 7s - loss: 0.5621 - accuracy: 0.9983 - 7s/epoch - 1s/step\n",
            "Epoch 4/5\n",
            "\n",
            "Epoch 4: accuracy did not improve from 1.00000\n",
            "7/7 - 7s - loss: 0.2444 - accuracy: 0.9967 - 7s/epoch - 1s/step\n",
            "Epoch 5/5\n",
            "\n",
            "Epoch 5: accuracy did not improve from 1.00000\n",
            "7/7 - 7s - loss: 0.1640 - accuracy: 1.0000 - 7s/epoch - 1s/step\n",
            "2/2 [==============================] - 1s 245ms/step - loss: 0.1509 - accuracy: 1.0000\n",
            "Epoch 1/5\n",
            "\n",
            "Epoch 1: accuracy did not improve from 1.00000\n",
            "7/7 - 9s - loss: 4.0283 - accuracy: 0.8760 - 9s/epoch - 1s/step\n",
            "Epoch 2/5\n",
            "\n",
            "Epoch 2: accuracy did not improve from 1.00000\n",
            "7/7 - 7s - loss: 1.5683 - accuracy: 0.9983 - 7s/epoch - 1s/step\n",
            "Epoch 3/5\n",
            "\n",
            "Epoch 3: accuracy did not improve from 1.00000\n",
            "7/7 - 7s - loss: 0.5867 - accuracy: 0.9983 - 7s/epoch - 1s/step\n",
            "Epoch 4/5\n",
            "\n",
            "Epoch 4: accuracy did not improve from 1.00000\n",
            "7/7 - 7s - loss: 0.2460 - accuracy: 1.0000 - 7s/epoch - 1s/step\n",
            "Epoch 5/5\n",
            "\n",
            "Epoch 5: accuracy did not improve from 1.00000\n",
            "7/7 - 7s - loss: 0.1771 - accuracy: 1.0000 - 7s/epoch - 1s/step\n",
            "2/2 [==============================] - 1s 249ms/step - loss: 0.1643 - accuracy: 1.0000\n",
            "Epoch 1/5\n",
            "\n",
            "Epoch 1: accuracy did not improve from 1.00000\n",
            "7/7 - 9s - loss: 3.9107 - accuracy: 0.9702 - 9s/epoch - 1s/step\n",
            "Epoch 2/5\n",
            "\n",
            "Epoch 2: accuracy did not improve from 1.00000\n",
            "7/7 - 7s - loss: 1.5379 - accuracy: 1.0000 - 7s/epoch - 1s/step\n",
            "Epoch 3/5\n",
            "\n",
            "Epoch 3: accuracy did not improve from 1.00000\n",
            "7/7 - 7s - loss: 0.5459 - accuracy: 0.9983 - 7s/epoch - 1s/step\n",
            "Epoch 4/5\n",
            "\n",
            "Epoch 4: accuracy did not improve from 1.00000\n",
            "7/7 - 7s - loss: 0.2183 - accuracy: 1.0000 - 7s/epoch - 1s/step\n",
            "Epoch 5/5\n",
            "\n",
            "Epoch 5: accuracy did not improve from 1.00000\n",
            "7/7 - 7s - loss: 0.1518 - accuracy: 1.0000 - 7s/epoch - 1s/step\n",
            "2/2 [==============================] - 1s 246ms/step - loss: 0.1405 - accuracy: 1.0000\n",
            "Epoch 1/5\n",
            "\n",
            "Epoch 1: accuracy did not improve from 1.00000\n",
            "8/8 - 17s - loss: 3.6262 - accuracy: 0.9339 - 17s/epoch - 2s/step\n",
            "Epoch 2/5\n",
            "\n",
            "Epoch 2: accuracy did not improve from 1.00000\n",
            "8/8 - 9s - loss: 1.2113 - accuracy: 1.0000 - 9s/epoch - 1s/step\n",
            "Epoch 3/5\n",
            "\n",
            "Epoch 3: accuracy did not improve from 1.00000\n",
            "8/8 - 9s - loss: 0.3711 - accuracy: 1.0000 - 9s/epoch - 1s/step\n",
            "Epoch 4/5\n",
            "\n",
            "Epoch 4: accuracy did not improve from 1.00000\n",
            "8/8 - 9s - loss: 0.1751 - accuracy: 1.0000 - 9s/epoch - 1s/step\n",
            "Epoch 5/5\n",
            "\n",
            "Epoch 5: accuracy did not improve from 1.00000\n",
            "8/8 - 9s - loss: 0.1458 - accuracy: 1.0000 - 9s/epoch - 1s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"third model:\")\n",
        "print(grid_result_3.best_params_)\n",
        "print(grid_result_3.best_estimator_)\n",
        "print(grid_result_3.best_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeTZ8xKdkni8",
        "outputId": "e8ebee4f-9f49-4893-f52c-ddeb3eb0a823"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "third model:\n",
            "{'batch_size': 100, 'epochs': 5, 'learn_rate': 0.01}\n",
            "<keras.wrappers.scikit_learn.KerasClassifier object at 0x7fa57069c910>\n",
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_3_final = load_model('./model_vgg16_enable.h5')\n",
        "mdoel_3_final_train_evaluate = model_3_final.evaluate(X_train,y_train, verbose=0)\n",
        "mdoel_3_final_test_evaluate = model_3_final.evaluate(X_test,y_test, verbose=0)\n",
        "print(\"the third model accuracy on training dataset is:\", mdoel_3_final_train_evaluate[1])\n",
        "print(\"the third model accuracy on test dataset is:\", mdoel_3_final_test_evaluate[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uK52qc7akxuo",
        "outputId": "30848cda-ae42-480c-8f5f-a42151590370"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the third model accuracy on training dataset is: 0.9973545074462891\n",
            "the third model accuracy on test dataset is: 0.9920634627342224\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conclusion:\n",
        "\n",
        "It can be concluded that the last model which all blocks are enabled from the pre-trained VGG16 model has the overal best performance (Accuracy on test dataset is 99.21%)\n",
        "\n",
        "Model 1 has all layers in the pre-trained model frozen which could causing an influence from the weights in the pre-trained model, which could not be the best setup for the model combined. (test - 93.65%, train - 95.63%).\n",
        "\n",
        "Model 2 has only block5 enabled from the VGG16 model is also good, has test accuracy of 98.81%, with 100% on train dataset.\n",
        "\n",
        "Model 3 has all layers enabled from the pre-trained model, which should be giving us the most flexibility to perfectly train the model. "
      ],
      "metadata": {
        "id": "q75YJuEe7uOL"
      }
    }
  ]
}